{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurtvalcorza/kurtvalcorza/blob/main/Transcribe_Audio_Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFtEeY13V5le"
      },
      "source": [
        "# Setup\n",
        "- Upload audio mp3 file/s to Google Drive\n",
        "- Change runtime type Hardware accelerator to T4 GPU\n",
        "- Install Whisper and mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# whisper-large-v2\n",
        "- [https://github.com/openai/whisper](https://github.com/openai/whisper)"
      ],
      "metadata": {
        "id": "GNmYH7tsGWkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-oYXJ64VDD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f4d45d-4e1e-497c-bd36-4ebf9b875b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-pmb63lg_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-pmb63lg_\n",
            "  Resolved https://github.com/openai/whisper.git to commit dd985ac4b90cafeef8712f2998d62c59c3e62d22\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803705 sha256=9e4fe40da3138a8103fef0afc2c7ebcffd30208ba947bca46bf92cdc97b64de6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b5n29t9q/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d6CY0USYMq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c212b6a-77db-4c86-a857-b69e7f7f0c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpoREdPV2bkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae24ce35-5d75-4663-fa93-a0ebcbd70ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:41<00:00, 74.8MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Tagalog\n",
            "[00:00.000 --> 00:03.140]  civil engineering\n",
            "[00:03.140 --> 00:04.900]  electrical po\n",
            "[00:04.900 --> 00:05.800]  ah electrical\n",
            "[00:05.800 --> 00:07.000]  oh wow\n",
            "[00:07.000 --> 00:09.140]  kay Sir Pavi ko po ako nag-take\n",
            "[00:09.140 --> 00:11.960]  dapat mamashall kayo ulit sa UPL\n",
            "[00:11.960 --> 00:13.740]  pinaka-miss yung lugar ano\n",
            "[00:13.740 --> 00:15.660]  ay malimit po yan\n",
            "[00:15.660 --> 00:17.520]  kasi meron silang ano\n",
            "[00:17.520 --> 00:19.760]  meron po silang MOU\n",
            "[00:19.760 --> 00:20.680]  with\n",
            "[00:20.680 --> 00:23.000]  Institute of Biology\n",
            "[00:23.000 --> 00:24.060]  tama ba John?\n",
            "[00:24.140 --> 00:24.760]  ay ano po\n",
            "[00:24.760 --> 00:27.420]  Museum of Natural History\n",
            "[00:27.420 --> 00:28.820]  yes po\n",
            "[00:30.000 --> 00:33.400]  nakita ko sa ano\n",
            "[00:33.400 --> 00:35.000]  sa project brief nyo\n",
            "[00:35.000 --> 00:36.640]  opo\n",
            "[00:36.640 --> 00:38.840]  ayun po Doc Rachel\n",
            "[00:38.840 --> 00:41.820]  naalalan yung time na nagpunta ako dyan\n",
            "[00:41.820 --> 00:43.520]  yung nagkita tayo\n",
            "[00:43.520 --> 00:45.220]  yung briefly\n",
            "[00:45.220 --> 00:46.880]  yung dumalo kami ni Rox\n",
            "[00:46.880 --> 00:50.620]  saan nga ba tayo nagkita?\n",
            "[00:51.260 --> 00:52.220]  saan tayo nagkita?\n",
            "[00:52.220 --> 00:54.220]  nung pumunta po ako dyan sa ICS\n",
            "[00:54.740 --> 00:56.080]  February pa nga\n",
            "[00:56.080 --> 00:56.700]  ay oo\n",
            "[00:56.700 --> 00:59.680]  yun yung time na sinama ko ni Sir Ari\n",
            "[00:59.680 --> 01:01.480]  Ariane Hasildo\n",
            "[01:01.480 --> 01:02.840]  saka ni Rox Almudien\n",
            "[01:02.840 --> 01:05.520]  tapos yun yung time na nag\n",
            "[01:05.520 --> 01:06.200]  ano sabi ko\n",
            "[01:06.200 --> 01:07.680]  collab ko tayo\n",
            "[01:07.680 --> 01:09.180]  oo yun yung time po\n",
            "[01:09.180 --> 01:10.880]  eh parang isang taon na ata\n",
            "[01:10.880 --> 01:11.680]  yun mahigit\n",
            "[01:11.680 --> 01:13.840]  ah si Mamayla pala nandyan din\n",
            "[01:13.840 --> 01:14.580]  Mamayla\n",
            "[01:14.580 --> 01:15.500]  say hello\n",
            "[01:15.500 --> 01:18.280]  oo nga pala\n",
            "[01:18.280 --> 01:20.780]  baka may problema siya sa ano\n",
            "[01:20.780 --> 01:22.100]  sa audio\n",
            "[01:22.100 --> 01:22.600]  ayan\n",
            "[01:22.600 --> 01:23.840]  hello hello\n",
            "[01:23.840 --> 01:25.900]  hi ma'am\n",
            "[01:25.900 --> 01:27.260]  oo nga pala\n",
            "[01:27.260 --> 01:28.980]  mahigit isang taon na ata yun\n",
            "[01:28.980 --> 01:29.560]  opo\n",
            "[01:29.680 --> 01:31.260]  kasi ganito po yan eh\n",
            "[01:31.260 --> 01:32.720]  may kwento ko lang din po no\n",
            "[01:32.720 --> 01:35.180]  related din po\n",
            "[01:35.180 --> 01:36.900]  ito sa tinatanong niyong MOU\n",
            "[01:36.900 --> 01:38.240]  meron po\n",
            "[01:38.240 --> 01:39.460]  yung ASTI po\n",
            "[01:39.460 --> 01:40.300]  may project\n",
            "[01:40.300 --> 01:40.900]  ALAM\n",
            "[01:40.900 --> 01:41.920]  ASTI ALAM\n",
            "[01:41.920 --> 01:44.200]  tapos isa sa mga use cases po nun\n",
            "[01:44.200 --> 01:44.700]  ay yung\n",
            "[01:44.700 --> 01:46.500]  3D reconstruction\n",
            "[01:46.500 --> 01:47.540]  ng mga ano\n",
            "[01:47.540 --> 01:48.140]  na kapag\n",
            "[01:48.140 --> 01:50.240]  meron kaming memorandum of\n",
            "[01:50.240 --> 01:51.060]  understanding\n",
            "[01:51.060 --> 01:52.880]  with Museum of Natural History\n",
            "[01:52.880 --> 01:53.280]  where\n",
            "[01:53.280 --> 01:55.560]  gagamitin yung technology ni ASTI\n",
            "[01:55.560 --> 01:57.500]  para ma-reconstruct\n",
            "[01:57.500 --> 01:58.300]  in 3D\n",
            "[01:58.300 --> 01:59.260]  yung mga\n",
            "[01:59.260 --> 01:59.560]  ano po yung\n",
            "[01:59.560 --> 02:00.000]  ano po ba\n",
            "[02:00.000 --> 02:00.560]  diba sa\n",
            "[02:00.560 --> 02:01.700]  sa Museum of Natural History\n",
            "[02:01.700 --> 02:02.980]  maraming mga insects\n",
            "[02:02.980 --> 02:04.640]  tapos gagamit\n",
            "[02:04.640 --> 02:06.020]  meron po kaming\n",
            "[02:06.020 --> 02:07.260]  dine-develop na device\n",
            "[02:07.260 --> 02:08.600]  detect ng picture\n",
            "[02:08.600 --> 02:09.180]  dun sa insect\n",
            "[02:09.180 --> 02:10.540]  tapos marirecreate po yun\n",
            "[02:10.540 --> 02:11.300]  in 3D\n",
            "[02:11.300 --> 02:12.640]  yun yung aming\n",
            "[02:12.640 --> 02:13.100]  bawa\n",
            "[02:13.100 --> 02:13.800]  ngayon\n",
            "[02:13.800 --> 02:15.820]  Kurt correct me\n",
            "[02:15.820 --> 02:16.500]  if I'm wrong\n",
            "[02:16.500 --> 02:17.300]  regarding the\n",
            "[02:17.300 --> 02:19.180]  status of the MOU\n",
            "[02:19.180 --> 02:21.280]  parang ang gusto po yata\n",
            "[02:21.280 --> 02:22.700]  is buong UPLB na\n",
            "[02:22.700 --> 02:23.440]  hindi lang yung\n",
            "[02:23.440 --> 02:24.820]  Museum of Natural History\n",
            "[02:24.820 --> 02:26.060]  Kurt can you\n",
            "[02:26.060 --> 02:27.300]  shed some light\n",
            "[02:27.300 --> 02:28.400]  on that development\n",
            "[02:28.400 --> 02:28.700]  yung\n",
            "[02:29.560 --> 02:31.460]  saang banda\n",
            "[02:31.460 --> 02:32.120]  sorry ha\n",
            "[02:32.120 --> 02:33.160]  saang banda si\n",
            "[02:33.160 --> 02:34.280]  Alam\n",
            "[02:34.280 --> 02:35.780]  saan ba siya\n",
            "[02:35.780 --> 02:36.500]  nandun ba siya\n",
            "[02:36.500 --> 02:37.480]  sa project brief\n",
            "[02:37.480 --> 02:38.080]  ng ano\n",
            "[02:38.080 --> 02:40.980]  kasi pinadala nyo\n",
            "[02:40.980 --> 02:42.320]  ako ng project brief\n",
            "[02:42.320 --> 02:42.840]  eh no\n",
            "[02:42.840 --> 02:43.840]  at ano po siya\n",
            "[02:43.840 --> 02:44.700]  bali magiging\n",
            "[02:44.700 --> 02:45.100]  yung pong\n",
            "[02:45.100 --> 02:46.260]  project brief\n",
            "[02:46.260 --> 02:47.040]  na pinadala po\n",
            "[02:47.040 --> 02:48.120]  ay continuation po\n",
            "[02:48.120 --> 02:48.660]  yan ni Alam\n",
            "[02:48.660 --> 02:49.480]  kasi si Alam po\n",
            "[02:49.480 --> 02:50.640]  ay patapos na\n",
            "[02:50.640 --> 02:51.840]  okay okay\n",
            "[02:51.840 --> 02:53.040]  mamaya po\n",
            "[02:53.040 --> 02:53.840]  matidiscuss po\n",
            "[02:53.840 --> 02:54.660]  doon sa slides\n",
            "[02:54.660 --> 02:57.320]  yung Museum of National History\n",
            "[02:57.320 --> 02:58.380]  Mamayla\n",
            "[02:58.380 --> 02:59.000]  and Sir\n",
            "[02:59.000 --> 02:59.500]  Andre\n",
            "[02:59.560 --> 03:01.960]  naka MOU\n",
            "[03:01.960 --> 03:02.360]  ano\n",
            "[03:02.360 --> 03:03.240]  MOU ba\n",
            "[03:03.240 --> 03:04.880]  o MOA kayo\n",
            "[03:04.880 --> 03:06.220]  sorry\n",
            "[03:06.220 --> 03:07.960]  and then sa engineering\n",
            "[03:07.960 --> 03:08.960]  meron din ata\n",
            "[03:08.960 --> 03:10.080]  sa College of\n",
            "[03:10.080 --> 03:11.260]  Engineering\n",
            "[03:11.260 --> 03:11.980]  and\n",
            "[03:11.980 --> 03:13.300]  SEAT\n",
            "[03:13.300 --> 03:14.440]  SEAT yun diba\n",
            "[03:14.440 --> 03:15.860]  Agricultural\n",
            "[03:15.860 --> 03:16.800]  Technologies\n",
            "[03:16.800 --> 03:17.560]  ba yun\n",
            "[03:17.560 --> 03:18.460]  nagpulit na kasi\n",
            "[03:18.460 --> 03:19.420]  yung mga pangalan\n",
            "[03:19.420 --> 03:21.460]  dati simple lang\n",
            "[03:21.460 --> 03:22.580]  College of Forestry\n",
            "[03:22.580 --> 03:22.740]  lang\n",
            "[03:22.740 --> 03:23.940]  College of Engineering\n",
            "[03:23.940 --> 03:24.700]  ngayon\n",
            "[03:24.700 --> 03:26.140]  medyo nag iba-iba na eh\n",
            "[03:26.140 --> 03:27.840]  College of Agriculture\n",
            "[03:27.840 --> 03:28.900]  ganun lang\n",
            "[03:28.900 --> 03:29.480]  ngayon\n",
            "[03:29.480 --> 03:31.040]  and Food Technology\n",
            "[03:31.040 --> 03:31.820]  ata ang\n",
            "[03:31.820 --> 03:32.520]  agriculture\n",
            "[03:32.520 --> 03:33.400]  ay nagbago na po\n",
            "[03:33.400 --> 03:34.540]  yung College of Agriculture\n",
            "[03:34.540 --> 03:34.900]  oo\n",
            "[03:34.900 --> 03:35.620]  iba na\n",
            "[03:35.620 --> 03:37.020]  kasi in-highlight na nila\n",
            "[03:37.020 --> 03:37.860]  yung Food Tech\n",
            "[03:37.860 --> 03:40.080]  yes\n",
            "[03:40.080 --> 03:41.500]  sa inyo ba yung\n",
            "[03:41.500 --> 03:42.660]  tinatakot natin\n",
            "[03:42.660 --> 03:42.960]  si Kirk\n",
            "[03:42.960 --> 03:43.380]  si Kirk po\n",
            "[03:43.380 --> 03:44.820]  yung\n",
            "[03:44.820 --> 03:45.820]  yung sign\n",
            "[03:45.820 --> 03:47.280]  yung sign po na\n",
            "[03:47.280 --> 03:49.000]  MOU po ma'am\n",
            "[03:49.000 --> 03:49.220]  is\n",
            "[03:49.220 --> 03:50.080]  between\n",
            "[03:50.080 --> 03:50.860]  DOST\n",
            "[03:50.860 --> 03:51.360]  and\n",
            "[03:51.360 --> 03:52.980]  UPLB\n",
            "[03:52.980 --> 03:53.880]  so it was signed by\n",
            "[03:53.880 --> 03:55.400]  Chancellor Camacho po\n",
            "[03:55.400 --> 03:56.540]  so wala pong\n",
            "[03:56.540 --> 03:57.280]  hindi po siya\n",
            "[03:57.280 --> 03:58.340]  limited or\n",
            "[03:58.340 --> 03:59.400]  restricted to us\n",
            "[03:59.400 --> 03:59.900]  specific\n",
            "[03:59.900 --> 04:01.960]  college po\n",
            "[04:01.960 --> 04:03.960]  okay hindi na namin\n",
            "[04:03.960 --> 04:04.720]  kailangan\n",
            "[04:04.720 --> 04:06.040]  maganda sana\n",
            "[04:06.040 --> 04:06.900]  kung merong mga\n",
            "[04:06.900 --> 04:08.380]  piktura na yun\n",
            "[04:08.380 --> 04:11.380]  diba maganda\n",
            "[04:11.380 --> 04:12.900]  nakipag MOU ka\n",
            "[04:12.900 --> 04:13.700]  sa ASTI\n",
            "[04:13.700 --> 04:14.340]  ganun\n",
            "[04:14.340 --> 04:15.920]  pwede po naman\n",
            "[04:15.920 --> 04:17.040]  possible din naman po\n",
            "[04:17.040 --> 04:17.460]  yun ang\n",
            "[04:17.460 --> 04:18.660]  mangyari pa din\n",
            "[04:18.660 --> 04:19.780]  later on\n",
            "[04:19.780 --> 04:20.500]  dun sa ano\n",
            "[04:20.500 --> 04:21.020]  parang\n",
            "[04:21.020 --> 04:22.020]  actually\n",
            "[04:22.020 --> 04:23.000]  we can have that\n",
            "[04:23.000 --> 04:23.340]  parang\n",
            "[04:23.340 --> 04:24.200]  yun po\n",
            "[04:24.200 --> 04:24.580]  pwedeng\n",
            "[04:24.580 --> 04:26.200]  kasi magkakaroon po kami\n",
            "[04:26.200 --> 04:27.120]  ng ASTI con\n",
            "[04:27.120 --> 04:28.260]  baka\n",
            "[04:28.260 --> 04:29.280]  pwede pong\n",
            "[04:29.280 --> 04:30.140]  maihabol\n",
            "[04:30.140 --> 04:31.980]  yun yung piktura\n",
            "[04:31.980 --> 04:32.640]  na sinasabi\n",
            "[04:32.640 --> 04:33.600]  na signing ako\n",
            "[04:33.600 --> 04:34.320]  umumat\n",
            "[04:34.320 --> 04:36.500]  we can\n",
            "[04:36.500 --> 04:37.220]  actually\n",
            "[04:37.220 --> 04:38.520]  invite you\n",
            "[04:38.520 --> 04:39.060]  doon sa\n",
            "[04:39.060 --> 04:40.180]  event namin\n",
            "[04:40.180 --> 04:40.720]  na yun\n",
            "[04:40.720 --> 04:42.440]  pero Kurt\n",
            "[04:42.440 --> 04:43.160]  matanong ko\n",
            "[04:43.160 --> 04:44.040]  nasign na ba\n",
            "[04:44.040 --> 04:45.240]  yung MOU na yun\n",
            "[04:45.240 --> 04:46.340]  with UPLB\n",
            "[04:46.340 --> 04:47.760]  o ano pa\n",
            "[04:47.760 --> 04:48.560]  hindi pa\n",
            "[04:48.560 --> 04:50.360]  signed po yun sir\n",
            "[04:50.360 --> 04:51.500]  ah signed na\n",
            "[04:51.500 --> 04:52.080]  so okay na\n",
            "[04:52.080 --> 04:53.260]  during ASTI con\n",
            "[04:53.260 --> 04:53.840]  last\n",
            "[04:53.840 --> 04:55.240]  last\n",
            "[04:55.240 --> 04:56.120]  with\n",
            "[04:56.120 --> 04:56.960]  buong\n",
            "[04:56.960 --> 04:57.400]  ano yun to\n",
            "[04:57.400 --> 04:57.980]  UPLB\n",
            "[04:57.980 --> 04:59.120]  Chancellor level\n",
            "[04:59.120 --> 04:59.620]  nagto\n",
            "[04:59.620 --> 05:00.720]  yes sir\n",
            "[05:00.720 --> 05:02.260]  edi covered na tayo\n",
            "[05:02.260 --> 05:02.840]  edi\n",
            "[05:02.840 --> 05:03.640]  ano na lang\n",
            "[05:03.640 --> 05:05.020]  mag-usap na lang tayo\n",
            "[05:05.020 --> 05:05.700]  kung ano yung\n",
            "[05:05.700 --> 05:06.900]  specific na pwede\n",
            "[05:06.900 --> 05:07.580]  natin gawin\n",
            "[05:07.580 --> 05:08.200]  doon tayo\n",
            "[05:08.200 --> 05:08.480]  mag\n",
            "[05:08.480 --> 05:09.740]  buwa\n",
            "[05:09.740 --> 05:12.140]  sige po ma'am\n",
            "[05:12.140 --> 05:12.880]  sige sige\n",
            "[05:12.880 --> 05:13.340]  okay\n",
            "[05:13.340 --> 05:14.660]  now with that\n",
            "[05:14.660 --> 05:15.140]  po\n",
            "[05:15.140 --> 05:15.420]  ay\n",
            "[05:15.420 --> 05:16.240]  sige po\n",
            "[05:16.240 --> 05:17.060]  ma'am\n",
            "[05:17.060 --> 05:17.320]  sige\n",
            "[05:17.320 --> 05:18.160]  ma'am Myla\n",
            "[05:18.160 --> 05:19.140]  tsaka sir Andre\n",
            "[05:19.140 --> 05:20.040]  mga studyante\n",
            "[05:20.040 --> 05:20.780]  daw natin\n",
            "[05:20.780 --> 05:21.540]  mga product\n",
            "[05:21.540 --> 05:22.700]  ng UPLB\n",
            "[05:22.700 --> 05:24.320]  si\n",
            "[05:24.320 --> 05:25.900]  sino nga\n",
            "[05:25.900 --> 05:26.540]  si\n",
            "[05:26.540 --> 05:26.980]  si\n",
            "[05:26.980 --> 05:27.560]  sir Bunny\n",
            "[05:27.560 --> 05:28.280]  Bunny\n",
            "[05:28.280 --> 05:29.080]  si Bunny\n",
            "[05:29.120 --> 05:30.520]  si Miss Roxanne\n",
            "[05:30.520 --> 05:32.540]  si Miss Roxanne\n",
            "[05:32.540 --> 05:33.280]  at saka si\n",
            "[05:33.280 --> 05:33.720]  John\n",
            "[05:33.720 --> 05:39.480]  si Kurt po\n",
            "[05:39.480 --> 05:40.260]  ay UPOU\n",
            "[05:40.260 --> 05:41.980]  ah wow\n",
            "[05:41.980 --> 05:43.440]  UPOU po si Kurt\n",
            "[05:43.440 --> 05:45.680]  magkapatid\n",
            "[05:45.680 --> 05:47.620]  magkapatid tayo\n",
            "[05:47.620 --> 05:50.160]  kila Dr. Myla\n",
            "[05:50.160 --> 05:51.900]  sige po\n",
            "[05:51.900 --> 05:53.500]  meron po kaming\n",
            "[05:53.500 --> 05:54.060]  na ano\n",
            "[05:54.060 --> 05:55.920]  para po siguro\n",
            "[05:55.920 --> 05:56.540]  magkaroon kayo\n",
            "[05:56.540 --> 05:57.020]  ng idea\n",
            "[05:57.020 --> 05:57.600]  kung ano yung mga\n",
            "[05:57.600 --> 05:58.600]  possible points of\n",
            "[05:58.600 --> 05:59.100]  collaboration\n",
            "[05:59.120 --> 06:00.020]  natin\n",
            "[06:00.020 --> 06:01.200]  with regards\n",
            "[06:01.200 --> 06:01.720]  to ano\n",
            "[06:01.720 --> 06:02.900]  meron po kaming\n",
            "[06:02.900 --> 06:03.680]  presentation\n",
            "[06:03.680 --> 06:04.580]  ayun may\n",
            "[06:04.580 --> 06:05.480]  may chinat po dito\n",
            "[06:05.480 --> 06:06.500]  si ma'am Joanne\n",
            "[06:06.500 --> 06:07.980]  both institutions\n",
            "[06:07.980 --> 06:08.940]  agree to develop\n",
            "[06:08.940 --> 06:09.580]  the following\n",
            "[06:09.580 --> 06:10.800]  collaborative activities\n",
            "[06:10.800 --> 06:11.480]  in the academic\n",
            "[06:11.480 --> 06:13.100]  student internships\n",
            "[06:13.100 --> 06:13.620]  eto po\n",
            "[06:13.620 --> 06:14.600]  na eto\n",
            "[06:14.600 --> 06:15.380]  eto meron ng\n",
            "[06:15.380 --> 06:16.500]  collaborative\n",
            "[06:16.500 --> 06:18.080]  research project\n",
            "[06:18.080 --> 06:20.280]  ayan wait\n",
            "[06:20.280 --> 06:22.280]  hi sir\n",
            "[06:22.280 --> 06:22.780]  Arian\n",
            "[06:22.780 --> 06:24.300]  nandito na si\n",
            "[06:24.300 --> 06:24.820]  sir Arian\n",
            "[06:24.820 --> 06:26.280]  hi sir\n",
            "[06:26.280 --> 06:27.120]  Arian\n",
            "[06:27.120 --> 06:27.680]  no no\n",
            "[06:27.680 --> 06:28.380]  yun\n",
            "[06:28.380 --> 06:30.840]  oo nga pala\n",
            "[06:30.840 --> 06:31.560]  kayo nga pala\n",
            "[06:31.560 --> 06:32.520]  magkasama noon\n",
            "[06:32.520 --> 06:33.680]  oo po kami\n",
            "[06:33.680 --> 06:34.480]  magkasama noon\n",
            "[06:34.480 --> 06:35.320]  nung dumalaw po\n",
            "[06:35.320 --> 06:36.400]  ako sa ICS\n",
            "[06:36.400 --> 06:39.780]  may tanong ko po\n",
            "[06:39.780 --> 06:40.380]  yung project\n",
            "[06:40.380 --> 06:40.980]  saray po\n",
            "[06:40.980 --> 06:41.740]  sa inyo po yun\n",
            "[06:41.740 --> 06:42.840]  yung saray\n",
            "[06:42.840 --> 06:44.100]  ano involved kami\n",
            "[06:44.100 --> 06:44.500]  ron\n",
            "[06:44.500 --> 06:46.020]  si ma'am Connie\n",
            "[06:46.020 --> 06:47.300]  at saka si\n",
            "[06:47.300 --> 06:48.960]  Aldrin How\n",
            "[06:48.960 --> 06:50.000]  ang involved doon\n",
            "[06:50.000 --> 06:50.860]  taga ICS\n",
            "[06:50.860 --> 06:51.400]  sila\n",
            "[06:51.400 --> 06:52.760]  kasi smart yun eh\n",
            "[06:52.760 --> 06:53.320]  smart\n",
            "[06:53.320 --> 06:54.540]  ano po yun\n",
            "[06:54.540 --> 06:55.360]  ah kumbaga\n",
            "[06:55.360 --> 06:56.640]  ongoing pa rin po\n",
            "[06:56.640 --> 06:56.880]  siya\n",
            "[06:56.880 --> 06:57.260]  ongoing\n",
            "[06:57.260 --> 06:58.000]  ah\n",
            "[06:58.000 --> 06:58.700]  ongoing\n",
            "[06:58.700 --> 06:59.720]  may bago silang\n",
            "[06:59.720 --> 07:00.600]  funding ngayon\n",
            "[07:00.600 --> 07:01.940]  na 600 million\n",
            "[07:01.940 --> 07:02.580]  wow\n",
            "[07:02.580 --> 07:03.060]  wow\n",
            "[07:03.060 --> 07:03.800]  ano\n",
            "[07:03.800 --> 07:04.500]  multi\n",
            "[07:04.500 --> 07:05.660]  multi ano kasi\n",
            "[07:05.660 --> 07:06.440]  collaborative\n",
            "[07:06.440 --> 07:07.160]  so\n",
            "[07:07.160 --> 07:08.720]  may mga regional\n",
            "[07:08.720 --> 07:09.980]  center sila\n",
            "[07:09.980 --> 07:10.860]  ng saray\n",
            "[07:10.860 --> 07:11.700]  oo\n",
            "[07:11.700 --> 07:12.540]  okay okay\n",
            "[07:12.540 --> 07:12.740]  sige\n",
            "[07:12.740 --> 07:13.640]  lagi po yun ma'am\n",
            "[07:13.640 --> 07:13.900]  ano\n",
            "[07:13.900 --> 07:15.960]  kasi kasama yun\n",
            "[07:15.960 --> 07:16.800]  doon sa slides\n",
            "[07:16.800 --> 07:17.480]  ng BOST\n",
            "[07:17.480 --> 07:18.340]  actually last\n",
            "[07:18.340 --> 07:19.340]  yesterday\n",
            "[07:19.340 --> 07:20.660]  nasa central office\n",
            "[07:20.660 --> 07:21.020]  ako\n",
            "[07:21.020 --> 07:22.580]  secretary\n",
            "[07:22.580 --> 07:24.160]  may visitor\n",
            "[07:24.160 --> 07:25.080]  from Australia\n",
            "[07:25.080 --> 07:26.980]  nag present\n",
            "[07:26.980 --> 07:27.300]  ng mga\n",
            "[07:27.300 --> 07:27.980]  AI project\n",
            "[07:28.000 --> 07:28.740]  ng DOST\n",
            "[07:28.740 --> 07:29.860]  so yun\n",
            "[07:29.860 --> 07:30.900]  nakita ko yung saray\n",
            "[07:30.900 --> 07:31.420]  doon sa ano\n",
            "[07:31.420 --> 07:32.040]  alam ko kasi\n",
            "[07:32.040 --> 07:33.780]  smart agriculture\n",
            "[07:33.780 --> 07:35.700]  pinipredict yung ano\n",
            "[07:35.700 --> 07:36.500]  yung halimbawa\n",
            "[07:36.500 --> 07:38.020]  given the soil\n",
            "[07:38.020 --> 07:39.720]  baka mas alam ni\n",
            "[07:39.720 --> 07:40.480]  sir Aryan\n",
            "[07:40.480 --> 07:41.080]  i-explain\n",
            "[07:41.080 --> 07:42.340]  so yung mga\n",
            "[07:42.340 --> 07:43.140]  characteristics\n",
            "[07:43.140 --> 07:43.760]  ng soil\n",
            "[07:43.760 --> 07:45.060]  aalamin kung\n",
            "[07:45.060 --> 07:46.620]  magiging successful\n",
            "[07:46.620 --> 07:47.160]  ang\n",
            "[07:47.160 --> 07:48.120]  ang\n",
            "[07:48.120 --> 07:48.900]  planting\n",
            "[07:48.900 --> 07:50.160]  ganun\n",
            "[07:50.160 --> 07:50.960]  ako\n",
            "[07:50.960 --> 07:51.720]  oo\n",
            "[07:51.720 --> 07:53.200]  sige po\n",
            "[07:53.200 --> 07:54.220]  so ito may\n",
            "[07:54.220 --> 07:55.400]  may chinat po dito\n",
            "[07:55.400 --> 07:56.040]  si ma'am Joanne\n",
            "[07:56.040 --> 07:57.100]  pero mamaya ko na lang po\n",
            "[07:57.100 --> 07:57.960]  siguro to i-discuss\n",
            "[07:57.960 --> 07:58.860]  after my\n",
            "[07:58.860 --> 07:59.840]  presentation\n",
            "[07:59.840 --> 08:00.340]  para\n",
            "[08:00.340 --> 08:01.260]  these are something\n",
            "[08:01.260 --> 08:03.300]  that we can\n",
            "[08:03.300 --> 08:04.120]  these are\n",
            "[08:04.120 --> 08:05.240]  possible points\n",
            "[08:05.240 --> 08:06.200]  of collaborations\n",
            "[08:06.200 --> 08:06.980]  po no\n",
            "[08:06.980 --> 08:08.960]  before I begin po\n",
            "[08:08.960 --> 08:10.080]  with my presentation\n",
            "[08:10.080 --> 08:11.160]  I'd like to\n",
            "[08:11.160 --> 08:12.080]  introduce lang po\n",
            "[08:12.080 --> 08:12.560]  yung some\n",
            "[08:12.560 --> 08:14.040]  members po\n",
            "[08:14.040 --> 08:15.100]  na hindi pa na-introduce\n",
            "[08:15.100 --> 08:15.680]  kanina\n",
            "[08:15.680 --> 08:17.060]  like si Miss Nia\n",
            "[08:17.060 --> 08:17.520]  Nia\n",
            "[08:17.520 --> 08:20.260]  kasama rin po namin\n",
            "[08:20.260 --> 08:20.560]  si Miss\n",
            "[08:20.560 --> 08:21.380]  si Nia naman po\n",
            "[08:21.380 --> 08:22.060]  involved siya doon\n",
            "[08:22.060 --> 08:22.960]  sa isang project\n",
            "[08:22.960 --> 08:23.780]  yung gulay\n",
            "[08:23.780 --> 08:24.620]  naman\n",
            "[08:24.620 --> 08:25.580]  na\n",
            "[08:25.580 --> 08:26.660]  na project\n",
            "[08:27.960 --> 08:29.960]  hello\n",
            "[08:29.960 --> 08:32.960]  ay baka may\n",
            "[08:32.960 --> 08:33.960]  may problem lang\n",
            "[08:33.960 --> 08:34.960]  ah Nia pala\n",
            "[08:34.960 --> 08:35.960]  ano Nia\n",
            "[08:35.960 --> 08:36.960]  ah si Miss Nia pa ba po\n",
            "[08:36.960 --> 08:37.960]  kasama din po siya\n",
            "[08:37.960 --> 08:38.960]  from\n",
            "[08:38.960 --> 08:39.960]  from ASTI din po ito\n",
            "[08:39.960 --> 08:41.960]  I think\n",
            "[08:41.960 --> 08:42.960]  lahat naman po yata\n",
            "[08:42.960 --> 08:43.960]  na-introduce na\n",
            "[08:43.960 --> 08:44.960]  sige po\n",
            "[08:44.960 --> 08:45.960]  yung ba\n",
            "[08:45.960 --> 08:46.960]  yung ba\n",
            "[08:46.960 --> 08:47.960]  yung\n",
            "[08:47.960 --> 08:48.960]  di ba gumawa si DTI\n",
            "[08:48.960 --> 08:49.960]  ng\n",
            "[08:49.960 --> 08:50.960]  AI roadmap\n",
            "[08:50.960 --> 08:51.960]  di ba\n",
            "[08:51.960 --> 08:52.960]  ang ginagamit\n",
            "[08:52.960 --> 08:53.960]  may bago bang version noon\n",
            "[08:53.960 --> 08:55.960]  may bago na po ngayon ma'am\n",
            "[08:55.960 --> 08:56.960]  yung na SPHE\n",
            "[08:56.960 --> 08:57.960]  sa-type ko po dito\n",
            "[08:57.960 --> 08:58.960]  yung ano ah\n",
            "[08:58.960 --> 08:59.960]  wait lang po ah\n",
            "[08:59.960 --> 09:00.960]  yung latest\n",
            "[09:00.960 --> 09:01.960]  this is the latest\n",
            "[09:01.960 --> 09:02.960]  kasi\n",
            "[09:02.960 --> 09:03.960]  kapop\n",
            "[09:03.960 --> 09:04.960]  kapop\n",
            "[09:04.960 --> 09:05.960]  kapapublish pa lang to\n",
            "[09:05.960 --> 09:07.960]  hindi ka pa kasi na ano yung latest\n",
            "[09:07.960 --> 09:09.960]  from DOST po ito\n",
            "[09:09.960 --> 09:10.960]  ayan\n",
            "[09:10.960 --> 09:12.960]  eto po yung bagong directive ni PBBM\n",
            "[09:12.960 --> 09:14.960]  so actually\n",
            "[09:14.960 --> 09:17.960]  PBBM directed DOST\n",
            "[09:17.960 --> 09:18.960]  to lead the initiative po\n",
            "[09:18.960 --> 09:20.960]  ah DOST na pala\n",
            "[09:20.960 --> 09:21.960]  opo\n",
            "[09:21.960 --> 09:24.960]  sa bagay DTI kasi more on industries eno sir\n",
            "[09:24.960 --> 09:25.960]  opo opo\n",
            "[09:25.960 --> 09:28.960]  eto yung ano parang\n",
            "[09:28.960 --> 09:30.960]  PBBM ano\n",
            "[09:30.960 --> 09:34.960]  task DOST to craft a national AI\n",
            "[09:34.960 --> 09:35.960]  ah strategy\n",
            "[09:35.960 --> 09:38.960]  pero siyempre kailangan namin ng ano\n",
            "[09:38.960 --> 09:39.960]  involvement ng ano\n",
            "[09:39.960 --> 09:41.960]  ng other agencies\n",
            "[09:41.960 --> 09:43.960]  and this is also in collaboration\n",
            "[09:43.960 --> 09:46.960]  with the national innovation council\n",
            "[09:46.960 --> 09:47.960]  technical working group\n",
            "[09:47.960 --> 09:48.960]  so may mga binubupong panel\n",
            "[09:48.960 --> 09:49.960]  ah si Rhea\n",
            "[09:49.960 --> 09:51.960]  nando si Rhea\n",
            "[09:51.960 --> 09:52.960]  ah\n",
            "[09:52.960 --> 09:54.960]  sa national innovation council\n",
            "[09:54.960 --> 09:55.960]  yes\n",
            "[09:55.960 --> 09:56.960]  ah\n",
            "[09:56.960 --> 09:57.960]  ah\n",
            "[09:57.960 --> 09:59.960]  DOST and NIC\n",
            "[09:59.960 --> 10:00.960]  apo NIC\n",
            "[10:00.960 --> 10:04.960]  pero pala nabas lang pala ng balita\n",
            "[10:04.960 --> 10:05.960]  so gagawin pa\n",
            "[10:05.960 --> 10:07.960]  ah po\n",
            "[10:07.960 --> 10:09.960]  ano po pero nagstart na po kami\n",
            "[10:09.960 --> 10:10.960]  like\n",
            "[10:10.960 --> 10:11.960]  parang as early as February\n",
            "[10:11.960 --> 10:12.960]  po\n",
            "[10:12.960 --> 10:13.960]  nag\n",
            "[10:13.960 --> 10:14.960]  nagko-convene na\n",
            "[10:14.960 --> 10:15.960]  ganyan\n",
            "[10:15.960 --> 10:16.960]  tapos\n",
            "[10:16.960 --> 10:17.960]  last Tuesday lang yata\n",
            "[10:17.960 --> 10:18.960]  I think that was\n",
            "[10:18.960 --> 10:19.960]  kailan ba yung mini\n",
            "[10:19.960 --> 10:20.960]  manyeteeng si\n",
            "[10:20.960 --> 10:21.960]  ni PBMC\n",
            "[10:21.960 --> 10:22.960]  si SEC\n",
            "[10:22.960 --> 10:23.960]  no\n",
            "[10:23.960 --> 10:32.260]  Kasama nga yung director namin, ikinausap tangkol doon po dito sa AI for National Development po.\n",
            "[10:34.220 --> 10:37.360]  Ang ganda. I-involve nyo naman kami dyan.\n",
            "[10:37.980 --> 10:41.340]  Apo, ito po. Kapakita po mama ko ng presentation.\n",
            "[10:41.960 --> 10:50.300]  Tapos pagka na-present ko na po, that's the time that you may, para makikita nyo kung saan tayo pwedeng mag-collaborate.\n",
            "[10:50.300 --> 10:55.240]  Tapos kitinan natin itong sinir ni Ma'am Joanne ng mga points of collaboration.\n",
            "[10:55.540 --> 11:00.040]  Sige po. Ito yung program na ito pinapakita ngayon ni Kurt.\n",
            "[11:00.680 --> 11:05.260]  Advancing Computing Analytics, Big Data, and Artificial Intelligence in the Philippines.\n",
            "[11:05.920 --> 11:08.180]  Ito yung acronym ng ACABI.\n",
            "[11:08.400 --> 11:12.320]  So yung pangalan po ng program is ACABI.\n",
            "[11:12.640 --> 11:14.520]  Advancing Computing Analytics, Big Data.\n",
            "[11:14.520 --> 11:18.800]  Ito po ay part ng DOST Big Ticket Projects.\n",
            "[11:18.800 --> 11:21.640]  Na noong February ni-launch po ng DOST,\n",
            "[11:22.260 --> 11:27.220]  ang title ng program po na yun ay Elevate or Elevate PH.\n",
            "[11:27.700 --> 11:30.400]  Kaya sa Elevate, may number 8.\n",
            "[11:30.720 --> 11:35.140]  Kasi 8 research areas po yung pinondohan ng gobyerno.\n",
            "[11:35.700 --> 11:41.780]  Kasama po din yung geospatial analytics, circular economy, quantum computing.\n",
            "[11:41.780 --> 11:45.180]  Kasi yung baliwalo po yan. Kasama rin dun yung artificial intelligence.\n",
            "[11:45.940 --> 11:48.500]  Ngayon po, bali yung nag-open po ng ano.\n",
            "[11:48.800 --> 11:55.380]  Nang call for proposals, tapos under AI po, ito po yung na-approve.\n",
            "[11:56.440 --> 12:00.620]  Advancing Computing Analytics, Big Data, and Artificial Intelligence in the Philippines.\n",
            "[12:01.100 --> 12:02.140]  Sige, next slide, Kurt.\n",
            "[12:07.460 --> 12:10.180]  Ayan. Ay, wala na ba yung video?\n",
            "[12:11.120 --> 12:12.340]  Ayan yung video. Okay.\n",
            "[12:14.180 --> 12:17.180]  Manood po muna tayo ng mga projects po ng ASTI.\n",
            "[12:18.800 --> 12:29.000]  For over three decades, the Advanced Science and Technology Institute of the Department of Science and Technology,\n",
            "[12:29.000 --> 12:32.460]  or DOST-ASTI, has remained true to its slogan,\n",
            "[12:33.640 --> 12:34.980]  Moving Beyond Possibilities.\n",
            "[12:35.700 --> 12:43.820]  Established in 1987, DOST-ASTI pioneers research and development in information and communications technology and electronics.\n",
            "[12:44.520 --> 12:48.480]  Our technologies have helped transform sectors like agriculture, health,\n",
            "[12:48.800 --> 12:53.000]  disaster management, and education, especially in underserved communities.\n",
            "[12:53.800 --> 13:00.980]  From early innovations to present breakthroughs, DOST-ASTI has built a strong track record in developing low-cost,\n",
            "[13:01.420 --> 13:04.040]  scalable and easy-to-deploy technology solutions.\n",
            "[13:04.340 --> 13:09.580]  We have led national efforts in advanced research networks, weather and sensor systems,\n",
            "[13:10.020 --> 13:16.300]  mobile and wireless technologies, embedded systems, high-performance computing, space technology applications,\n",
            "[13:16.900 --> 13:18.040]  and today, emerging technologies.\n",
            "[13:18.800 --> 13:26.220]  Beyond developing technology, our mission is clear\n",
            "[13:26.220 --> 13:33.880]  To harness innovation that improves systems, streamlines processes, and opens opportunities for the everyday Filipino\n",
            "[13:33.880 --> 13:38.560]  From moving beyond possibilities, we are now creating them\n",
            "[13:40.560 --> 13:46.880]  This goal is driven by our four new flagship programs that define our institute's R&D priorities\n",
            "[13:46.880 --> 13:54.860]  ACCORD, or AI-Centered Computation Optimization and Responsible Research Development Program\n",
            "[13:54.860 --> 13:59.120]  Is the institute's flagship initiative for artificial intelligence in the country\n",
            "[13:59.120 --> 14:05.480]  The program aims to develop practical, high-impact AI solutions aligned with national priorities\n",
            "[14:05.700 --> 14:14.260]  It promotes ethical research, supports international collaboration, and builds the country's AI workforce through capacity-building efforts\n",
            "[14:14.260 --> 14:16.860]  A key initiative under ACCORD is\n",
            "[14:16.880 --> 14:23.180]  The Advancing Computing Analytics, Big Data, and Artificial Intelligence in the Philippines, or ACABI-PH\n",
            "[14:23.180 --> 14:29.540]  This initiative aims to accelerate AI research and adoption by addressing the biggest challenges\n",
            "[14:29.540 --> 14:36.540]  Such as limited AI infrastructure, fragmented R&D initiatives, and insufficient collaboration among stakeholders\n",
            "[14:36.540 --> 14:41.620]  Through this program, we will develop a centralized AI virtual hub\n",
            "[14:41.620 --> 14:46.700]  Wherein researchers, developers, and institutions can access shared datasets\n",
            "[14:46.880 --> 14:52.140]  Pre-trained machine learning models, tools, and resources to advance AI innovation\n",
            "[14:52.140 --> 14:58.740]  Ascent, or Advancement of Autonomous Systems, Wireless Connectivity, and Embedded Electronics\n",
            "[14:58.740 --> 15:05.320]  Our National Transformation Program focuses on autonomous systems, Internet of Things, and embedded electronics\n",
            "[15:05.320 --> 15:09.880]  That are key enablers of automation and smart operations across various sectors\n",
            "[15:09.880 --> 15:16.860]  Connect, or Collaborative Open Network Infrastructure for Emerging Technologies, Computing, and Connectivity Programs\n",
            "[15:16.880 --> 15:22.180]  Our National Transformation Program focuses on establishing and expanding large-scale network infrastructure\n",
            "[15:22.180 --> 15:27.560]  This program lays the groundwork for high-performance computing, connectivity, and shared platforms\n",
            "[15:27.560 --> 15:33.280]  That empower researchers and industries to collaborate and scale emerging technologies\n",
            "[15:33.280 --> 15:40.020]  And finally, Thrive, or Transforming High-Impact Research into Viable Everyday Solutions Program\n",
            "[15:40.020 --> 15:46.640]  Ensures that our technologies go beyond R&D and into real-world applications that respond to national needs\n",
            "[15:46.880 --> 15:52.420]  By bridging technology and people, DOST-ASTI is shaping an inclusive future for AI\n",
            "[15:52.420 --> 15:59.000]  One that empowers the Filipino people, strengthens local industries, and supports national development\n",
            "[15:59.000 --> 16:04.520]  As we face the future, DOST-ASTI continues to move beyond possibilities\n",
            "[16:04.520 --> 16:16.520]  Thank you for watching!\n",
            "[16:16.880 --> 16:46.860]  For more information, visit DOST-ASTI.com\n",
            "[16:46.880 --> 17:16.860]  Thank you for watching!\n",
            "[17:16.880 --> 17:46.860]  For more information, visit DOST-ASTI.com\n",
            "[17:46.880 --> 18:16.860]  For more information, visit DOST-ASTI.com\n",
            "[18:16.880 --> 18:46.860]  For more information, visit DOST-ASTI.com\n",
            "[18:46.880 --> 19:16.860]  For more information, visit DOST-ASTI.com\n",
            "[19:16.880 --> 19:46.860]  For more information, visit DOST-ASTI.com\n",
            "[19:46.880 --> 20:16.860]  For more information, visit DOST-ASTI.com\n",
            "[20:16.880 --> 20:46.860]  For more information, visit DOST-ASTI.com\n",
            "[20:46.880 --> 21:16.860]  For more information, visit DOST-ASTI.com\n",
            "[21:16.880 --> 21:46.740]  For more information, visit DOST-ASTI.com\n",
            "[21:46.740 --> 21:46.860]  For more information, visit DOST-ASTI.com\n",
            "[21:46.860 --> 21:46.880]  For more information, visit DOST-ASTI.com\n",
            "[21:46.880 --> 22:16.860]  For more information, visit DOST-ASTI.com\n",
            "[22:16.880 --> 22:46.860]  For more information, visit DOST-ASTI.com\n",
            "[22:46.880 --> 23:16.860]  For more information, visit DOST-ASTI.com\n",
            "[23:16.880 --> 23:46.860]  For more information, visit DOST-ASTI.com\n",
            "[23:46.880 --> 24:16.860]  For more information, visit DOST-ASTI.com\n",
            "[24:16.880 --> 24:46.860]  For more information, visit DOST-ASTI.com\n",
            "[24:46.880 --> 25:16.720]  For more information, visit DOST-ASTI.com\n",
            "[25:16.720 --> 25:16.840]  For more information, visit DOST-ASTI.com\n",
            "[25:16.840 --> 25:16.860]  For more information, visit DOST-ASTI.com\n",
            "[25:16.880 --> 25:28.740]  Ito po yung Sky Pinas program kung saan yung ASTI ALAM at saka yung ALAM LSI ay ito po yung project under this program.\n",
            "[25:28.740 --> 25:37.600]  So ang idea po nito, since marami po kasi tayong mga remote sensed images or remote sensed data like satellite images dito sa ASTI,\n",
            "[25:37.600 --> 25:48.280]  naisipan po ng program leader na gamitan po ng AI yung mag-develop ng mga AI model based on these satellite images for various applications.\n",
            "[25:49.040 --> 25:59.360]  So ito po, using computer vision din po, nakapag-develop po kami ng mga AI models para sa iba't ibang application like for example applications for agriculture,\n",
            "[25:59.360 --> 26:03.180]  for urban planning, for disaster risk management.\n",
            "[26:03.720 --> 26:07.500]  Tapos yung mga models po na yun ay inipon namin at nilagay po namin.\n",
            "[26:07.600 --> 26:08.580]  So isang repository.\n",
            "[26:09.080 --> 26:11.220]  Ang tawag po namin dun ay Dynamer.\n",
            "[26:12.700 --> 26:13.940]  Next slide, Kurt.\n",
            "[26:17.300 --> 26:18.940]  Ito naman yung itanong.\n",
            "[26:19.640 --> 26:23.460]  Itanong, ito yung parang chat GPT, quote unquote, no?\n",
            "[26:24.340 --> 26:26.100]  Medyo related sa chat GPT.\n",
            "[26:26.100 --> 26:33.480]  So the idea, this is a web application that answers questions in Tagalog, English, or Taglish,\n",
            "[26:33.660 --> 26:37.420]  using information from organization-maintained.\n",
            "[26:37.600 --> 26:38.520]  databases.\n",
            "[26:38.520 --> 26:42.600]  So kung meron po ang isang organization na mga databases or datastore,\n",
            "[26:42.900 --> 26:47.800]  bale, we are providing them a natural language interface to access them.\n",
            "[26:47.800 --> 26:53.300]  Like, magtatanong ka lang po ng questions in language you're comfortable with,\n",
            "[26:53.780 --> 26:59.800]  and then hindi mo na kailangan mag-develop po ng information system para mag-connect dun sa database na yun.\n",
            "[27:00.100 --> 27:04.280]  Bale, yung itanong na lang po ang magpo-provide po sa inyo ng answer.\n",
            "[27:04.280 --> 27:07.040]  Para siyang, yun, parang nga pong chat GPT ito.\n",
            "[27:07.600 --> 27:13.120]  Pero mas, ah, mas attuned sa mga, sa Filipino language.\n",
            "[27:14.040 --> 27:15.040]  Next slide.\n",
            "[27:17.520 --> 27:18.880]  Ayan yung gulay.\n",
            "[27:19.000 --> 27:24.300]  This is a project, ah, ah, funded by ASTI.\n",
            "[27:24.580 --> 27:28.700]  Ah, it's an AI and IoT-assisted small-scale plant growing system.\n",
            "[27:29.220 --> 27:34.580]  So parang ito po, may, may dineveloped kaming parang isang, ah, box po na gano'n.\n",
            "[27:34.580 --> 27:36.580]  Tapos may mga plants doon, may mga naka...\n",
            "[27:37.600 --> 27:43.620]  install na sensor, tapos yung, yung sensor na yun, ah, nagko-collect ng data,\n",
            "[27:44.140 --> 27:50.080]  and then doon sa data, you can do analytics, you can actually, ah, study how plant grows,\n",
            "[27:50.200 --> 27:57.620]  depende doon sa levels ng mga parameters ng, ano, like may sensor dyan about, ah, pH,\n",
            "[27:58.620 --> 28:06.960]  and, ah, so, ah, soil pH, level of oxygen, yung water level, and so on, ah, temperature, humidity, and so on, and so forth.\n",
            "[28:07.400 --> 28:07.580]  Tapos, ah, yung, ah, yung, ah, yung, ah, yung, ah, yung, ah, yung, ah, yung, ah, yung, ah, yung, ah, yung, ah,\n",
            "[28:07.600 --> 28:08.840]  tapos meron po yung analytics.\n",
            "[28:10.300 --> 28:11.180]  Next slide.\n",
            "[28:15.180 --> 28:28.180]  Iyon, SAC feeder naman, ah, this one uses computer vision and AI po para maging efficient yung pagpapakain po ng mga feeds doon sa mga, ah, aqua farm, no?\n",
            "[28:28.180 --> 28:30.400]  Yung mga, yung, yung mga shrimp to.\n",
            "[28:30.840 --> 28:37.580]  Balit, they have developed this, ano, this system para wala, ma-minimize yung waste.\n",
            "[28:37.580 --> 28:48.460]  To test the stage doon sa, ano, sa, sa mga, ah, fish po para at least, ah, maging mas viable po yung, ano, aqua farming in the Philippines.\n",
            "[28:49.060 --> 28:49.740]  Next slide.\n",
            "[28:52.880 --> 29:00.440]  And then CERB-I, identification of regions of interest in cervical pre-cancer and cancer screening images using computer vision.\n",
            "[29:00.760 --> 29:07.460]  This one naman po, ah, you use AI and computer vision po, ah, to identify yung mga...\n",
            "[29:07.580 --> 29:25.560]  Yung mga lesions, yung mga tumors doon po sa yung mga pre-cancer and cancer screening. So we are partnering with Cervic in this initiative. So this is one of the AI projects po ng ASTI.\n",
            "[29:25.560 --> 29:55.540]  Next slide.\n",
            "[29:55.560 --> 30:10.700]  Weather forecasting using AI. So in this case, we subscribe to the technology from California. Meron pong ano, meron pong ang poprovide ng technology from US, US-based technology.\n",
            "[30:12.320 --> 30:25.480]  Tapos yun po, initially, iaaralin po namin yung technology na yun so that later on, we will be developing our own AI-powered weather forecasting technique po.\n",
            "[30:25.560 --> 30:27.360]  Dito sa ASTI.\n",
            "[30:27.860 --> 30:28.540]  Next slide.\n",
            "[30:31.680 --> 30:39.900]  Yan, V2X. I think this is the last slide before yung pinaka, ano talaga, before yung Akabay.\n",
            "[30:40.300 --> 30:45.780]  V2X or itong initiatives for road safety, smart traffic, electronic enforcer on the roads.\n",
            "[30:46.420 --> 30:50.700]  This one, it uses vehicle to everything. Mga sensors din po ito.\n",
            "[30:50.700 --> 30:54.240]  For seamless communication between vehicles and road users.\n",
            "[30:54.400 --> 30:55.540]  Improving road safety.\n",
            "[30:55.560 --> 30:57.180]  for everyone.\n",
            "[30:57.620 --> 30:59.420]  So, makita nyo, very diverse\n",
            "[30:59.420 --> 31:01.480]  po yung applications ng AI\n",
            "[31:01.480 --> 31:03.380]  from the different\n",
            "[31:03.380 --> 31:04.920]  projects that we are actually\n",
            "[31:04.920 --> 31:06.560]  implementing.\n",
            "[31:07.380 --> 31:08.480]  So, next slide, Kurt.\n",
            "[31:10.980 --> 31:13.120]  Ito yung sinasabi ko po kanina na\n",
            "[31:13.120 --> 31:15.180]  elevate\n",
            "[31:15.180 --> 31:16.200]  na program.\n",
            "[31:17.400 --> 31:19.440]  Yung DOST's Big Ticket\n",
            "[31:19.440 --> 31:21.360]  R&D programs. Meron dyan\n",
            "[31:21.360 --> 31:23.400]  development of AR virtual hub,\n",
            "[31:24.100 --> 31:25.340]  geospatial analytics\n",
            "[31:25.340 --> 31:26.920]  solutions, quantum computing,\n",
            "[31:27.220 --> 31:28.540]  industry 4.0,\n",
            "[31:29.300 --> 31:31.760]  circular economy, smart agriculture,\n",
            "[31:32.520 --> 31:33.380]  smart technologies,\n",
            "[31:33.760 --> 31:35.060]  and biologics in pharma.\n",
            "[31:35.640 --> 31:37.060]  So, kaya siya tinag na elevate\n",
            "[31:37.060 --> 31:38.720]  na program. And,\n",
            "[31:38.820 --> 31:41.520]  under this program\n",
            "[31:41.520 --> 31:41.800]  po,\n",
            "[31:42.220 --> 31:45.520]  dun sa AI development ng AI virtual\n",
            "[31:45.520 --> 31:47.440]  hub, I would like to introduce\n",
            "[31:47.440 --> 31:49.480]  yung Akabay. Next slide, Kurt.\n",
            "[31:50.980 --> 31:51.300]  So, yan,\n",
            "[31:51.360 --> 31:53.280]  Akabay. Ito yung\n",
            "[31:53.280 --> 31:55.200]  program under the AI.\n",
            "[31:55.340 --> 31:57.040]  Yung iba pong ano,\n",
            "[31:57.460 --> 31:59.300]  meron din pong kanya-kanya mga programs\n",
            "[31:59.300 --> 32:01.420]  yun. So, I'm gonna zero in on the\n",
            "[32:01.420 --> 32:03.580]  AI or Artificial Intelligence\n",
            "[32:03.580 --> 32:05.320]  Research Trust ng DOST\n",
            "[32:05.320 --> 32:07.760]  at saka itong Akabay PH.\n",
            "[32:08.220 --> 32:09.020]  Next slide, Kurt.\n",
            "[32:11.440 --> 32:13.120]  So, dito ang idea is, yun,\n",
            "[32:13.220 --> 32:15.020]  para ma-harmonize yung mga\n",
            "[32:15.020 --> 32:17.440]  AI initiatives ng DOST. As you can\n",
            "[32:17.440 --> 32:18.780]  see, sabi ko nga kanina may\n",
            "[32:18.780 --> 32:21.560]  diverse. Akabay PH\n",
            "[32:21.560 --> 32:23.180]  serves as a catalyst empowering\n",
            "[32:23.180 --> 32:25.080]  Filipino researchers, businesses,\n",
            "[32:25.340 --> 32:27.140]  and communities to leverage AI\n",
            "[32:27.140 --> 32:28.940]  in addressing real-world challenges.\n",
            "[32:29.800 --> 32:31.260]  So, nakita nyo kanina na\n",
            "[32:31.260 --> 32:33.460]  very costly yung\n",
            "[32:33.460 --> 32:35.420]  development ng\n",
            "[32:35.420 --> 32:37.440]  AI. So, we wanted to\n",
            "[32:37.440 --> 32:39.500]  leverage on economies of scale\n",
            "[32:39.500 --> 32:41.300]  to democratize AI\n",
            "[32:41.300 --> 32:43.360]  access for Filipinos and\n",
            "[32:43.360 --> 32:45.440]  MSMEs at saka yung\n",
            "[32:45.440 --> 32:47.420]  mga marginalized communities po.\n",
            "[32:47.820 --> 32:49.620]  Kasi, para, kumbaga, we wanted\n",
            "[32:49.620 --> 32:51.340]  to somehow\n",
            "[32:51.340 --> 32:53.760]  yung\n",
            "[32:53.760 --> 32:55.300]  malesend ba yung\n",
            "[32:55.300 --> 32:56.900]  digital divide kasi\n",
            "[32:56.900 --> 32:59.600]  kita naman natin globally\n",
            "[32:59.600 --> 33:01.880]  napakalaking\n",
            "[33:01.880 --> 33:03.460]  disadvantage nung mga\n",
            "[33:03.460 --> 33:06.200]  haves and have, yung merong\n",
            "[33:06.200 --> 33:07.720]  capability sa\n",
            "[33:07.720 --> 33:09.620]  artificial intelligence like US\n",
            "[33:09.620 --> 33:11.740]  and China. We cannot really compete.\n",
            "[33:12.340 --> 33:13.760]  So, what we have to\n",
            "[33:13.760 --> 33:15.640]  do is to leverage\n",
            "[33:15.640 --> 33:17.740]  on economies of scale, we would\n",
            "[33:17.740 --> 33:19.660]  kumbaga\n",
            "[33:19.660 --> 33:20.940]  pull our resources\n",
            "[33:20.940 --> 33:23.560]  and also\n",
            "[33:23.560 --> 33:25.280]  reuse kung ano pa yung mga\n",
            "[33:25.300 --> 33:27.880]  available data sets, whatever we have\n",
            "[33:27.880 --> 33:29.700]  to make sure na\n",
            "[33:29.700 --> 33:31.980]  ma-democratize\n",
            "[33:31.980 --> 33:33.640]  natin itong paggamit ng\n",
            "[33:33.640 --> 33:36.100]  artificial intelligence.\n",
            "[33:36.340 --> 33:37.860]  So, that is why yung mga\n",
            "[33:37.860 --> 33:39.980]  projects kanina na nabanggit, they are\n",
            "[33:39.980 --> 33:42.000]  very important, lalo na\n",
            "[33:42.000 --> 33:43.860]  yung core and\n",
            "[33:43.860 --> 33:45.820]  yung pregenet kasi yun yung\n",
            "[33:45.820 --> 33:47.940]  mga infra\n",
            "[33:47.940 --> 33:50.140]  na kakailangan natin para makapag-develop\n",
            "[33:50.140 --> 33:50.960]  po tayo ng\n",
            "[33:50.960 --> 33:53.920]  mga AI for everyone.\n",
            "[33:54.600 --> 33:55.220]  So, next slide.\n",
            "[33:55.300 --> 33:57.300]  Ito.\n",
            "[33:58.540 --> 34:00.000]  Makikita natin dito\n",
            "[34:00.000 --> 34:00.620]  yung ano,\n",
            "[34:01.520 --> 34:02.980]  ayan, yung DOS\n",
            "[34:02.980 --> 34:05.000]  ni Naira, yung Gates po, ito naman yung isang\n",
            "[34:05.000 --> 34:06.080]  program sa\n",
            "[34:06.080 --> 34:08.620]  makikita nyo itong Gates\n",
            "[34:08.620 --> 34:10.920]  project.\n",
            "[34:11.960 --> 34:12.860]  Yan naman yung\n",
            "[34:12.860 --> 34:14.340]  for Geo Special Analytics.\n",
            "[34:15.800 --> 34:16.840]  Okay, ito po yung ano,\n",
            "[34:17.240 --> 34:18.940]  yung plan, no, to\n",
            "[34:18.940 --> 34:20.540]  expand yung aming\n",
            "[34:20.540 --> 34:23.020]  procurement ng mga high\n",
            "[34:23.020 --> 34:25.100]  performance computing. Kasi nga po\n",
            "[34:25.100 --> 34:25.600]  napaka\n",
            "[34:25.600 --> 34:29.000]  essential\n",
            "[34:29.000 --> 34:31.240]  itong infrastructure\n",
            "[34:31.240 --> 34:33.320]  na ito in AI development.\n",
            "[34:34.120 --> 34:34.700]  Currently,\n",
            "[34:35.160 --> 34:38.120]  meron lang kaming 127.7\n",
            "[34:38.120 --> 34:39.320]  teraflaps, no?\n",
            "[34:40.100 --> 34:42.280]  Ang aim is,\n",
            "[34:42.520 --> 34:43.920]  umabot tayo ng\n",
            "[34:43.920 --> 34:46.180]  10 petaflaps sana,\n",
            "[34:46.760 --> 34:46.960]  no?\n",
            "[34:49.160 --> 34:50.980]  We have to achieve that\n",
            "[34:50.980 --> 34:53.040]  at least 10 petaflaps, HPC\n",
            "[34:53.040 --> 34:54.980]  capacity, and expand global connectivity.\n",
            "[34:55.600 --> 34:57.020]  Siguro, bigyan ko lang\n",
            "[34:57.020 --> 34:57.960]  ng context.\n",
            "[34:59.700 --> 35:00.200]  Yung\n",
            "[35:00.200 --> 35:03.060]  sabi dun sa isang article ng Elon Musk,\n",
            "[35:03.180 --> 35:04.600]  meron siyang ibibuild na\n",
            "[35:04.600 --> 35:06.960]  Colossus, yung XAI\n",
            "[35:06.960 --> 35:07.980]  ni Elon Musk.\n",
            "[35:08.700 --> 35:10.800]  100,000 na\n",
            "[35:10.800 --> 35:13.380]  A100s.\n",
            "[35:13.860 --> 35:14.540]  Yung ano nga,\n",
            "[35:14.580 --> 35:16.680]  100,000. So, na-imagine ko,\n",
            "[35:16.800 --> 35:18.720]  isang company lang, isang big tech\n",
            "[35:18.720 --> 35:20.360]  company lang yun sa US.\n",
            "[35:21.040 --> 35:22.800]  Eh, ang Philippines, we barely\n",
            "[35:22.800 --> 35:24.800]  have 10 A100s.\n",
            "[35:25.100 --> 35:27.160]  At least dun sa ano, no?\n",
            "[35:27.260 --> 35:27.560]  Pero,\n",
            "[35:28.360 --> 35:30.080]  yun po yun, yun yung\n",
            "[35:30.080 --> 35:32.780]  inaano ko lang. So, we really have to\n",
            "[35:32.780 --> 35:34.840]  be parang, in a way,\n",
            "[35:34.900 --> 35:36.260]  strategic. Kaya\n",
            "[35:36.260 --> 35:38.700]  yesterday, I asked yung Australian\n",
            "[35:38.700 --> 35:40.780]  guest, no?\n",
            "[35:41.060 --> 35:42.800]  Na nagpunta sa\n",
            "[35:42.800 --> 35:44.460]  DOST, ano yung\n",
            "[35:44.460 --> 35:46.040]  pwede nilang i-advise?\n",
            "[35:46.820 --> 35:48.080]  Ang sagot nila is,\n",
            "[35:48.780 --> 35:50.720]  kasi we cannot really compete with\n",
            "[35:50.720 --> 35:52.840]  big tech giants like\n",
            "[35:52.840 --> 35:54.660]  Google,\n",
            "[35:54.660 --> 35:54.900]  Google,\n",
            "[35:55.100 --> 35:56.820]  and OpenAI, yung\n",
            "[35:56.820 --> 35:58.160]  XAI ni Elon Musk,\n",
            "[35:58.820 --> 36:00.720]  with China and the US.\n",
            "[36:02.560 --> 36:03.160]  Siguro,\n",
            "[36:03.400 --> 36:05.000]  ano lang, ang masasabi-sabi niya\n",
            "[36:05.000 --> 36:06.920]  is invest in the young minds,\n",
            "[36:07.100 --> 36:08.920]  no? Kasi ang lamang natin\n",
            "[36:08.920 --> 36:10.880]  dito sa mga ano ito, yung median\n",
            "[36:10.880 --> 36:12.860]  age ng ating population, maraming\n",
            "[36:12.860 --> 36:14.360]  ng taay mga bata na, no? So,\n",
            "[36:15.120 --> 36:16.820]  saka maraming mga matatalinong Filipino.\n",
            "[36:17.500 --> 36:18.780]  So, yung isa sa, yung siguro\n",
            "[36:18.780 --> 36:20.820]  kailangan natin i-leverage,\n",
            "[36:20.960 --> 36:22.860]  no? Mag-focus tayo dun sa\n",
            "[36:22.860 --> 36:24.900]  algorithms and yun sa\n",
            "[36:25.100 --> 36:26.860]  research. Baka may\n",
            "[36:26.860 --> 36:28.680]  better way of doing kahit\n",
            "[36:28.680 --> 36:30.740]  yung mga, ano na, mga\n",
            "[36:30.740 --> 36:32.980]  research na yun. So, that's one thing\n",
            "[36:32.980 --> 36:34.680]  na ano, of course, yung ating\n",
            "[36:34.680 --> 36:36.820]  sovereign data rin. Sovereign\n",
            "[36:36.820 --> 36:37.960]  data and\n",
            "[36:37.960 --> 36:40.860]  trying\n",
            "[36:40.860 --> 36:42.340]  to find my notes. I\n",
            "[36:42.340 --> 36:44.540]  took notes yesterday kasi.\n",
            "[36:45.320 --> 36:46.040]  Nung, ano,\n",
            "[36:46.280 --> 36:49.080]  invest in young minds, leverage sovereign data,\n",
            "[36:49.580 --> 36:51.180]  and focus on an application\n",
            "[36:51.180 --> 36:52.560]  area. Ayun.\n",
            "[36:53.280 --> 36:54.680]  Yun yung siguro pwede natin.\n",
            "[36:55.100 --> 36:57.240]  It's, pagka, if we're\n",
            "[36:57.240 --> 36:59.300]  trying to, parang, build what they have\n",
            "[36:59.300 --> 37:01.500]  built, hindi pwede. Hindi natin kakayanin\n",
            "[37:01.500 --> 37:03.520]  yung, ano. It would take a significant\n",
            "[37:03.520 --> 37:04.840]  amount of our GDP\n",
            "[37:04.840 --> 37:07.220]  para makapag-build lang ng, ano, and\n",
            "[37:07.220 --> 37:09.360]  pati yung, ano,\n",
            "[37:09.440 --> 37:11.340]  resources na kailangan. Saka it took\n",
            "[37:11.340 --> 37:13.180]  them time. Although yung\n",
            "[37:13.180 --> 37:15.260]  na-prove ng DPSIC na they can\n",
            "[37:15.260 --> 37:17.200]  build something, parang, more\n",
            "[37:17.200 --> 37:18.880]  efficiently, but still,\n",
            "[37:19.560 --> 37:21.300]  I don't think that's the way to\n",
            "[37:21.300 --> 37:23.380]  go. Anyway, so, yun,\n",
            "[37:23.460 --> 37:24.040]  ito yung, ano,\n",
            "[37:25.100 --> 37:27.200]  plan. Next slide, Kurt.\n",
            "[37:30.780 --> 37:31.260]  Yan.\n",
            "[37:31.720 --> 37:33.520]  So, ito, ito po, ipapakita ko sa inyo.\n",
            "[37:33.620 --> 37:34.660]  This is very important.\n",
            "[37:35.460 --> 37:37.680]  Nag-take stock\n",
            "[37:37.680 --> 37:39.600]  kami. We assessed kung\n",
            "[37:39.600 --> 37:40.180]  ano yung, ano.\n",
            "[37:41.400 --> 37:43.760]  Meron kami mga nodes at may mga high-performance\n",
            "[37:43.760 --> 37:45.720]  computing. Makikita nyo dito sa\n",
            "[37:45.720 --> 37:47.520]  kanan, yung map ng Philippines.\n",
            "[37:48.460 --> 37:49.560]  Ito yung may mga\n",
            "[37:49.560 --> 37:51.940]  na-donate-an ng V100\n",
            "[37:51.940 --> 37:53.680]  na HPC.\n",
            "[37:53.900 --> 37:55.080]  Tapos makikita nyo, isang V100,\n",
            "[37:55.100 --> 37:58.080]  ang capacity niya\n",
            "[37:58.080 --> 37:59.600]  is yung 7 teraflops.\n",
            "[38:01.140 --> 38:02.060]  So, yan. So, tinina\n",
            "[38:02.060 --> 38:03.480]  namin paano ba. Kasi, ang\n",
            "[38:03.480 --> 38:05.900]  idea po kasi, sabi ni, ano,\n",
            "[38:06.020 --> 38:07.020]  sabi ni PBBM,\n",
            "[38:08.120 --> 38:09.980]  regarding doon sa development of\n",
            "[38:09.980 --> 38:11.580]  AI virtual hub na under the\n",
            "[38:11.580 --> 38:13.580]  Akabay program, huwag kayong gumawa ng isang\n",
            "[38:13.580 --> 38:16.160]  center lang. Dapat mag-redown\n",
            "[38:16.160 --> 38:17.740]  dyan sa region. So,\n",
            "[38:17.740 --> 38:19.520]  we, hindi, hindi, ang\n",
            "[38:19.520 --> 38:21.580]  idea po is, hindi lang, kunyari sa\n",
            "[38:21.580 --> 38:23.580]  ASTI lang, what we wanted\n",
            "[38:23.580 --> 38:24.940]  to do is to,\n",
            "[38:25.100 --> 38:27.000]  develop or empower\n",
            "[38:27.000 --> 38:29.180]  yung mga communities in the region\n",
            "[38:29.180 --> 38:31.000]  to adopt artificial\n",
            "[38:31.000 --> 38:33.620]  intelligence. So, paano ba yun?\n",
            "[38:33.740 --> 38:35.280]  Paano namin ma-achieve yun?\n",
            "[38:35.900 --> 38:37.480]  Ayun po, we wanted to partner\n",
            "[38:37.480 --> 38:39.500]  po, kaya nabawa sa UPLB, and also\n",
            "[38:39.500 --> 38:41.260]  ano, we will partner\n",
            "[38:41.260 --> 38:43.140]  with you. In terms of what?\n",
            "[38:43.540 --> 38:45.300]  In terms of capacity building,\n",
            "[38:45.860 --> 38:47.360]  in terms, yun nga, yung sa internship,\n",
            "[38:47.640 --> 38:48.980]  in terms of\n",
            "[38:48.980 --> 38:51.080]  capacity building on AI,\n",
            "[38:51.080 --> 38:53.080]  also in terms of\n",
            "[38:53.080 --> 38:54.460]  grid computing.\n",
            "[38:55.100 --> 38:56.740]  Or federated learning.\n",
            "[38:57.280 --> 38:59.100]  So, maraming mga areas\n",
            "[38:59.100 --> 39:01.060]  of collaborations po. Pero yun po yung\n",
            "[39:01.060 --> 39:03.720]  idea, ma-empower\n",
            "[39:03.720 --> 39:04.900]  namin yung mga\n",
            "[39:04.900 --> 39:09.400]  communities in the region, hindi lang\n",
            "[39:09.400 --> 39:11.360]  doon sa mga urban centers\n",
            "[39:11.360 --> 39:12.920]  here in the Philippines.\n",
            "[39:13.680 --> 39:15.460]  So, in terms of infrastructure,\n",
            "[39:15.460 --> 39:17.220]  kung kaya po namin, ganon.\n",
            "[39:17.580 --> 39:19.700]  So, that's why we wanted to beef up our\n",
            "[39:19.700 --> 39:21.300]  infrastructure as well.\n",
            "[39:21.400 --> 39:23.660]  Para at least, makatulong\n",
            "[39:23.660 --> 39:25.080]  kami doon sa mga nangangailangan.\n",
            "[39:25.100 --> 39:27.260]  Makapag-develop din po sila ng AI.\n",
            "[39:28.040 --> 39:29.260]  So, yun po yung idea.\n",
            "[39:30.080 --> 39:30.660]  Next slide.\n",
            "[39:33.080 --> 39:33.440]  Ayun.\n",
            "[39:33.920 --> 39:35.020]  Under the ACABI\n",
            "[39:35.020 --> 39:37.240]  program, ang main project\n",
            "[39:37.240 --> 39:38.780]  po dito yung DOST Naira,\n",
            "[39:38.880 --> 39:41.400]  Nexus for AI Research and Applications.\n",
            "[39:41.960 --> 39:43.560]  Ang under Naira po,\n",
            "[39:44.260 --> 39:45.080]  eto na yung\n",
            "[39:45.080 --> 39:46.920]  continuation ng ALAM, kung\n",
            "[39:46.920 --> 39:48.960]  tutusin, kasi dito\n",
            "[39:48.960 --> 39:50.400]  merong platform.\n",
            "[39:51.060 --> 39:52.760]  Apos, yung platform na yun,\n",
            "[39:53.100 --> 39:54.760]  it's going to be a repository.\n",
            "[39:54.760 --> 39:56.660]  of models and has\n",
            "[39:56.660 --> 39:58.540]  some tools that can enable\n",
            "[39:58.540 --> 40:00.780]  adapters\n",
            "[40:00.780 --> 40:02.740]  of AI to easily\n",
            "[40:02.740 --> 40:05.080]  create their own applications.\n",
            "[40:05.940 --> 40:06.440]  So, yun po, parang\n",
            "[40:06.440 --> 40:08.220]  AI as a service po siya.\n",
            "[40:09.620 --> 40:10.620]  Ito yung\n",
            "[40:10.620 --> 40:12.880]  DOST Naira.\n",
            "[40:13.600 --> 40:14.960]  Aside from\n",
            "[40:14.960 --> 40:16.760]  consultancy and services\n",
            "[40:17.660 --> 40:18.900]  and capacity building,\n",
            "[40:19.300 --> 40:20.600]  tapos collaborative AI\n",
            "[40:20.600 --> 40:22.420]  R&D, and providing\n",
            "[40:22.420 --> 40:24.740]  of the necessary infrastructure.\n",
            "[40:24.740 --> 40:26.640]  Ito po yung magiging\n",
            "[40:26.640 --> 40:27.460]  parang pinaka\n",
            "[40:27.460 --> 40:30.780]  focal point po nung sinasabi kong\n",
            "[40:30.780 --> 40:32.160]  empowerment ng mga\n",
            "[40:32.160 --> 40:34.760]  local communities\n",
            "[40:34.760 --> 40:36.800]  in terms of AI adoption.\n",
            "[40:37.440 --> 40:38.260]  Next slide.\n",
            "[40:41.700 --> 40:42.740]  Ayun. From research\n",
            "[40:42.740 --> 40:44.820]  to real-world impact, accelerating AI adoption\n",
            "[40:44.820 --> 40:46.260]  with AI as a service.\n",
            "[40:46.660 --> 40:48.640]  Para po siyang, i-expand namin yung\n",
            "[40:48.640 --> 40:50.440]  currently na-develop namin, DIMER,\n",
            "[40:50.620 --> 40:52.420]  yung repository ng AI models and\n",
            "[40:52.420 --> 40:54.720]  data sets na magkakaroon na po,\n",
            "[40:54.740 --> 40:56.800]  siya ng mga tools or mga\n",
            "[40:56.800 --> 40:58.540]  APIs para at least\n",
            "[40:58.540 --> 41:00.940]  makapag-connect sa mga application\n",
            "[41:00.940 --> 41:02.740]  o makapag-provide\n",
            "[41:03.860 --> 41:04.320]  ng mga\n",
            "[41:04.320 --> 41:06.580]  AI applications. Kaya siya tinawag ng\n",
            "[41:06.580 --> 41:09.200]  Nexus of AI Research and Applications.\n",
            "[41:10.140 --> 41:10.920]  Next slide, Kurt.\n",
            "[41:15.360 --> 41:16.420]  Next slide.\n",
            "[41:21.460 --> 41:22.700]  Ayun. Yan.\n",
            "[41:22.700 --> 41:24.700]  Consultancy and services and capacity\n",
            "[41:24.740 --> 41:26.940]  building. So, pwede natin po\n",
            "[41:26.940 --> 41:28.960]  itong gawin. Alimbawa, kapag meron\n",
            "[41:28.960 --> 41:30.020]  na po kinaisip na\n",
            "[41:30.020 --> 41:32.560]  specific application or specific\n",
            "[41:32.560 --> 41:34.360]  projects that you'd like to\n",
            "[41:34.360 --> 41:35.060]  ano,\n",
            "[41:36.400 --> 41:38.680]  that like to use AI\n",
            "[41:38.680 --> 41:40.680]  as a solution po doon sa pain points\n",
            "[41:40.680 --> 41:43.100]  na yun, pwede kami mag-provide\n",
            "[41:43.100 --> 41:45.080]  ng, yan, capacity building efforts.\n",
            "[41:45.280 --> 41:45.900]  Next slide.\n",
            "[41:49.420 --> 41:50.560]  Tapos, ayun po.\n",
            "[41:50.840 --> 41:52.120]  Aside from that,\n",
            "[41:52.620 --> 41:54.720]  from the get-go, we would like\n",
            "[41:54.720 --> 41:56.760]  to emphasize on the\n",
            "[41:56.760 --> 42:00.000]  governance and\n",
            "[42:00.000 --> 42:02.980]  ethics of artificial intelligence.\n",
            "[42:03.120 --> 42:05.020]  We've been attending several\n",
            "[42:05.020 --> 42:06.520]  fora and\n",
            "[42:06.520 --> 42:09.040]  capacity building in this regard\n",
            "[42:09.040 --> 42:10.900]  po para at least maging responsible\n",
            "[42:10.900 --> 42:12.480]  po yung aming development\n",
            "[42:12.480 --> 42:14.680]  ng mga AI systems.\n",
            "[42:15.400 --> 42:16.080]  Next slide.\n",
            "[42:19.200 --> 42:21.040]  Ayun. This is the timeline.\n",
            "[42:21.940 --> 42:22.880]  So, anoy ko lang po,\n",
            "[42:22.880 --> 42:24.480]  bale, ang program po is,\n",
            "[42:24.720 --> 42:26.300]  Akabay, and under that program\n",
            "[42:26.300 --> 42:28.740]  is yung Naira, Nexus for\n",
            "[42:28.740 --> 42:30.360]  AI Research and Applications.\n",
            "[42:30.860 --> 42:32.720]  Actually, sa Naira, may mga initial\n",
            "[42:32.720 --> 42:34.300]  data sets, may mga initial\n",
            "[42:34.300 --> 42:36.020]  use cases na po kami.\n",
            "[42:36.520 --> 42:38.380]  Like yung sa 3D reconstruction,\n",
            "[42:39.120 --> 42:40.080]  pati yung sa\n",
            "[42:40.080 --> 42:42.700]  traffic,\n",
            "[42:43.280 --> 42:43.940]  and then,\n",
            "[42:44.440 --> 42:46.660]  aside from that, we also have projects\n",
            "[42:46.660 --> 42:48.060]  under the Akabay, yung\n",
            "[42:48.060 --> 42:50.560]  with FNRI, yung Philippine\n",
            "[42:50.560 --> 42:51.960]  Food Composition Tables.\n",
            "[42:52.500 --> 42:54.360]  Magkakaroon po siya ng parang chatbot,\n",
            "[42:54.360 --> 42:55.700]  and then, yung\n",
            "[42:55.700 --> 42:58.760]  PPRI naman, yung textile research.\n",
            "[42:59.860 --> 43:01.040]  We're gonna use\n",
            "[43:01.040 --> 43:02.480]  AI and computer vision\n",
            "[43:02.480 --> 43:04.200]  to automatically identify\n",
            "[43:04.200 --> 43:05.640]  kung anong klaseng fiber yun.\n",
            "[43:06.060 --> 43:08.600]  Ganon din po sa FPRDI, sa Food Product\n",
            "[43:08.600 --> 43:10.500]  Research and Development Institute,\n",
            "[43:10.860 --> 43:12.360]  meron din pong\n",
            "[43:13.140 --> 43:14.540]  use case ang Naira doon.\n",
            "[43:14.880 --> 43:16.280]  Yun naman pong wood identification\n",
            "[43:16.280 --> 43:18.240]  using AI. Now, automatically,\n",
            "[43:18.920 --> 43:20.440]  kapag ka, let's say, may\n",
            "[43:20.440 --> 43:22.440]  naputol na puno, pipicturan\n",
            "[43:22.440 --> 43:24.340]  lang doon, may report ka,\n",
            "[43:24.360 --> 43:26.660]  illegal ito. This is a protected\n",
            "[43:26.660 --> 43:28.440]  parang ganon. Makikita\n",
            "[43:28.440 --> 43:30.160]  kagad kung anong\n",
            "[43:30.160 --> 43:32.580]  species ng puno yung naputol.\n",
            "[43:32.780 --> 43:34.140]  Parang ganon. Yun yung\n",
            "[43:34.140 --> 43:36.500]  para mapabilis po kagad yung enforcement\n",
            "[43:36.500 --> 43:37.520]  ng mga batas.\n",
            "[43:38.620 --> 43:40.420]  So, those are some of the initial use\n",
            "[43:40.420 --> 43:42.320]  cases po ng Naira. But,\n",
            "[43:42.400 --> 43:44.060]  we can extend that. Yun naman po yung\n",
            "[43:44.060 --> 43:45.720]  mas maganda po sana kung mas maraming\n",
            "[43:45.720 --> 43:48.260]  use cases, mas maraming matulungan po\n",
            "[43:48.260 --> 43:50.300]  itong project na ito. Kung meron po\n",
            "[43:50.300 --> 43:52.400]  kayo naisip na, let's say, project\n",
            "[43:52.400 --> 43:54.360]  ninyo ng existing, we can\n",
            "[43:54.360 --> 43:56.380]  probably partner with para\n",
            "[43:56.380 --> 43:58.100]  po doon sa ano.\n",
            "[43:59.220 --> 44:00.400]  Yun po siguro yung mga pwede\n",
            "[44:00.400 --> 44:02.300]  nating pag-usapan later.\n",
            "[44:02.900 --> 44:04.660]  Pero, may pakita ko lang\n",
            "[44:04.660 --> 44:06.560]  po sa inyo yung timeline. Yung Naira po\n",
            "[44:06.560 --> 44:08.580]  o yung Akabay, nag-start po siya\n",
            "[44:08.580 --> 44:10.620]  ng April 1 and it has\n",
            "[44:10.620 --> 44:11.480]  a 3-year\n",
            "[44:11.480 --> 44:14.560]  duration. So, meron\n",
            "[44:14.560 --> 44:16.380]  po tayong, for the first year, initial\n",
            "[44:16.380 --> 44:18.340]  development and implementation.\n",
            "[44:19.340 --> 44:20.500]  So, magkakaroon na kami\n",
            "[44:20.500 --> 44:21.900]  ng capacity building.\n",
            "[44:22.700 --> 44:23.220]  Tapos,\n",
            "[44:24.360 --> 44:26.360]  i-develop na rin po yung, ah, i-cocontinue\n",
            "[44:26.360 --> 44:28.500]  yung development ng AI virtual\n",
            "[44:28.500 --> 44:30.600]  hub. And then, later on,\n",
            "[44:30.680 --> 44:32.680]  i-expand yung scale hanggang\n",
            "[44:32.680 --> 44:34.940]  sa masustain po ito\n",
            "[44:34.940 --> 44:36.740]  later on kahit na magtapos\n",
            "[44:36.740 --> 44:38.080]  na yung project duration.\n",
            "[44:38.620 --> 44:39.400]  Next slide, Bert.\n",
            "[44:42.260 --> 44:42.780]  Ayun.\n",
            "[44:43.020 --> 44:44.840]  Ayun po yung, ano, yung\n",
            "[44:44.840 --> 44:46.860]  presentation ko. And salamat\n",
            "[44:46.860 --> 44:48.520]  po sa, thank you for listening.\n",
            "[44:49.140 --> 44:51.060]  Meron po bang mga questions\n",
            "[44:51.060 --> 44:52.740]  Dr. Rachel and\n",
            "[44:52.740 --> 44:53.420]  team?\n",
            "[44:54.360 --> 44:57.420]  Thank you, Sir\n",
            "[44:57.420 --> 44:58.060]  Elmer.\n",
            "[45:03.500 --> 45:05.860]  Mga questions lang po.\n",
            "[45:06.040 --> 45:06.460]  Yung\n",
            "[45:06.460 --> 45:09.360]  sa student\n",
            "[45:10.140 --> 45:11.720]  capacity building,\n",
            "[45:11.720 --> 45:13.300]  ah, capacity building, no,\n",
            "[45:13.380 --> 45:14.680]  for the young minds.\n",
            "[45:15.380 --> 45:17.220]  Apo. Meron kasi\n",
            "[45:17.220 --> 45:19.120]  kaming faculty na a-attend sana\n",
            "[45:19.120 --> 45:20.980]  nung Oxford Machine Learning\n",
            "[45:20.980 --> 45:23.140]  training. Apo.\n",
            "[45:23.140 --> 45:24.340]  August po yun.\n",
            "[45:24.360 --> 45:26.240]  May alam ba kayo na pwedeng?\n",
            "[45:26.340 --> 45:28.380]  Sa inyo ba? Kayo ba ang nagpo-provide?\n",
            "[45:28.500 --> 45:30.560]  O sa P-shirt kami\n",
            "[45:30.560 --> 45:31.680]  dadaan?\n",
            "[45:32.540 --> 45:34.660]  Ah, under this program po,\n",
            "[45:34.920 --> 45:36.360]  pwede naman kami na yung mag-provide.\n",
            "[45:37.320 --> 45:38.580]  Actually, I am\n",
            "[45:38.580 --> 45:40.400]  also in talks with, ano,\n",
            "[45:41.140 --> 45:42.240]  with\n",
            "[45:42.240 --> 45:44.500]  ILO, International Labor\n",
            "[45:44.500 --> 45:46.060]  Organization. Meron din silang training of\n",
            "[45:46.060 --> 45:48.300]  trainers na mag-a-undergo kami.\n",
            "[45:48.840 --> 45:50.540]  Although itong under ACABY program,\n",
            "[45:50.660 --> 45:52.580]  kasama po talaga namin sa deliverables\n",
            "[45:52.580 --> 45:54.340]  yung capacity building.\n",
            "[45:54.360 --> 45:56.500]  So, this is part of our deliverable po.\n",
            "[45:56.720 --> 45:58.180]  So, pwede po natin siyang i-address.\n",
            "[45:58.180 --> 45:59.320]  I-refer ko sa iyo.\n",
            "[46:00.440 --> 46:02.340]  Actually, kasi dahil wala siyang\n",
            "[46:02.340 --> 46:03.960]  makuhang funding source,\n",
            "[46:04.740 --> 46:06.220]  ang in-enrollan na lang niya\n",
            "[46:06.220 --> 46:08.300]  yung mga online, tapos yung\n",
            "[46:08.300 --> 46:10.200]  mga kailangan na andoon,\n",
            "[46:10.880 --> 46:12.300]  eh, kasi wala nga ang funding.\n",
            "[46:12.720 --> 46:14.260]  Hindi niya in-enroll, pero\n",
            "[46:14.260 --> 46:16.220]  napagastos pa rin siya.\n",
            "[46:16.540 --> 46:18.020]  Pwede bang i-reimburse yun?\n",
            "[46:18.560 --> 46:20.360]  Pero sayang, ano, kung alam ko\n",
            "[46:20.360 --> 46:21.800]  lang na meron kayo, eh,\n",
            "[46:22.000 --> 46:24.040]  parang almost 100,000 ata\n",
            "[46:24.040 --> 46:25.020]  mahigit kung\n",
            "[46:25.020 --> 46:27.900]  i-enroll niya lahat.\n",
            "[46:28.080 --> 46:30.280]  Parang meron siyang package na six\n",
            "[46:30.280 --> 46:31.880]  ano, six\n",
            "[46:31.880 --> 46:34.080]  topics. Parang\n",
            "[46:34.080 --> 46:35.600]  tatlo lang yung in-enroll niya.\n",
            "[46:35.920 --> 46:38.440]  Parang ganon. Pwede namin i-refer sa inyo.\n",
            "[46:40.040 --> 46:42.200]  Ate, ano po yung pinaka-objective\n",
            "[46:42.200 --> 46:44.080]  ma'am nung ano? Bakit kailangan nung\n",
            "[46:44.080 --> 46:46.200]  capacity building nung dun sa in-enroll niya?\n",
            "[46:46.600 --> 46:47.560]  Ano siya?\n",
            "[46:48.260 --> 46:50.140]  Oxford Machine Learning\n",
            "[46:50.140 --> 46:51.220]  Summer School\n",
            "[46:51.220 --> 46:53.700]  August 7 to 10.\n",
            "[46:54.040 --> 46:56.400]  Tapos meron siyang programa, eh.\n",
            "[46:57.900 --> 46:59.780]  Imbat-ibang topics.\n",
            "[47:11.620 --> 47:13.460]  Ah, may bayad po ito, no?\n",
            "[47:13.640 --> 47:15.880]  Oo, may bayad. Two-week Oxford\n",
            "[47:15.880 --> 47:17.820]  AI program.\n",
            "[47:18.660 --> 47:20.260]  Parang may anim na\n",
            "[47:20.260 --> 47:21.420]  topics.\n",
            "[47:22.120 --> 47:22.840]  2025.\n",
            "[47:22.840 --> 47:23.360]  2025.\n",
            "[47:23.680 --> 47:25.120]  Mahal. Oo.\n",
            "[47:26.100 --> 47:28.700]  So, ang in-enroll, ang kinuha na lang niya\n",
            "[47:28.700 --> 47:29.360]  yung mga\n",
            "[47:29.360 --> 47:32.580]  online, kasi walang\n",
            "[47:32.580 --> 47:34.420]  funding na papunta. Pero\n",
            "[47:34.420 --> 47:36.080]  nag-enroll siya dun sa online.\n",
            "[47:39.960 --> 47:42.840]  What we can do po,\n",
            "[47:43.000 --> 47:44.200]  kunyari, let's say,\n",
            "[47:44.860 --> 47:48.600]  usually po kasi ang\n",
            "[47:48.600 --> 47:50.540]  ano namin, ang objective\n",
            "[47:50.540 --> 47:52.540]  namin is, ikakapacitate namin\n",
            "[47:52.840 --> 47:54.680]  yung isang grupo to actually\n",
            "[47:54.680 --> 47:56.760]  develop some AI applications\n",
            "[47:56.760 --> 47:57.940]  that they can use.\n",
            "[47:58.480 --> 48:00.960]  And ang isa pong target namin, mga MSM\n",
            "[48:00.960 --> 48:01.460]  is sana.\n",
            "[48:02.720 --> 48:04.600]  Para we can actually\n",
            "[48:04.600 --> 48:06.000]  teach them how to\n",
            "[48:06.000 --> 48:08.640]  build AI for yung ano, or\n",
            "[48:08.640 --> 48:10.840]  we can actually teach them how to use\n",
            "[48:10.840 --> 48:12.620]  already existing AIs\n",
            "[48:12.620 --> 48:14.860]  para po ma-accelerate\n",
            "[48:14.860 --> 48:15.940]  yung kanilang productivity.\n",
            "[48:16.700 --> 48:18.800]  So, that's the idea po doon sa aming\n",
            "[48:18.800 --> 48:19.900]  ano. That's one of the\n",
            "[48:19.900 --> 48:22.640]  goal po ng aming capacity building\n",
            "[48:22.640 --> 48:24.380]  effort. Kasi isa sa ano po nito,\n",
            "[48:24.440 --> 48:25.740]  impact po nito, is yun nga,\n",
            "[48:26.260 --> 48:28.260]  ma-strengthen po yung mga\n",
            "[48:28.260 --> 48:29.240]  MSMEs.\n",
            "[48:30.260 --> 48:32.340]  Pero syempre tayo, kailangan natin\n",
            "[48:32.340 --> 48:34.420]  mag-train, diba? Para ma-train\n",
            "[48:34.420 --> 48:36.000]  natin yung iba. So,\n",
            "[48:36.100 --> 48:38.300]  paano nyo ginagawa? Ah, may\n",
            "[48:38.300 --> 48:39.520]  sarili kayong training\n",
            "[48:39.520 --> 48:41.800]  for the team.\n",
            "[48:42.400 --> 48:44.260]  Apo. Actually, yun nga po yung\n",
            "[48:44.260 --> 48:45.660]  ano, yung\n",
            "[48:45.660 --> 48:47.520]  sinabi ko kanina,\n",
            "[48:48.020 --> 48:50.260]  in institute\n",
            "[48:50.260 --> 48:52.100]  before ng DOST,\n",
            "[48:52.640 --> 48:53.960]  mga patraining nila,\n",
            "[48:54.300 --> 48:56.400]  we hired experts from the\n",
            "[48:56.400 --> 48:58.180]  universities. Actually, yun sila,\n",
            "[48:58.240 --> 49:00.300]  Doc Frost-Nabal, yung mga ano,\n",
            "[49:00.860 --> 49:02.240]  and then sila, sila\n",
            "[49:02.240 --> 49:04.240]  Doc Didit, sila Doc Arnie,\n",
            "[49:04.380 --> 49:06.460]  Askaraga. Sila yung mga noon na\n",
            "[49:06.460 --> 49:08.580]  nag-train noon eh, doon sa AI\n",
            "[49:08.580 --> 49:10.460]  noong mga, noong\n",
            "[49:10.460 --> 49:12.720]  time na yun. And also,\n",
            "[49:13.000 --> 49:13.900]  aside from that,\n",
            "[49:14.180 --> 49:16.220]  nag-ano din po sila, nag-ano din po sila ng\n",
            "[49:16.220 --> 49:18.100]  expert and mga balik scientist\n",
            "[49:18.100 --> 49:20.480]  to train po yung mga sa DOST.\n",
            "[49:20.860 --> 49:22.260]  And most of the researchers\n",
            "[49:22.260 --> 49:23.840]  naman din po dito sa ASTI\n",
            "[49:23.840 --> 49:26.480]  are actually graduate students who are taking\n",
            "[49:26.480 --> 49:28.360]  Masters of Artificial\n",
            "[49:28.360 --> 49:29.260]  Intelligence.\n",
            "[49:29.660 --> 49:31.240]  Naka-enroll siya doon sa\n",
            "[49:31.240 --> 49:34.480]  Master of Engineering ata sa Diliman.\n",
            "[49:34.900 --> 49:35.620]  Opo, sa Diliman.\n",
            "[49:35.800 --> 49:37.100]  O, naka-enroll siya doon.\n",
            "[49:37.560 --> 49:40.720]  Okay, so, and then yung\n",
            "[49:40.720 --> 49:42.260]  kasali ba kami\n",
            "[49:42.260 --> 49:43.440]  doon sa ano, sa\n",
            "[49:43.440 --> 49:46.380]  HPC? Parang nakita\n",
            "[49:46.380 --> 49:47.360]  ko UPLB.\n",
            "[49:47.840 --> 49:50.100]  Okay, yun po, ang\n",
            "[49:50.100 --> 49:52.240]  naka-receive po sa inyo is si Dr. J.P.\n",
            "[49:52.260 --> 49:54.600]  Ramoso. Ay, doctor na ba?\n",
            "[49:54.760 --> 49:56.100]  Si Sir J.P. po, na\n",
            "[49:56.100 --> 49:58.460]  ngayon kasi naka, ano yata, siya sa UK.\n",
            "[49:59.020 --> 50:00.300]  Taga-SEAT po siya.\n",
            "[50:01.840 --> 50:02.640]  Sir J.P.,\n",
            "[50:02.640 --> 50:04.220]  meron pong ano doon. Hindi ko lang\n",
            "[50:04.220 --> 50:06.200]  alam kung ano na yung utilization\n",
            "[50:06.200 --> 50:08.520]  ng ano, kung sino gumagamit po sa UPLB.\n",
            "[50:08.900 --> 50:10.040]  Pero meron pong ano,\n",
            "[50:10.440 --> 50:11.680]  HPC po sa ano.\n",
            "[50:12.240 --> 50:12.960]  Alam niyo yun,\n",
            "[50:13.740 --> 50:16.160]  nandiyo pa ba si Sir Arian?\n",
            "[50:16.700 --> 50:18.000]  Mamaya lang. Alam niyo yun?\n",
            "[50:18.520 --> 50:19.740]  Kasi yun ang problema.\n",
            "[50:19.740 --> 50:21.540]  Ano yung in-offer ng engineering?\n",
            "[50:22.260 --> 50:23.960]  Pero yung engineering student nila\n",
            "[50:23.960 --> 50:25.400]  ngayon, nasa atin nagra-run eh.\n",
            "[50:27.080 --> 50:27.900]  May nakikita ko\n",
            "[50:27.900 --> 50:29.960]  dating promotion ng engineering for\n",
            "[50:29.960 --> 50:32.000]  a 200\n",
            "[50:32.000 --> 50:33.960]  gig gram yata. Hindi ko lang alam\n",
            "[50:33.960 --> 50:35.720]  kung 7 teraflops yun. Pero\n",
            "[50:35.720 --> 50:37.720]  basta may ngayon, ma'am, currently, may\n",
            "[50:37.720 --> 50:39.780]  isang engineering student na nagra-run ng\n",
            "[50:39.780 --> 50:40.860]  light simulation\n",
            "[50:40.860 --> 50:43.320]  sa servers.\n",
            "[50:43.660 --> 50:45.680]  Sa iyo. Kaya yun yung\n",
            "[50:45.680 --> 50:46.360]  sinasabi ko.\n",
            "[50:46.360 --> 50:49.580]  Kung suggestion ko na lang\n",
            "[50:49.580 --> 50:50.100]  ganito, no?\n",
            "[50:50.520 --> 50:52.240]  Medyo matagal na rin kayo tayo sa mga callers.\n",
            "[50:52.260 --> 50:54.420]  Ang lagi namin sinasabi\n",
            "[50:54.420 --> 50:56.180]  ni Sir Jimmy, if you want\n",
            "[50:56.180 --> 50:58.560]  this to go, let's start small.\n",
            "[50:59.320 --> 51:00.260]  Tama yan kay ma'am, no?\n",
            "[51:00.340 --> 51:02.200]  Kung may scholarship. Sa amin, may\n",
            "[51:02.200 --> 51:03.560]  nirarang ngayon dito si\n",
            "[51:03.560 --> 51:05.820]  sa image processing.\n",
            "[51:06.040 --> 51:08.420]  Kausapin niyo lang si Dokbal. Basta pag sa image processing\n",
            "[51:08.420 --> 51:09.920]  siya na kasi pinagpasaan ni ano eh.\n",
            "[51:10.520 --> 51:12.620]  Just to give you an idea, no? May nirarang\n",
            "[51:12.620 --> 51:14.480]  siya na 20 gig na data\n",
            "[51:14.480 --> 51:16.300]  sa wood identification\n",
            "[51:16.300 --> 51:17.160]  to Elmer.\n",
            "[51:18.700 --> 51:19.940]  Shout out pala kay Vanny\n",
            "[51:19.940 --> 51:20.600]  tsaka Rox.\n",
            "[51:21.420 --> 51:22.240]  Nandiyan pala siya.\n",
            "[51:22.260 --> 51:24.160]  Sorry, hindi ako ron nung mag-like Rox.\n",
            "[51:24.360 --> 51:26.200]  Hindi ako, first time kumag-microsoft teams.\n",
            "[51:26.820 --> 51:27.940]  Let's start small.\n",
            "[51:29.080 --> 51:30.380]  Yung 20 gig\n",
            "[51:30.380 --> 51:32.180]  na yun, niran yata ni Val\n",
            "[51:32.180 --> 51:34.580]  sa maganda ng PC at 5 days.\n",
            "[51:34.960 --> 51:35.980]  So if you can just like\n",
            "[51:35.980 --> 51:38.100]  assign a student, practicum muna,\n",
            "[51:39.400 --> 51:40.480]  gamitin\n",
            "[51:40.480 --> 51:42.040]  niyang facility nyo.\n",
            "[51:42.800 --> 51:43.880]  May speed up tayo.\n",
            "[51:44.220 --> 51:46.120]  Yan kaagad, no? Ma-action na natin\n",
            "[51:46.120 --> 51:48.320]  agad. Even as Mamayla, tama ba?\n",
            "[51:48.980 --> 51:50.240]  Mas alam ni Mamayla yun\n",
            "[51:50.240 --> 51:52.060]  sa practicum eh. O ngayong practicum,\n",
            "[51:52.260 --> 51:54.100]  ang pwede mong kuin\n",
            "[51:54.100 --> 51:55.960]  Elmer. Kunyari, makaka-ako ka ng\n",
            "[51:55.960 --> 51:58.060]  3 to 5. Ang gagawin nila\n",
            "[51:58.060 --> 51:59.740]  agad, yung mga current namin.\n",
            "[51:59.920 --> 52:01.100]  Tapos sa bioinformatics,\n",
            "[52:01.880 --> 52:03.780]  nagparinig na ako dun sa mga nagwi-wishlist\n",
            "[52:03.780 --> 52:05.700]  ng A100 sa akin. Sabi ko, may\n",
            "[52:05.700 --> 52:07.780]  H200 daw. Ang balita ko,\n",
            "[52:07.920 --> 52:08.500]  ang asti.\n",
            "[52:09.560 --> 52:12.240]  So yun yung start small.\n",
            "[52:12.380 --> 52:14.180]  Pag sa start small, maasahan mo ako dyan.\n",
            "[52:14.340 --> 52:16.400]  I can give you a topic. May speed up\n",
            "[52:16.400 --> 52:17.960]  tayong gagawin. Dati nga,\n",
            "[52:18.020 --> 52:20.020]  nahiya ako eh. Kasi nung nagsastart ang QR\n",
            "[52:20.020 --> 52:20.800]  or asti.\n",
            "[52:22.260 --> 52:24.240]  Pangingi sila ng problem\n",
            "[52:24.240 --> 52:26.200]  na nagra-run sa MPI. Hindi ko\n",
            "[52:26.200 --> 52:28.520]  nasend. So ngayon,\n",
            "[52:28.600 --> 52:30.540]  babaway ako. I have, I think,\n",
            "[52:31.740 --> 52:32.200]  mga ano,\n",
            "[52:32.280 --> 52:34.380]  nagagamit talaga ng GPU. So I think\n",
            "[52:34.380 --> 52:36.140]  I have 3.\n",
            "[52:36.760 --> 52:38.000]  Assign it to the practicum.\n",
            "[52:38.140 --> 52:39.420]  ESP nila next year.\n",
            "[52:40.180 --> 52:42.040]  By the end of the year, you have\n",
            "[52:42.040 --> 52:44.220]  at least an output of students\n",
            "[52:44.220 --> 52:45.500]  supported by your project.\n",
            "[52:46.020 --> 52:46.800]  And ano.\n",
            "[52:48.400 --> 52:50.460]  Kasi ang advantage noon, sir,\n",
            "[52:51.300 --> 52:52.240]  eh, naan dyan.\n",
            "[52:52.260 --> 52:53.280]  Sila, sila.\n",
            "[52:54.020 --> 52:54.860]  Ako. Iyon.\n",
            "[52:55.400 --> 52:57.260]  Bunny and...\n",
            "[52:57.260 --> 52:59.540]  Pero on the onset, pangingi ako ng solar\n",
            "[52:59.540 --> 53:00.980]  para sa servers ko.\n",
            "[53:01.980 --> 53:02.660]  Ayun nga, eh.\n",
            "[53:02.660 --> 53:04.760]  Kasi pag nawawala ng kuryente,\n",
            "[53:05.140 --> 53:06.200]  ang problema namin.\n",
            "[53:06.220 --> 53:07.900]  Baka naman pwedeng ipush yan.\n",
            "[53:08.480 --> 53:10.560]  Parang this week, dalawang beses, ano,\n",
            "[53:10.740 --> 53:12.540]  dalawang beses nawala ng kuryente.\n",
            "[53:13.260 --> 53:15.280]  Sige. Sir Bunny muna. Sir Bunny.\n",
            "[53:15.540 --> 53:15.920]  Sir Bunny.\n",
            "[53:17.400 --> 53:19.820]  Sir Aryan, advertisement lang dun sa\n",
            "[53:19.820 --> 53:21.820]  solar. Contact nyo si...\n",
            "[53:22.260 --> 53:24.440]  si VP Peter C.\n",
            "[53:24.720 --> 53:26.640]  sa UP System, yung digital...\n",
            "[53:26.640 --> 53:28.240]  yung CIO ng UP po ngayon.\n",
            "[53:28.860 --> 53:30.320]  May mga tie-ups daw siya sa\n",
            "[53:30.320 --> 53:32.420]  Department of Energy na willing sila\n",
            "[53:32.420 --> 53:34.180]  mag-invest ng solar. Basta yung\n",
            "[53:34.180 --> 53:36.380]  institution, magpuprovide ng real estate\n",
            "[53:36.380 --> 53:37.320]  na papatungan.\n",
            "[53:38.480 --> 53:39.500]  May andaming...\n",
            "[53:39.500 --> 53:42.300]  Marami kaming bubong, tsaka...\n",
            "[53:42.300 --> 53:43.260]  Bubong lang, bubong.\n",
            "[53:43.700 --> 53:46.320]  Si Sir Bernie and Bunny sa 4th floor,\n",
            "[53:46.480 --> 53:48.400]  yung mga 2TB RAM\n",
            "[53:48.400 --> 53:49.760]  tsaka 1TB RAM.\n",
            "[53:50.780 --> 53:51.880]  Ano na? Ang next noon,\n",
            "[53:52.260 --> 53:54.180]  na-inspire kami mag-solar\n",
            "[53:54.180 --> 53:56.260]  kasi baka madali ikabit.\n",
            "[53:57.200 --> 53:57.920]  Ayun po, si\n",
            "[53:57.920 --> 54:00.300]  VP Peter C. po ng\n",
            "[54:00.300 --> 54:02.280]  UP System, may mga programa po sa\n",
            "[54:02.280 --> 54:04.380]  ganyan po. Sige, pag ni-name drop\n",
            "[54:04.380 --> 54:05.760]  bakit na kay Peter? Alam ko,\n",
            "[54:06.080 --> 54:07.920]  compare kayo. Close yan, close sila.\n",
            "[54:08.780 --> 54:09.320]  Close sila.\n",
            "[54:10.500 --> 54:12.320]  Meron kaming common na inaanak na\n",
            "[54:12.320 --> 54:13.240]  taga dumaget eh.\n",
            "[54:14.240 --> 54:16.060]  Pero sige, pangitin to.\n",
            "[54:16.740 --> 54:18.240]  Sir Aryan, pag nyo ako i-name drop,\n",
            "[54:18.340 --> 54:19.240]  sir, baka hindi ma-approve.\n",
            "[54:19.240 --> 54:19.800]  Hahaha.\n",
            "[54:22.260 --> 54:24.000]  Sir Aryan, okay, yung\n",
            "[54:24.000 --> 54:25.980]  thank you dun sa idea, yung\n",
            "[54:25.980 --> 54:28.880]  yung A200, bibili pa lang\n",
            "[54:28.880 --> 54:30.700]  namin, pero may isa\n",
            "[54:30.700 --> 54:32.660]  naka ano dito sa program, bibili kami\n",
            "[54:32.660 --> 54:34.660]  A200. Ang meron kami ngayon,\n",
            "[54:34.760 --> 54:36.620]  bukod dun sa core ah, bukod dun sa core,\n",
            "[54:37.260 --> 54:38.780]  meron kami isang V100,\n",
            "[54:38.980 --> 54:41.120]  yung same lang nung kay Sir JP,\n",
            "[54:41.740 --> 54:42.800]  saka isang A100.\n",
            "[54:43.040 --> 54:44.780]  Yung A100, nabili naman namin yun\n",
            "[54:44.780 --> 54:46.500]  under the ALAM program. Ngayon,\n",
            "[54:46.580 --> 54:48.320]  for Naira, bibili kami ng\n",
            "[54:48.320 --> 54:50.440]  A200. So yun yung ano,\n",
            "[54:50.780 --> 54:51.960]  aside from dun sa,\n",
            "[54:52.260 --> 54:54.000]  sa core. Tapos,\n",
            "[54:54.280 --> 54:56.160]  tama ba yung narinig ko kanina,\n",
            "[54:56.300 --> 54:57.840]  meron na sa inyo nag-wood AI?\n",
            "[54:58.520 --> 54:59.860]  Oo, may na-publish na kami.\n",
            "[55:00.240 --> 55:00.820]  Kami mismo.\n",
            "[55:01.520 --> 55:03.420]  Teka, teka, teka, ano naman,\n",
            "[55:03.840 --> 55:04.320]  pasalin.\n",
            "[55:04.540 --> 55:06.380]  Hindi yan, basta-basta na picture,\n",
            "[55:06.560 --> 55:08.360]  saka ano, kailangan mo niya ng\n",
            "[55:08.360 --> 55:11.920]  in-attach sa ano,\n",
            "[55:12.100 --> 55:12.920]  sa cellphone na\n",
            "[55:12.920 --> 55:14.260]  micron cam.\n",
            "[55:14.720 --> 55:16.440]  Yan yung, ano yan yung aming project\n",
            "[55:16.440 --> 55:17.640]  sa FPRDI.\n",
            "[55:18.240 --> 55:19.480]  Send ko sa iyo yung, ano namin.\n",
            "[55:19.480 --> 55:21.480]  Sige, sir. Sige, thank you, thank you.\n",
            "[55:22.260 --> 55:24.780]  So, isalin nyo si Arian sa project.\n",
            "[55:25.520 --> 55:26.060]  Sige po.\n",
            "[55:26.480 --> 55:28.640]  Ayun, nag-raise din kanina\n",
            "[55:28.640 --> 55:30.420]  si Sir Andre, pero naka-raise ngayon\n",
            "[55:30.420 --> 55:32.200]  si Mamayla po. Sige po.\n",
            "[55:33.300 --> 55:33.620]  Hello.\n",
            "[55:34.480 --> 55:35.380]  Hello, hello.\n",
            "[55:36.400 --> 55:38.820]  May mga naran ho kami dati\n",
            "[55:38.820 --> 55:40.460]  sa HPC, DOST\n",
            "[55:40.460 --> 55:41.540]  asti din sa core.\n",
            "[55:42.340 --> 55:44.300]  Pwede pa ho ba kaya kami ulit\n",
            "[55:44.300 --> 55:45.940]  mag-access\n",
            "[55:45.940 --> 55:47.700]  sa core?\n",
            "[55:48.400 --> 55:49.880]  May mamayla.\n",
            "[55:50.480 --> 55:51.940]  Hello, hello, Bonnie.\n",
            "[55:52.260 --> 55:54.680]  Kamusta po kay Sir Roslyn?\n",
            "[55:55.000 --> 55:55.700]  Ma'am, ano po,\n",
            "[55:56.760 --> 55:59.220]  ano ba tawag mo dyan?\n",
            "[55:59.340 --> 56:00.780]  I-linea, i-programa po natin\n",
            "[56:00.780 --> 56:02.360]  yung need nyo na\n",
            "[56:02.360 --> 56:04.780]  resources sa core\n",
            "[56:04.780 --> 56:06.300]  kasi as of now,\n",
            "[56:06.400 --> 56:08.260]  nag-upgrade po kami. Kung relatively\n",
            "[56:08.260 --> 56:10.280]  maliit po, kaya\n",
            "[56:10.280 --> 56:12.160]  naman po yan, pero kung relatively\n",
            "[56:12.160 --> 56:14.800]  malaki, medyo i-ta-timing\n",
            "[56:14.800 --> 56:15.400]  po natin.\n",
            "[56:16.120 --> 56:18.180]  Ang short answer is yes po.\n",
            "[56:20.100 --> 56:22.240]  Open naman po yung core for access sa UPS.\n",
            "[56:22.260 --> 56:24.940]  I-match lang po natin\n",
            "[56:24.940 --> 56:26.380]  doon sa resource na kailangan nyo po.\n",
            "[56:27.880 --> 56:30.300]  Kailangan, kailangan namin yan\n",
            "[56:30.300 --> 56:32.260]  dahil tumutukod yung mga...\n",
            "[56:33.940 --> 56:35.080]  Actually, ma'am,\n",
            "[56:35.540 --> 56:38.260]  ito yung missing link natin sa\n",
            "[56:38.260 --> 56:40.260]  ano din, AI for Agriculture\n",
            "[56:40.260 --> 56:41.380]  ng IPB.\n",
            "[56:42.260 --> 56:43.920]  Kasi malilimit po tayo\n",
            "[56:43.920 --> 56:45.020]  kung wala tayong infra.\n",
            "[56:46.020 --> 56:48.300]  So, paano po, ma'am, to proceed\n",
            "[56:48.300 --> 56:50.200]  kung kunyari meron ng topic\n",
            "[56:50.200 --> 56:51.440]  na ma-identify?\n",
            "[56:52.260 --> 56:53.640]  Paano po yung\n",
            "[56:53.640 --> 56:54.160]  nito?\n",
            "[56:54.940 --> 56:57.060]  Kasi, Sir Elmer,\n",
            "[56:57.220 --> 56:59.720]  currently, may mga talks kami\n",
            "[56:59.720 --> 57:02.140]  with Institute of Plant Breeding,\n",
            "[57:02.280 --> 57:03.720]  naka-ilang meetings na,\n",
            "[57:03.840 --> 57:05.760]  and then mag-re-release kami\n",
            "[57:05.760 --> 57:07.820]  ng mga practicum students,\n",
            "[57:08.260 --> 57:10.020]  and then sa College of\n",
            "[57:10.020 --> 57:12.000]  Forestry and Natural Resources,\n",
            "[57:12.700 --> 57:13.800]  kasi ang dami nilang\n",
            "[57:13.800 --> 57:15.840]  data, kailangan talaga nila\n",
            "[57:15.840 --> 57:16.580]  ng AI.\n",
            "[57:17.460 --> 57:19.880]  Yan ang problema. Tapos ako\n",
            "[57:19.880 --> 57:21.640]  nga, siyempre, NLP naman,\n",
            "[57:22.260 --> 57:24.360]  so, ang mga approaches\n",
            "[57:24.360 --> 57:25.820]  talagang\n",
            "[57:25.820 --> 57:27.700]  matakaw sa\n",
            "[57:27.700 --> 57:29.100]  competition.\n",
            "[57:29.660 --> 57:30.920]  Sige po. Ganito po.\n",
            "[57:31.980 --> 57:33.960]  I acknowledge po yung\n",
            "[57:33.960 --> 57:36.140]  naka-release yung answer ba ni Sir Andre, no?\n",
            "[57:36.500 --> 57:38.080]  Pero, sagutin ko lang muna yung\n",
            "[57:38.080 --> 57:39.900]  kay Mamayla po na,\n",
            "[57:40.300 --> 57:42.320]  bali, ang mangyayari po, yung mga projects\n",
            "[57:42.320 --> 57:43.880]  na yan, ako natutuan ako ngayon,\n",
            "[57:43.940 --> 57:45.580]  na-excite din po ako. Hopefully,\n",
            "[57:46.200 --> 57:48.380]  sana, ano, ma-provide na namin\n",
            "[57:48.380 --> 57:50.500]  ng, ano, makapag-partner\n",
            "[57:50.500 --> 57:52.100]  po tayo, ano, yung mga\n",
            "[57:52.100 --> 57:53.600]  existing research ninyo.\n",
            "[57:54.180 --> 57:56.200]  Mangyayari po yan, under the\n",
            "[57:56.200 --> 57:57.680]  Naira program,\n",
            "[57:57.880 --> 57:59.860]  ipaprioritize po namin, kasi\n",
            "[57:59.860 --> 58:01.740]  ano lang, depende po dun sa\n",
            "[58:01.740 --> 58:04.040]  capacity po na kaya\n",
            "[58:04.040 --> 58:05.440]  namin gawin. Pero,\n",
            "[58:05.440 --> 58:07.640]  ang mangyayari dyan, kung alin yung\n",
            "[58:07.640 --> 58:09.880]  usually kasi madaming pwedeng gawin eh.\n",
            "[58:10.080 --> 58:11.600]  Yung pong Naira kasi,\n",
            "[58:11.840 --> 58:13.680]  generic naman siya, hindi naman siya\n",
            "[58:13.680 --> 58:15.520]  parang for agriculture lang\n",
            "[58:15.520 --> 58:17.860]  or for NLP lang. Lahat po\n",
            "[58:17.860 --> 58:19.640]  basta AI. Ngayon,\n",
            "[58:19.740 --> 58:21.520]  with regards to that, kung takaling\n",
            "[58:22.100 --> 58:23.540]  talagang, ano,\n",
            "[58:24.080 --> 58:26.120]  we would consider them as\n",
            "[58:26.120 --> 58:28.220]  one of the use cases. Like, katulad\n",
            "[58:28.220 --> 58:30.200]  may mga initial use cases na yan, tapos\n",
            "[58:30.200 --> 58:31.860]  mag-a-assign tayo ng staff, or\n",
            "[58:31.860 --> 58:33.720]  ng staff po ninyo, tapos magiging,\n",
            "[58:34.040 --> 58:36.080]  magkakaroon po ng collaboration, na research\n",
            "[58:36.080 --> 58:38.180]  collaboration po, with regards\n",
            "[58:38.180 --> 58:40.220]  to kung ano yung kayang i-provide at that\n",
            "[58:40.220 --> 58:41.960]  moment, ganun po yung\n",
            "[58:41.960 --> 58:43.740]  mangyayari. Halimbawa, yung would AI\n",
            "[58:43.740 --> 58:46.620]  na ano po yan, makikikolaborate\n",
            "[58:46.620 --> 58:47.960]  ako kay Sir Arian,\n",
            "[58:48.060 --> 58:50.060]  that's going to be one use case. Another use\n",
            "[58:50.060 --> 58:52.080]  case din po yung kay Ma'am Myla,\n",
            "[58:52.100 --> 58:54.140]  tapos titinan na lang po natin kung ano yung\n",
            "[58:54.140 --> 58:55.840]  available na, ano, na\n",
            "[58:55.840 --> 58:57.800]  capacity nung, ah,\n",
            "[58:58.360 --> 59:00.200]  kung ano meron tayong infra\n",
            "[59:00.200 --> 59:02.000]  na pwedeng paggamitan po nung, ano,\n",
            "[59:02.080 --> 59:03.960]  ipaprioritize na lang po. Parang\n",
            "[59:03.960 --> 59:05.740]  ganun po yung, ah,\n",
            "[59:06.100 --> 59:07.840]  mangyayari. So, in that case po,\n",
            "[59:08.000 --> 59:10.060]  kapag ka ganun, magkakaroon\n",
            "[59:10.060 --> 59:12.360]  lang po tayo ng mga memorandum of agreement\n",
            "[59:12.360 --> 59:13.480]  and partnership\n",
            "[59:13.480 --> 59:15.040]  para po at least\n",
            "[59:15.040 --> 59:18.160]  maano din siya under the,\n",
            "[59:18.160 --> 59:19.360]  ano, the\n",
            "[59:20.180 --> 59:21.180]  akabay program.\n",
            "[59:21.540 --> 59:21.920]  Ayun po.\n",
            "[59:22.100 --> 59:23.520]  Sige po.\n",
            "[59:23.520 --> 59:26.320]  Yung si, ah, nag-message si Sir Arian.\n",
            "[59:26.480 --> 59:28.360]  Yung si Dr. Val Madrid\n",
            "[59:28.360 --> 59:29.780]  kasi mga image eh.\n",
            "[59:30.300 --> 59:31.680]  Image yung kanya, ano.\n",
            "[59:32.400 --> 59:34.100]  Pinakilala sa akin ni Sir Arian to\n",
            "[59:34.100 --> 59:36.320]  nung nag-visit ako dyan. Umakit kami sa taas.\n",
            "[59:36.640 --> 59:38.040]  Si Doc Val.\n",
            "[59:38.340 --> 59:40.280]  Ayun. Sige. Si Sir Andre\n",
            "[59:40.280 --> 59:40.800]  po muna.\n",
            "[59:42.520 --> 59:43.020]  Sir Andre.\n",
            "[59:45.440 --> 59:46.080]  Hello po.\n",
            "[59:46.120 --> 59:46.880]  Audible po ba ako?\n",
            "[59:47.320 --> 59:47.640]  Hello.\n",
            "[59:49.640 --> 59:51.340]  Parang may nabanggit po kanina\n",
            "[59:51.340 --> 59:52.060]  sa presentation.\n",
            "[59:52.100 --> 59:54.220]  May mga ready, may mga data sets\n",
            "[59:54.220 --> 59:55.700]  daw na pinaprovide ng BUSD.\n",
            "[59:56.180 --> 59:58.060]  Paano po bang, libre po ba ito?\n",
            "[59:58.280 --> 01:00:00.200]  At may process po ba sa pagkuka po?\n",
            "[01:00:02.320 --> 01:00:04.140]  Meron pong, ano, meron pong,\n",
            "[01:00:04.180 --> 01:00:05.200]  ano, ah,\n",
            "[01:00:05.620 --> 01:00:07.880]  proseso. Pero most of them naman po ay\n",
            "[01:00:07.880 --> 01:00:10.100]  ay libre. Kunyari, yung mga\n",
            "[01:00:10.100 --> 01:00:11.480]  let's say yung weather data\n",
            "[01:00:11.480 --> 01:00:14.120]  or yung mga images na, ano,\n",
            "[01:00:14.660 --> 01:00:16.180]  meron lang pong parang, ano,\n",
            "[01:00:16.420 --> 01:00:18.220]  data sharing agreement na, ano,\n",
            "[01:00:18.500 --> 01:00:19.000]  is assigned.\n",
            "[01:00:19.000 --> 01:00:19.060]  Okay.\n",
            "[01:00:21.220 --> 01:00:21.640]  Sa,\n",
            "[01:00:22.100 --> 01:00:23.740]  ba ata proseso nun, Sir?\n",
            "[01:00:23.860 --> 01:00:26.200]  Kasi yung ladaan ata sa legal\n",
            "[01:00:26.200 --> 01:00:27.500]  ng UPLB, eh, no?\n",
            "[01:00:27.680 --> 01:00:29.360]  Kasi hindi naman pwedeng basta kami\n",
            "[01:00:29.360 --> 01:00:30.720]  ang piperman yan, eh, no?\n",
            "[01:00:32.060 --> 01:00:33.440]  At pero sa\n",
            "[01:00:33.440 --> 01:00:35.460]  ASTI kasi,\n",
            "[01:00:36.740 --> 01:00:37.820]  parang, ano lang,\n",
            "[01:00:37.980 --> 01:00:38.460]  ah,\n",
            "[01:00:39.780 --> 01:00:40.920]  nag-ano rin po kami,\n",
            "[01:00:41.060 --> 01:00:42.720]  yung nag-share kami doon sa\n",
            "[01:00:42.720 --> 01:00:45.660]  pag-asa, may kinonsult lang kami\n",
            "[01:00:45.660 --> 01:00:46.660]  na legal\n",
            "[01:00:46.660 --> 01:00:48.980]  ng DOST.\n",
            "[01:00:49.740 --> 01:00:51.240]  Tapos, yun po, yun yung, ano,\n",
            "[01:00:52.100 --> 01:00:53.100]  ah,\n",
            "[01:00:53.360 --> 01:00:56.460]  kasi depende po kung saan gagamitin din, eh,\n",
            "[01:00:56.600 --> 01:00:58.040]  yung, ano, yung data, kung\n",
            "[01:00:58.040 --> 01:01:00.500]  sa research ba, yung gano'n.\n",
            "[01:01:00.800 --> 01:01:02.580]  Pero dapat kasi pag mga ganito,\n",
            "[01:01:02.740 --> 01:01:04.760]  ano na, eh, parang padaliin na, eh,\n",
            "[01:01:04.760 --> 01:01:06.880]  yung, ano, lalo na kung hindi naman\n",
            "[01:01:06.880 --> 01:01:08.040]  sensitive yung\n",
            "[01:01:08.040 --> 01:01:10.120]  data, yung\n",
            "[01:01:10.120 --> 01:01:12.200]  for research na, dapat\n",
            "[01:01:12.200 --> 01:01:14.500]  yung mga ganitong usapin. Meron kasi kami,\n",
            "[01:01:14.620 --> 01:01:16.780]  alam ko sa DOST, parang yung\n",
            "[01:01:16.780 --> 01:01:18.780]  ah, memo about data\n",
            "[01:01:18.780 --> 01:01:20.800]  sharing, may nilabas na memo\n",
            "[01:01:20.800 --> 01:01:21.640]  gano'n, parang,\n",
            "[01:01:22.100 --> 01:01:24.500]  ah, dapat freely pwedeng i-share yung\n",
            "[01:01:24.500 --> 01:01:26.420]  data nung mga, ah,\n",
            "[01:01:26.460 --> 01:01:28.440]  mga research data, eh, within DOST.\n",
            "[01:01:28.820 --> 01:01:30.640]  Pero with regards po, siguro sa ano,\n",
            "[01:01:30.740 --> 01:01:32.400]  baka kailangan po ng, ano, data sharing\n",
            "[01:01:32.400 --> 01:01:32.880]  agreement.\n",
            "[01:01:35.160 --> 01:01:35.640]  Sir.\n",
            "[01:01:37.380 --> 01:01:38.620]  Ah, si Sir Bani\n",
            "[01:01:38.620 --> 01:01:39.800]  muna bago si Sir Arian.\n",
            "[01:01:40.700 --> 01:01:42.540]  Sir Bani, yung sasabihin mo kanina?\n",
            "[01:01:43.260 --> 01:01:44.260]  Ay, thank you, Sir Elmer.\n",
            "[01:01:44.660 --> 01:01:46.300]  Ma'am, may yung sa\n",
            "[01:01:46.300 --> 01:01:48.900]  paggamit ng core, dati nag-a-allow\n",
            "[01:01:48.900 --> 01:01:50.200]  ng individual,\n",
            "[01:01:50.680 --> 01:01:51.100]  ah,\n",
            "[01:01:52.100 --> 01:01:54.340]  graduate students, ah,\n",
            "[01:01:54.340 --> 01:01:56.500]  to act it. Kaso lang nabulunan\n",
            "[01:01:56.500 --> 01:01:58.440]  si ASTI sa dami ng individual\n",
            "[01:01:58.440 --> 01:02:00.560]  ah, accounts\n",
            "[01:02:00.560 --> 01:02:02.320]  na nag-e-enroll.\n",
            "[01:02:02.740 --> 01:02:04.660]  So, ang naging decision recently,\n",
            "[01:02:04.860 --> 01:02:06.100]  kung pwede institutional,\n",
            "[01:02:06.820 --> 01:02:08.560]  yung, ah,\n",
            "[01:02:08.660 --> 01:02:10.480]  agreement sa paggamit ng core,\n",
            "[01:02:10.820 --> 01:02:11.760]  meaning, ah,\n",
            "[01:02:12.340 --> 01:02:14.440]  kung pwede po matuloy yung pinag-uusapan nyo kanina\n",
            "[01:02:14.440 --> 01:02:16.420]  na MOA between, ah,\n",
            "[01:02:16.420 --> 01:02:18.440]  AS, mailagay po doon yung\n",
            "[01:02:18.440 --> 01:02:20.720]  use nung, nung HPC,\n",
            "[01:02:20.900 --> 01:02:21.940]  nung core facility.\n",
            "[01:02:22.100 --> 01:02:24.140]  Tapos, ah, yung\n",
            "[01:02:24.140 --> 01:02:26.340]  question ni Sir Andre doon sa dataset, may sinend ako\n",
            "[01:02:26.340 --> 01:02:27.740]  na chat po, na link.\n",
            "[01:02:28.160 --> 01:02:30.460]  Ilan po yan doon sa mga datasets na naka-store\n",
            "[01:02:30.460 --> 01:02:31.260]  po dito sa amin?\n",
            "[01:02:33.660 --> 01:02:34.740]  Ayun. Thank you, Sir Bani.\n",
            "[01:02:35.220 --> 01:02:36.580]  Ah, if I may ask lang\n",
            "[01:02:36.580 --> 01:02:38.420]  siguro bago kay Sir Arian, ah,\n",
            "[01:02:38.460 --> 01:02:39.680]  at saka kay Ma'am Rox.\n",
            "[01:02:40.360 --> 01:02:40.760]  Ah,\n",
            "[01:02:42.260 --> 01:02:44.580]  Sir Andre, may specific po ba\n",
            "[01:02:44.580 --> 01:02:46.560]  kayong ina-eye na, ano, na dataset?\n",
            "[01:02:47.160 --> 01:02:48.680]  Baka, alimbawa, let's say,\n",
            "[01:02:48.760 --> 01:02:50.740]  hindi ko kasi alam, baka\n",
            "[01:02:50.740 --> 01:02:52.080]  yung projects, ah,\n",
            "[01:02:52.100 --> 01:02:53.600]  yung, ano siya, project, or\n",
            "[01:02:53.600 --> 01:02:55.740]  general po yung tanong ninyo\n",
            "[01:02:55.740 --> 01:02:56.740]  about datasets?\n",
            "[01:02:57.680 --> 01:02:59.920]  General naman po, Sir. Ah, general. Okay.\n",
            "[01:03:00.040 --> 01:03:01.860]  Yun po. Sige po. Ah,\n",
            "[01:03:01.960 --> 01:03:04.020]  Rox, nakita ko nakarace yung hand mo kanina.\n",
            "[01:03:05.880 --> 01:03:07.680]  Hmm. Hindi ako nag-raise pero,\n",
            "[01:03:08.220 --> 01:03:09.820]  um, I have to say something.\n",
            "[01:03:10.700 --> 01:03:12.160]  Sige, sige. I think yung, ano,\n",
            "[01:03:12.700 --> 01:03:14.240]  um, na-mention din ata kanina\n",
            "[01:03:14.240 --> 01:03:15.140]  ni Ma'am Joanne,\n",
            "[01:03:15.400 --> 01:03:16.480]  division chief po namin.\n",
            "[01:03:18.160 --> 01:03:20.000]  Um, isa sa mga pwedeng\n",
            "[01:03:20.000 --> 01:03:22.080]  maging area, ah, ng collaboration.\n",
            "[01:03:22.100 --> 01:03:23.740]  Atin is\n",
            "[01:03:23.740 --> 01:03:26.180]  student internship, ah, primarily\n",
            "[01:03:26.180 --> 01:03:28.020]  um, yung mga\n",
            "[01:03:28.020 --> 01:03:30.320]  um, comm-sci students natin\n",
            "[01:03:30.320 --> 01:03:31.940]  sa ICS. Kasi ngayon,\n",
            "[01:03:32.520 --> 01:03:34.160]  meron kaming ongoing partnership\n",
            "[01:03:34.160 --> 01:03:35.680]  pero sa SEH at sa DEE.\n",
            "[01:03:36.540 --> 01:03:37.960]  Um, meron kaming\n",
            "[01:03:37.960 --> 01:03:39.800]  ongoing MOA, MOA, no?\n",
            "[01:03:40.000 --> 01:03:41.580]  Sir Elmer, yung ALAM.\n",
            "[01:03:42.140 --> 01:03:44.020]  Particularly dun sa National Museum,\n",
            "[01:03:44.200 --> 01:03:45.960]  ah, NMH.\n",
            "[01:03:46.460 --> 01:03:48.220]  Museum of National History. Tama ba, Job?\n",
            "[01:03:48.480 --> 01:03:50.100]  Tama. Ah, sa\n",
            "[01:03:50.100 --> 01:03:51.760]  sa UPLG.\n",
            "[01:03:52.100 --> 01:03:54.200]  Then, we're topping si DEE\n",
            "[01:03:54.200 --> 01:03:56.080]  for, ano,\n",
            "[01:03:56.180 --> 01:03:58.300]  augmentation or additional capacity.\n",
            "[01:03:58.960 --> 01:04:00.260]  And I know, si ICS din,\n",
            "[01:04:00.360 --> 01:04:02.400]  meron namang capacity on AI talaga.\n",
            "[01:04:02.620 --> 01:04:04.380]  And, we've met, sir, ano rin,\n",
            "[01:04:04.420 --> 01:04:06.100]  si Doc Val Madrid, I think,\n",
            "[01:04:06.380 --> 01:04:08.020]  few years ago, pero ibang\n",
            "[01:04:08.020 --> 01:04:10.260]  collaboration kasi. Nasa ITB kami noon.\n",
            "[01:04:10.880 --> 01:04:11.860]  Meron silang project\n",
            "[01:04:11.860 --> 01:04:14.100]  sa, ano, sa Crap Science\n",
            "[01:04:14.100 --> 01:04:16.000]  ata, ITB, sa\n",
            "[01:04:16.000 --> 01:04:17.960]  Institute of Plant Breeding.\n",
            "[01:04:18.480 --> 01:04:20.260]  Pero, ibang area kasi yun.\n",
            "[01:04:20.360 --> 01:04:21.480]  Pero, hindi nag-push through.\n",
            "[01:04:22.100 --> 01:04:24.200]  So, I think for, ano, for ACA\n",
            "[01:04:24.200 --> 01:04:26.280]  by, may possibility, kasi this is\n",
            "[01:04:26.280 --> 01:04:28.240]  externally funded, no? Mas malaki\n",
            "[01:04:28.240 --> 01:04:30.340]  yung scope natin. And may, mas may\n",
            "[01:04:30.340 --> 01:04:32.320]  ma-offer talaga kami na, ano, na\n",
            "[01:04:32.320 --> 01:04:34.300]  resources. And\n",
            "[01:04:34.300 --> 01:04:35.780]  now, we'll be hiring,\n",
            "[01:04:36.260 --> 01:04:38.260]  onboarding mga interns kasi\n",
            "[01:04:38.260 --> 01:04:40.340]  from DEE. And we'll provide din\n",
            "[01:04:40.340 --> 01:04:41.480]  yung, ano, ah,\n",
            "[01:04:42.200 --> 01:04:44.180]  yun nga, resources available here. Yun nga,\n",
            "[01:04:44.240 --> 01:04:45.960]  A100 and HPC.\n",
            "[01:04:46.840 --> 01:04:48.400]  Ah, kung saan sila\n",
            "[01:04:48.400 --> 01:04:50.460]  mag-run ng models. So, now,\n",
            "[01:04:50.660 --> 01:04:52.060]  yun po siguro, isa sa mga pwede\n",
            "[01:04:52.060 --> 01:04:54.140]  natin, yung lowest hanging point, if you want to, ano,\n",
            "[01:04:54.340 --> 01:04:56.300]  to, to start yung\n",
            "[01:04:56.300 --> 01:04:58.200]  partnership with ICES na,\n",
            "[01:04:58.300 --> 01:04:59.720]  ano, ah, baby steps muna.\n",
            "[01:05:00.400 --> 01:05:02.200]  Then, from there, yun,\n",
            "[01:05:02.220 --> 01:05:03.740]  we can identify projects together.\n",
            "[01:05:04.720 --> 01:05:06.000]  And, yun nga, particularly\n",
            "[01:05:06.000 --> 01:05:08.660]  example, yung isa naming na-identify\n",
            "[01:05:08.660 --> 01:05:10.340]  na, na-work out dun sa previous\n",
            "[01:05:10.340 --> 01:05:11.540]  project, yung sa ALAM.\n",
            "[01:05:12.420 --> 01:05:14.420]  Um, yung 3D reconstruction\n",
            "[01:05:14.420 --> 01:05:16.300]  ng mga\n",
            "[01:05:16.300 --> 01:05:17.320]  entom species.\n",
            "[01:05:18.420 --> 01:05:20.140]  So, yun, pwede rin ganun yung\n",
            "[01:05:20.140 --> 01:05:21.900]  maging approach if\n",
            "[01:05:22.060 --> 01:05:24.220]  si Sir Val Madrid, no, may mga projects dun siya\n",
            "[01:05:24.220 --> 01:05:25.480]  with, ah,\n",
            "[01:05:26.280 --> 01:05:27.740]  sa ITB, no, pwede rin siyang\n",
            "[01:05:27.740 --> 01:05:29.980]  ipasok dito. Well, we have also yung\n",
            "[01:05:29.980 --> 01:05:31.780]  gulay kasi dun siya interested before\n",
            "[01:05:31.780 --> 01:05:34.160]  sa data ng gulay. Um,\n",
            "[01:05:34.300 --> 01:05:36.240]  pero, mag-end yung project this year.\n",
            "[01:05:36.680 --> 01:05:38.080]  If ever makapag-generate ng\n",
            "[01:05:38.080 --> 01:05:40.100]  data yung gulay, yun, pwede rin siyang\n",
            "[01:05:40.100 --> 01:05:41.420]  gamitin sa\n",
            "[01:05:41.420 --> 01:05:44.200]  College of Agriculture, example.\n",
            "[01:05:44.480 --> 01:05:46.540]  Then, we'll work together with ICES\n",
            "[01:05:46.540 --> 01:05:48.240]  to, to\n",
            "[01:05:48.240 --> 01:05:50.220]  develop, um, yun, for that\n",
            "[01:05:50.220 --> 01:05:52.000]  particular use case. Siguro yun yung\n",
            "[01:05:52.060 --> 01:05:54.340]  isa na naisip kong\n",
            "[01:05:54.340 --> 01:05:56.080]  ano, parang lowest hanging fruit\n",
            "[01:05:56.080 --> 01:05:58.520]  that we can, ano, um,\n",
            "[01:05:58.800 --> 01:05:59.880]  push through, no, with the\n",
            "[01:05:59.880 --> 01:06:02.200]  project ACABA, eh, program ACABA\n",
            "[01:06:02.200 --> 01:06:02.660]  and I.\n",
            "[01:06:05.400 --> 01:06:06.140]  Thank you,\n",
            "[01:06:06.260 --> 01:06:08.160]  Rox. Ah, Sir\n",
            "[01:06:08.160 --> 01:06:08.520]  Arian?\n",
            "[01:06:11.560 --> 01:06:12.500]  Ah, yun nga,\n",
            "[01:06:12.840 --> 01:06:14.240]  ah, we can start small,\n",
            "[01:06:14.420 --> 01:06:15.880]  pero yung issue talaga na\n",
            "[01:06:15.880 --> 01:06:18.040]  encounter namin dun sa Wood-Eye,\n",
            "[01:06:18.800 --> 01:06:20.140]  pag may nanghingi na ng data,\n",
            "[01:06:20.940 --> 01:06:21.880]  so, we cannot decide,\n",
            "[01:06:22.060 --> 01:06:24.020]  decide ka agad, kasi, ang naghirap\n",
            "[01:06:24.020 --> 01:06:26.020]  talaga nun, yung mga taga-forestry, in fact,\n",
            "[01:06:26.100 --> 01:06:27.360]  we encourage them na\n",
            "[01:06:27.360 --> 01:06:30.240]  AI is becoming mechanistic na,\n",
            "[01:06:30.760 --> 01:06:31.780]  but the\n",
            "[01:06:31.780 --> 01:06:33.860]  efforts of the curator\n",
            "[01:06:33.860 --> 01:06:35.900]  of the data, ah,\n",
            "[01:06:36.060 --> 01:06:38.020]  well, mabait kami sa kanila, sinabi namin, sila\n",
            "[01:06:38.020 --> 01:06:39.900]  talaga yung may hawak ng gold data,\n",
            "[01:06:40.080 --> 01:06:42.240]  so, ingat lang, sabi ko, sa pag-share.\n",
            "[01:06:42.840 --> 01:06:43.720]  Huwag agad-agad.\n",
            "[01:06:43.860 --> 01:06:45.940]  Although, as public, ibabalance mo rin, eh,\n",
            "[01:06:45.940 --> 01:06:47.900]  kasi as a public university, we are\n",
            "[01:06:47.900 --> 01:06:49.040]  obliged to share, no?\n",
            "[01:06:49.500 --> 01:06:52.020]  Pero, dapat may ano talaga. Kaya siguro,\n",
            "[01:06:52.060 --> 01:06:53.920]  dito, sa, ano natin, sa\n",
            "[01:06:53.920 --> 01:06:56.160]  COLAB, maganda talaga na with the use cases,\n",
            "[01:06:56.280 --> 01:06:57.980]  pag meron na kasi talagang actual data\n",
            "[01:06:57.980 --> 01:07:00.020]  may use na, baka nga darating\n",
            "[01:07:00.020 --> 01:07:02.280]  ang time, we can apply like yung mga lumang\n",
            "[01:07:02.280 --> 01:07:04.520]  method na statistical database,\n",
            "[01:07:05.040 --> 01:07:05.840]  na we can provide\n",
            "[01:07:05.840 --> 01:07:07.540]  researcher ka agad with a ready\n",
            "[01:07:07.540 --> 01:07:10.200]  accessible data, pero without exposing\n",
            "[01:07:10.200 --> 01:07:12.000]  the, ano rin,\n",
            "[01:07:12.100 --> 01:07:13.980]  the IP of the owner\n",
            "[01:07:13.980 --> 01:07:15.980]  of the data. So, isa yun sa mga\n",
            "[01:07:15.980 --> 01:07:16.780]  magandang\n",
            "[01:07:16.780 --> 01:07:19.380]  papupuntahan, kasi\n",
            "[01:07:19.380 --> 01:07:21.900]  madali lang sabihin, pero pag when the\n",
            "[01:07:21.900 --> 01:07:23.860]  rubber meets the road na may naihingi na ng data,\n",
            "[01:07:23.980 --> 01:07:25.380]  actually, taga-dilim man yun nang hingi,\n",
            "[01:07:25.900 --> 01:07:27.840]  hindi rin kayo maka-decide, both ICS\n",
            "[01:07:27.840 --> 01:07:29.880]  and CFNR cannot\n",
            "[01:07:29.880 --> 01:07:31.920]  decide. So, siguro, with that, we can,\n",
            "[01:07:32.140 --> 01:07:33.380]  ano, paano ba yung portion\n",
            "[01:07:33.380 --> 01:07:36.020]  ng data na ma-share?\n",
            "[01:07:36.640 --> 01:07:37.940]  There are, yan, meron akong\n",
            "[01:07:37.940 --> 01:07:39.660]  naisip na idea. Actually,\n",
            "[01:07:40.480 --> 01:07:41.780]  pinapagawa din sa amin ito\n",
            "[01:07:41.780 --> 01:07:43.520]  ni Doc Franze, yung\n",
            "[01:07:43.520 --> 01:07:45.860]  federated learning, baka this is something,\n",
            "[01:07:45.960 --> 01:07:47.800]  yun yung pwede natin ipilot, UPLB\n",
            "[01:07:47.800 --> 01:07:49.880]  and ASTI. Kasi sa federated\n",
            "[01:07:49.880 --> 01:07:51.340]  learning po, ano,\n",
            "[01:07:51.900 --> 01:07:53.980]  magte-train tayo, both\n",
            "[01:07:53.980 --> 01:07:56.000]  parehas magte-train, without even sharing\n",
            "[01:07:56.000 --> 01:07:57.800]  the data sets. Like, for example,\n",
            "[01:07:57.940 --> 01:08:00.080]  meron kaming data sets ng Wood AI\n",
            "[01:08:00.080 --> 01:08:02.100]  na nakuha namin na,\n",
            "[01:08:02.140 --> 01:08:04.140]  ano, tapos kayo din meron, but you don't\n",
            "[01:08:04.140 --> 01:08:06.120]  want to share your data sets,\n",
            "[01:08:06.460 --> 01:08:08.120]  you can actually train models,\n",
            "[01:08:08.620 --> 01:08:09.940]  tapos yung, ang\n",
            "[01:08:09.940 --> 01:08:11.820]  isi-share lang natin, ay, ang\n",
            "[01:08:11.820 --> 01:08:14.220]  isi-share lang natin is yung mga model weights,\n",
            "[01:08:14.820 --> 01:08:15.820]  hindi yung data mismo,\n",
            "[01:08:15.820 --> 01:08:17.420]  hindi lalabas. Oh, yeah, yeah, yeah.\n",
            "[01:08:17.740 --> 01:08:19.800]  Yeah, parang gano'n, federated learning\n",
            "[01:08:19.800 --> 01:08:21.840]  yung approach. That is something,\n",
            "[01:08:21.900 --> 01:08:24.020]  that we can look into, that we can actually\n",
            "[01:08:24.020 --> 01:08:25.900]  work on, siguro po.\n",
            "[01:08:25.960 --> 01:08:28.420]  That's one, ano, yung naiisip ko.\n",
            "[01:08:30.220 --> 01:08:31.140]  Okay, thank you.\n",
            "[01:08:32.300 --> 01:08:33.520]  Yung sa internship,\n",
            "[01:08:33.860 --> 01:08:35.720]  tama-tama, hindi pa ata\n",
            "[01:08:35.720 --> 01:08:37.420]  deadline na naman, Myla.\n",
            "[01:08:38.300 --> 01:08:39.980]  Sa internship, open\n",
            "[01:08:39.980 --> 01:08:41.580]  kasi ang application for\n",
            "[01:08:41.580 --> 01:08:42.640]  companies, eh.\n",
            "[01:08:43.580 --> 01:08:45.640]  Although, ang\n",
            "[01:08:45.640 --> 01:08:47.680]  understanding ko, ma'am, parang\n",
            "[01:08:47.680 --> 01:08:48.960]  dapat may MOU?\n",
            "[01:08:50.780 --> 01:08:50.960]  Ayan.\n",
            "[01:08:51.900 --> 01:08:55.700]  Pero may MOU na ata\n",
            "[01:08:55.700 --> 01:08:57.480]  ang UPLB with us, di ba?\n",
            "[01:08:59.000 --> 01:09:00.080]  Covered ba yun?\n",
            "[01:09:01.640 --> 01:09:02.240]  Internship?\n",
            "[01:09:02.980 --> 01:09:03.800]  I-check ko pa\n",
            "[01:09:03.800 --> 01:09:05.500]  yung fine print,\n",
            "[01:09:05.880 --> 01:09:07.420]  pero may share ko lang po,\n",
            "[01:09:07.780 --> 01:09:10.000]  we have already experience na\n",
            "[01:09:10.000 --> 01:09:11.740]  kumuha kami ng OJT\n",
            "[01:09:11.740 --> 01:09:13.120]  from UPLB.\n",
            "[01:09:13.660 --> 01:09:15.220]  Tama, di ba, Kurt and Jom?\n",
            "[01:09:15.220 --> 01:09:16.960]  Meron na tayong mga OJT\n",
            "[01:09:16.960 --> 01:09:18.460]  before from UPLB.\n",
            "[01:09:19.000 --> 01:09:20.680]  Yes po, sir, meron po.\n",
            "[01:09:21.900 --> 01:09:23.040]  Nakalagay ba sa...\n",
            "[01:09:23.040 --> 01:09:29.380]  Yes, nakalagay po doon\n",
            "[01:09:29.380 --> 01:09:30.700]  and dagdag ko lang po na yung\n",
            "[01:09:30.700 --> 01:09:32.280]  isa po naming intern was\n",
            "[01:09:32.280 --> 01:09:34.860]  able to do his thesis\n",
            "[01:09:34.860 --> 01:09:36.120]  po with us and\n",
            "[01:09:36.120 --> 01:09:37.700]  actually, na-defend na po niya\n",
            "[01:09:37.700 --> 01:09:40.120]  nitong May po and gagraduate na po.\n",
            "[01:09:41.600 --> 01:09:43.020]  Anong topic yun?\n",
            "[01:09:44.380 --> 01:09:46.040]  Focus talking po siya\n",
            "[01:09:46.040 --> 01:09:48.760]  ng images po for macro shots po.\n",
            "[01:09:49.800 --> 01:09:50.320]  Hmm.\n",
            "[01:09:51.900 --> 01:09:53.440]  Pwede pumingi na lang ng kopya\n",
            "[01:09:53.440 --> 01:09:54.500]  ng MOU din.\n",
            "[01:09:55.980 --> 01:09:56.820]  Sige, ma'am.\n",
            "[01:09:57.060 --> 01:09:58.160]  Kurt can send\n",
            "[01:09:58.160 --> 01:10:00.720]  a copy of the MOU.\n",
            "[01:10:00.940 --> 01:10:03.520]  And then, paano ba ang procedure,\n",
            "[01:10:03.740 --> 01:10:04.320]  ma'am, Myla?\n",
            "[01:10:04.920 --> 01:10:07.340]  Kung halimbawa, covered naman ng MOU,\n",
            "[01:10:09.040 --> 01:10:09.680]  kailangan natin\n",
            "[01:10:09.680 --> 01:10:11.040]  mag-apply si Asti?\n",
            "[01:10:12.740 --> 01:10:13.000]  Oo.\n",
            "[01:10:13.000 --> 01:10:15.360]  Meron lang po sana kaming\n",
            "[01:10:15.360 --> 01:10:18.920]  company profile form\n",
            "[01:10:18.920 --> 01:10:21.800]  and then ilalagay po doon.\n",
            "[01:10:21.900 --> 01:10:23.160]  Ano exactly yung\n",
            "[01:10:23.160 --> 01:10:24.340]  paggagawin\n",
            "[01:10:24.340 --> 01:10:26.260]  sa student?\n",
            "[01:10:26.640 --> 01:10:27.500]  Yun lang naman, ho.\n",
            "[01:10:27.580 --> 01:10:28.160]  Mabilis na.\n",
            "[01:10:28.860 --> 01:10:30.520]  Okay lang po kaya, ma'am?\n",
            "[01:10:30.700 --> 01:10:32.240]  Kasi parang\n",
            "[01:10:32.240 --> 01:10:33.880]  from the get-go,\n",
            "[01:10:34.020 --> 01:10:34.920]  bangitin ko na po,\n",
            "[01:10:35.020 --> 01:10:35.900]  na dito sa Asti,\n",
            "[01:10:35.980 --> 01:10:36.740]  ang internship po,\n",
            "[01:10:36.800 --> 01:10:37.480]  hindi po paid.\n",
            "[01:10:37.600 --> 01:10:38.880]  Wala po kaming pansweldo\n",
            "[01:10:38.880 --> 01:10:39.660]  sa mga ano.\n",
            "[01:10:39.820 --> 01:10:41.520]  Okay lang po kaya sa student yun.\n",
            "[01:10:41.940 --> 01:10:43.840]  Pwede natin sigurong i-work around\n",
            "[01:10:43.840 --> 01:10:45.560]  na some of them can stay here\n",
            "[01:10:45.560 --> 01:10:47.000]  and report sa ICS\n",
            "[01:10:47.000 --> 01:10:49.540]  kung parang siya may work from home.\n",
            "[01:10:49.640 --> 01:10:50.580]  Kasi galing kami from\n",
            "[01:10:50.580 --> 01:10:51.780]  purely online,\n",
            "[01:10:51.900 --> 01:10:53.440]  internship during pandemic.\n",
            "[01:10:53.660 --> 01:10:54.680]  Kung okay naman sa inyo,\n",
            "[01:10:55.480 --> 01:10:56.500]  i-indicate na lang\n",
            "[01:10:56.500 --> 01:10:58.040]  kung kailan nyo talaga sila required.\n",
            "[01:10:58.160 --> 01:10:59.320]  Kasi kawawa nga din naman\n",
            "[01:10:59.320 --> 01:11:00.060]  ng student, no?\n",
            "[01:11:00.260 --> 01:11:01.860]  Mauubos yung pagbabiyahe.\n",
            "[01:11:02.220 --> 01:11:02.400]  Oo.\n",
            "[01:11:02.900 --> 01:11:05.000]  Or magre-rent pa ba sila dyan?\n",
            "[01:11:05.140 --> 01:11:06.100]  At yung iba talaga sa kanila\n",
            "[01:11:06.100 --> 01:11:07.360]  so far sa invitation ko,\n",
            "[01:11:07.440 --> 01:11:09.520]  they considered monetary benefits\n",
            "[01:11:09.520 --> 01:11:10.900]  kasi iba na talaga ngayon.\n",
            "[01:11:11.820 --> 01:11:12.820]  Nag-beg of siya,\n",
            "[01:11:12.900 --> 01:11:13.800]  maganda yung offer ko\n",
            "[01:11:13.800 --> 01:11:15.220]  for Sinter Labs internship.\n",
            "[01:11:15.520 --> 01:11:16.100]  Pero sabi niya,\n",
            "[01:11:16.140 --> 01:11:17.200]  Sir, sorry, I need to\n",
            "[01:11:17.200 --> 01:11:19.480]  earn a living ngayon.\n",
            "[01:11:19.740 --> 01:11:21.060]  Gagamitin niya yung practicum niya\n",
            "[01:11:21.060 --> 01:11:21.260]  to...\n",
            "[01:11:21.900 --> 01:11:23.400]  be compensated.\n",
            "[01:11:23.820 --> 01:11:25.320]  At mataas ang offer sa kanila, ha?\n",
            "[01:11:25.360 --> 01:11:26.120]  Last time sa IRI,\n",
            "[01:11:26.220 --> 01:11:27.640]  ang offer sa kanila is ano eh,\n",
            "[01:11:28.260 --> 01:11:29.240]  natigil lang kasi yung\n",
            "[01:11:29.240 --> 01:11:29.960]  COICA internship.\n",
            "[01:11:30.080 --> 01:11:31.660]  $300 per month.\n",
            "[01:11:32.340 --> 01:11:32.780]  Oo.\n",
            "[01:11:32.780 --> 01:11:33.220]  Wow.\n",
            "[01:11:34.700 --> 01:11:35.180]  Interns.\n",
            "[01:11:36.080 --> 01:11:36.560]  Practicum.\n",
            "[01:11:37.040 --> 01:11:38.240]  Saka, I remember kasi\n",
            "[01:11:38.240 --> 01:11:39.460]  naalala ko noon noong time.\n",
            "[01:11:39.760 --> 01:11:40.940]  Kasi nag-UPLB din ako\n",
            "[01:11:40.940 --> 01:11:41.820]  for three years.\n",
            "[01:11:42.100 --> 01:11:43.000]  Matagal na 19.\n",
            "[01:11:43.940 --> 01:11:45.420]  Applied math din po ako, ma'am.\n",
            "[01:11:45.520 --> 01:11:46.500]  Applied math din po ako.\n",
            "[01:11:47.240 --> 01:11:48.620]  Sa ano din,\n",
            "[01:11:48.700 --> 01:11:49.340]  IMSP.\n",
            "[01:11:49.640 --> 01:11:50.400]  Naalala ko noon kasi\n",
            "[01:11:50.400 --> 01:11:51.620]  nakita ko yung com-sign na\n",
            "[01:11:51.620 --> 01:11:51.740]  ano,\n",
            "[01:11:51.900 --> 01:11:52.580]  meron talaga doon\n",
            "[01:11:52.580 --> 01:11:53.700]  na course na practicum.\n",
            "[01:11:53.940 --> 01:11:54.960]  Actually, sa amin din yata.\n",
            "[01:11:55.160 --> 01:11:56.380]  Sa pag may\n",
            "[01:11:56.380 --> 01:11:57.620]  applied math,\n",
            "[01:11:57.760 --> 01:11:58.840]  ang pag OR kami,\n",
            "[01:11:58.980 --> 01:11:59.960]  may practicum din kami\n",
            "[01:11:59.960 --> 01:12:00.620]  na ano,\n",
            "[01:12:01.260 --> 01:12:02.060]  sa syllabus.\n",
            "[01:12:02.220 --> 01:12:02.820]  So, yun po ba yun?\n",
            "[01:12:02.880 --> 01:12:03.900]  Yung practicum na yun\n",
            "[01:12:03.900 --> 01:12:04.360]  na course?\n",
            "[01:12:06.020 --> 01:12:06.780]  Meron kami.\n",
            "[01:12:07.240 --> 01:12:07.600]  Opo.\n",
            "[01:12:10.420 --> 01:12:11.120]  Yes, ma'am.\n",
            "[01:12:11.200 --> 01:12:12.160]  Mayla nakarace\n",
            "[01:12:12.160 --> 01:12:12.660]  ng hand.\n",
            "[01:12:15.220 --> 01:12:15.900]  Yes, oo.\n",
            "[01:12:16.120 --> 01:12:16.900]  Yung pong\n",
            "[01:12:16.900 --> 01:12:18.660]  nasa chatbox na po\n",
            "[01:12:18.660 --> 01:12:19.200]  yung ano,\n",
            "[01:12:19.980 --> 01:12:20.840]  yung link.\n",
            "[01:12:21.260 --> 01:12:21.880]  Tapos, kung pwede,\n",
            "[01:12:21.900 --> 01:12:22.580]  pwede po sana\n",
            "[01:12:22.580 --> 01:12:24.040]  ma-fill up\n",
            "[01:12:24.040 --> 01:12:25.180]  and then\n",
            "[01:12:25.180 --> 01:12:26.520]  i-process namin\n",
            "[01:12:26.520 --> 01:12:27.560]  agad pagka\n",
            "[01:12:27.560 --> 01:12:28.500]  nandito na.\n",
            "[01:12:28.960 --> 01:12:29.460]  Kasi, ho,\n",
            "[01:12:29.520 --> 01:12:30.440]  ang maganda dito sa\n",
            "[01:12:30.440 --> 01:12:31.360]  practicum,\n",
            "[01:12:32.000 --> 01:12:33.180]  magsimula ng\n",
            "[01:12:33.180 --> 01:12:33.980]  June 16\n",
            "[01:12:33.980 --> 01:12:36.660]  at kung matuloy pa natin\n",
            "[01:12:36.660 --> 01:12:37.380]  ng SP,\n",
            "[01:12:38.200 --> 01:12:39.200]  by December,\n",
            "[01:12:39.340 --> 01:12:40.580]  may proposal siya\n",
            "[01:12:40.580 --> 01:12:41.700]  and then\n",
            "[01:12:41.700 --> 01:12:43.680]  graduation ng\n",
            "[01:12:43.680 --> 01:12:44.060]  May,\n",
            "[01:12:44.280 --> 01:12:45.040]  next year,\n",
            "[01:12:45.280 --> 01:12:45.620]  June,\n",
            "[01:12:46.480 --> 01:12:47.500]  meron na pong\n",
            "[01:12:47.500 --> 01:12:47.900]  product,\n",
            "[01:12:48.660 --> 01:12:49.620]  may delivery na.\n",
            "[01:12:50.060 --> 01:12:51.100]  So, pwede nang\n",
            "[01:12:51.100 --> 01:12:51.880]  i-showcase yun.\n",
            "[01:12:51.900 --> 01:12:52.680]  Kung ano,\n",
            "[01:12:52.820 --> 01:12:53.980]  kung maka-umpisa ng\n",
            "[01:12:53.980 --> 01:12:54.380]  June.\n",
            "[01:12:56.080 --> 01:12:57.480]  Yun yung pwedeng\n",
            "[01:12:57.480 --> 01:12:58.280]  mangyari, ho.\n",
            "[01:13:00.080 --> 01:13:01.620]  So, parang isang taon yun.\n",
            "[01:13:01.960 --> 01:13:02.260]  Ano?\n",
            "[01:13:02.520 --> 01:13:03.780]  So, practicum.\n",
            "[01:13:04.140 --> 01:13:04.440]  Tapos,\n",
            "[01:13:05.160 --> 01:13:06.520]  by December,\n",
            "[01:13:06.700 --> 01:13:07.420]  ano, proposal,\n",
            "[01:13:07.660 --> 01:13:07.840]  ano?\n",
            "[01:13:08.620 --> 01:13:09.480]  And then,\n",
            "[01:13:09.620 --> 01:13:11.040]  final implementation\n",
            "[01:13:11.040 --> 01:13:12.060]  hanggang\n",
            "[01:13:12.060 --> 01:13:13.060]  mga ganito,\n",
            "[01:13:13.280 --> 01:13:13.540]  May.\n",
            "[01:13:14.940 --> 01:13:15.560]  As long as,\n",
            "[01:13:15.560 --> 01:13:15.760]  ano,\n",
            "[01:13:16.040 --> 01:13:17.640]  as long as the\n",
            "[01:13:17.640 --> 01:13:18.400]  project, siguro,\n",
            "[01:13:18.480 --> 01:13:19.500]  ilang years nga project\n",
            "[01:13:19.500 --> 01:13:20.120]  na akabay?\n",
            "[01:13:20.560 --> 01:13:21.320]  Three years po.\n",
            "[01:13:21.320 --> 01:13:21.860]  Ayun.\n",
            "[01:13:21.900 --> 01:13:22.900]  Every year,\n",
            "[01:13:22.900 --> 01:13:23.900]  may ano tayo.\n",
            "[01:13:23.900 --> 01:13:24.900]  We will\n",
            "[01:13:24.900 --> 01:13:25.900]  have at least\n",
            "[01:13:25.900 --> 01:13:26.900]  three to five\n",
            "[01:13:26.900 --> 01:13:27.900]  interns for akabay.\n",
            "[01:13:27.900 --> 01:13:29.900]  Maganda yan.\n",
            "[01:13:29.900 --> 01:13:30.900]  Kasi, every year din,\n",
            "[01:13:30.900 --> 01:13:31.900]  may SP sila\n",
            "[01:13:31.900 --> 01:13:32.900]  and TC.\n",
            "[01:13:32.900 --> 01:13:33.900]  Sa three to five nyan,\n",
            "[01:13:33.900 --> 01:13:34.900]  may tumuloy lang na\n",
            "[01:13:34.900 --> 01:13:35.900]  isa or dalawa,\n",
            "[01:13:35.900 --> 01:13:36.900]  panalo na yung\n",
            "[01:13:36.900 --> 01:13:37.900]  promotion mo sa\n",
            "[01:13:37.900 --> 01:13:38.900]  internship.\n",
            "[01:13:38.900 --> 01:13:39.900]  Kasi, some of them,\n",
            "[01:13:39.900 --> 01:13:40.900]  hindi naman sila tumutuloy.\n",
            "[01:13:40.900 --> 01:13:41.900]  Based experience namin\n",
            "[01:13:41.900 --> 01:13:42.900]  sa IRI,\n",
            "[01:13:42.900 --> 01:13:43.900]  some of them will\n",
            "[01:13:43.900 --> 01:13:45.900]  pursue a different topic.\n",
            "[01:13:45.900 --> 01:13:46.900]  Pero, pag mayroon lang\n",
            "[01:13:46.900 --> 01:13:48.900]  dalawa na tumuloy dyan,\n",
            "[01:13:48.900 --> 01:13:49.900]  tapos, papagaanin din natin,\n",
            "[01:13:49.900 --> 01:13:50.900]  tapos, papagaanin din natin,\n",
            "[01:13:50.900 --> 01:13:51.900]  tapos, papagaanin din natin,\n",
            "[01:13:51.900 --> 01:13:52.900]  ang suggestion ko,\n",
            "[01:13:52.900 --> 01:13:54.900]  that's also an opportunity\n",
            "[01:13:54.900 --> 01:13:56.900]  for us to really educate\n",
            "[01:13:56.900 --> 01:13:57.900]  our student interns\n",
            "[01:13:57.900 --> 01:13:59.900]  by training them\n",
            "[01:13:59.900 --> 01:14:01.900]  in the first two weeks.\n",
            "[01:14:01.900 --> 01:14:02.900]  And then, come up with\n",
            "[01:14:02.900 --> 01:14:04.900]  a proof of concept lang.\n",
            "[01:14:04.900 --> 01:14:06.900]  Tapos, ituloy nila sa SP\n",
            "[01:14:06.900 --> 01:14:07.900]  yung mga seriously\n",
            "[01:14:07.900 --> 01:14:10.900]  engaged dun sa practicum.\n",
            "[01:14:10.900 --> 01:14:11.900]  Kasi, mahirap din\n",
            "[01:14:11.900 --> 01:14:12.900]  mag-expect ng sobrang\n",
            "[01:14:12.900 --> 01:14:13.900]  bigat sa practicum na,\n",
            "[01:14:13.900 --> 01:14:15.900]  even 240 hours ng DOST\n",
            "[01:14:15.900 --> 01:14:17.900]  kung DOST scholar sila.\n",
            "[01:14:17.900 --> 01:14:19.900]  So, maganda naman ang kinalabasan\n",
            "[01:14:19.900 --> 01:14:20.900]  na parang\n",
            "[01:14:20.900 --> 01:14:22.900]  initial training deployment.\n",
            "[01:14:22.900 --> 01:14:23.900]  Tapos, SPTCs yung mga\n",
            "[01:14:23.900 --> 01:14:25.900]  tutuloy for one year.\n",
            "[01:14:27.900 --> 01:14:28.900]  I'm just thinking\n",
            "[01:14:28.900 --> 01:14:29.900]  ahead lang po siguro.\n",
            "[01:14:29.900 --> 01:14:30.900]  Baka nakikita ko,\n",
            "[01:14:30.900 --> 01:14:31.900]  kunyari,\n",
            "[01:14:31.900 --> 01:14:33.900]  after niyo po ma-review\n",
            "[01:14:33.900 --> 01:14:35.900]  Doc Rachel yung MOU\n",
            "[01:14:35.900 --> 01:14:36.900]  na isa send ni Kurt,\n",
            "[01:14:36.900 --> 01:14:38.900]  baka kailanganin natin,\n",
            "[01:14:38.900 --> 01:14:39.900]  hindi ko alam kung kakailanganin\n",
            "[01:14:39.900 --> 01:14:41.900]  ng addendum to specify\n",
            "[01:14:41.900 --> 01:14:43.900]  itong mga pinag-uusapan natin\n",
            "[01:14:43.900 --> 01:14:45.900]  ngayon na possible na\n",
            "[01:14:45.900 --> 01:14:47.900]  collaboration like this internship.\n",
            "[01:14:47.900 --> 01:14:48.900]  I'm not sure,\n",
            "[01:14:48.900 --> 01:14:50.900]  baka kailangan natin i-\n",
            "[01:14:50.900 --> 01:14:52.900]  lagay iyon din sa black and white\n",
            "[01:14:52.900 --> 01:14:54.900]  as an addendum to the\n",
            "[01:14:54.900 --> 01:14:57.900]  originally drafted\n",
            "[01:14:57.900 --> 01:15:00.900]  or originally signed MOU.\n",
            "[01:15:03.900 --> 01:15:05.900]  Naka-raise yung hand ni Mam Myla.\n",
            "[01:15:05.900 --> 01:15:06.900]  Mam Myla?\n",
            "[01:15:06.900 --> 01:15:08.900]  Oo. Kasi ang originally,\n",
            "[01:15:08.900 --> 01:15:10.900]  kaya ako nag-raise ng hand.\n",
            "[01:15:10.900 --> 01:15:13.900]  Kasi yung Intelligent Systems Cluster,\n",
            "[01:15:13.900 --> 01:15:15.900]  tama po ba yan?\n",
            "[01:15:17.900 --> 01:15:19.900]  Napadala niya rin sa amin ito,\n",
            "[01:15:19.900 --> 01:15:21.900]  si Doc Rachel na po.\n",
            "[01:15:21.900 --> 01:15:22.900]  Ang UP,\n",
            "[01:15:22.900 --> 01:15:24.900]  UP System kasi merong\n",
            "[01:15:24.900 --> 01:15:26.900]  Intelligent Systems Center.\n",
            "[01:15:26.900 --> 01:15:28.900]  So, meron din grant silang\n",
            "[01:15:28.900 --> 01:15:30.900]  pinaprovide\n",
            "[01:15:30.900 --> 01:15:33.900]  kung may research.\n",
            "[01:15:33.900 --> 01:15:34.900]  So, it means po,\n",
            "[01:15:34.900 --> 01:15:36.900]  parang maging pwedeng\n",
            "[01:15:36.900 --> 01:15:38.900]  involved din\n",
            "[01:15:38.900 --> 01:15:41.900]  sa proposal.\n",
            "[01:15:41.900 --> 01:15:42.900]  Meron na ho bang,\n",
            "[01:15:42.900 --> 01:15:44.900]  Sir Elmer, na\n",
            "[01:15:44.900 --> 01:15:47.900]  existing na ISC,\n",
            "[01:15:47.900 --> 01:15:48.900]  yung Intelligent Systems Cluster\n",
            "[01:15:48.900 --> 01:15:50.900]  na mga projects.\n",
            "[01:15:50.900 --> 01:15:51.900]  Tapos kayo din po,\n",
            "[01:15:51.900 --> 01:15:53.900]  involved din po?\n",
            "[01:15:53.900 --> 01:15:56.900]  Hindi po ako privy doon sa\n",
            "[01:15:56.900 --> 01:15:58.900]  Intelligent Systems Cluster\n",
            "[01:15:58.900 --> 01:16:00.900]  ng UP Diliman,\n",
            "[01:16:00.900 --> 01:16:02.900]  ng UP System.\n",
            "[01:16:02.900 --> 01:16:04.900]  Ah, okay.\n",
            "[01:16:06.900 --> 01:16:08.900]  Bali ang Asti,\n",
            "[01:16:08.900 --> 01:16:10.900]  Bali may projects kayo, diba?\n",
            "[01:16:10.900 --> 01:16:12.900]  So, ito yung mga pinresent nyo po, diba?\n",
            "[01:16:12.900 --> 01:16:13.900]  Apo.\n",
            "[01:16:13.900 --> 01:16:15.900]  Tapos, ang hinahanap natin\n",
            "[01:16:15.900 --> 01:16:17.900]  is possible involvement ba\n",
            "[01:16:17.900 --> 01:16:19.900]  ng ICS in these projects?\n",
            "[01:16:19.900 --> 01:16:21.900]  Ganun ba yun?\n",
            "[01:16:21.900 --> 01:16:22.900]  Ano po?\n",
            "[01:16:22.900 --> 01:16:23.900]  Bali,\n",
            "[01:16:23.900 --> 01:16:24.900]  not necessarily,\n",
            "[01:16:24.900 --> 01:16:25.900]  ako po,\n",
            "[01:16:25.900 --> 01:16:26.900]  specifically for the\n",
            "[01:16:26.900 --> 01:16:28.900]  Akabay project po.\n",
            "[01:16:28.900 --> 01:16:29.900]  Like,\n",
            "[01:16:29.900 --> 01:16:31.900]  possible\n",
            "[01:16:31.900 --> 01:16:32.900]  research collaboration\n",
            "[01:16:32.900 --> 01:16:34.900]  or possible use case po\n",
            "[01:16:34.900 --> 01:16:36.900]  ng mga AI.\n",
            "[01:16:36.900 --> 01:16:37.900]  Yun po, yung kanina.\n",
            "[01:16:37.900 --> 01:16:38.900]  Siguro,\n",
            "[01:16:38.900 --> 01:16:39.900]  i-revisit ko po yung\n",
            "[01:16:39.900 --> 01:16:40.900]  questionnaire ni Ma'am Joanne\n",
            "[01:16:40.900 --> 01:16:41.900]  kanina.\n",
            "[01:16:41.900 --> 01:16:42.900]  Na,\n",
            "[01:16:42.900 --> 01:16:43.900]  eto,\n",
            "[01:16:43.900 --> 01:16:44.900]  Student Internship\n",
            "[01:16:44.900 --> 01:16:46.900]  Collaborative Research Projects.\n",
            "[01:16:46.900 --> 01:16:48.900]  Eto po, dito po,\n",
            "[01:16:48.900 --> 01:16:49.900]  ah,\n",
            "[01:16:49.900 --> 01:16:51.900]  pwede itong under Akabay po, no?\n",
            "[01:16:51.900 --> 01:16:54.900]  Tapos, conduct of lectures and symposia.\n",
            "[01:16:54.900 --> 01:16:56.900]  We're also, ano po kasi,\n",
            "[01:16:56.900 --> 01:16:57.900]  ah, parang hosting\n",
            "[01:16:57.900 --> 01:16:59.900]  mga lecture series,\n",
            "[01:16:59.900 --> 01:17:01.900]  exchange of academic information and materials,\n",
            "[01:17:01.900 --> 01:17:02.900]  and promote\n",
            "[01:17:02.900 --> 01:17:05.900]  other academic cooperation po.\n",
            "[01:17:05.900 --> 01:17:07.900]  So, halimbawa, sir, yung\n",
            "[01:17:07.900 --> 01:17:08.900]  wood, ano,\n",
            "[01:17:08.900 --> 01:17:09.900]  wood project,\n",
            "[01:17:09.900 --> 01:17:12.900]  pwede rin yun sa Akabay, diba?\n",
            "[01:17:12.900 --> 01:17:14.900]  Apo, Akabay po talaga siya. Oo, yun.\n",
            "[01:17:14.900 --> 01:17:15.900]  Yung kay Sir Arya.\n",
            "[01:17:15.900 --> 01:17:16.900]  Yung kay Sir Arya.\n",
            "[01:17:16.900 --> 01:17:17.900]  Oo.\n",
            "[01:17:17.900 --> 01:17:18.900]  Okay.\n",
            "[01:17:18.900 --> 01:17:21.900]  Pwede tayo mag-research, collaborate po doon.\n",
            "[01:17:21.900 --> 01:17:22.900]  Kakailangan yun po namin.\n",
            "[01:17:22.900 --> 01:17:23.900]  At least, meron na.\n",
            "[01:17:23.900 --> 01:17:24.900]  Kasi,\n",
            "[01:17:24.900 --> 01:17:26.900]  yun po yung isa naming parang,\n",
            "[01:17:26.900 --> 01:17:27.900]  hindi naman pangako,\n",
            "[01:17:27.900 --> 01:17:28.900]  kumbaga,\n",
            "[01:17:28.900 --> 01:17:30.900]  parang expectation sa amin\n",
            "[01:17:30.900 --> 01:17:32.900]  from ng FPRDI,\n",
            "[01:17:32.900 --> 01:17:34.900]  na makapag-develop kami ng wood AI,\n",
            "[01:17:34.900 --> 01:17:35.900]  na meron na po pala kayo,\n",
            "[01:17:35.900 --> 01:17:36.900]  nasimulan.\n",
            "[01:17:36.900 --> 01:17:38.900]  At least, ano po, oo.\n",
            "[01:17:38.900 --> 01:17:39.900]  Oo, sir, yun ay\n",
            "[01:17:39.900 --> 01:17:41.900]  in collaboration with yun nga.\n",
            "[01:17:41.900 --> 01:17:43.900]  May owner kasi.\n",
            "[01:17:43.900 --> 01:17:44.900]  Oo.\n",
            "[01:17:44.900 --> 01:17:45.900]  On record ba to?\n",
            "[01:17:45.900 --> 01:17:47.900]  Oo, naka-record.\n",
            "[01:17:47.900 --> 01:17:48.900]  Meron sila.\n",
            "[01:17:48.900 --> 01:17:49.900]  Meron din yan sila, actually.\n",
            "[01:17:49.900 --> 01:17:50.900]  Meron din yan sila, actually.\n",
            "[01:17:50.900 --> 01:17:51.900]  May domain owner.\n",
            "[01:17:51.900 --> 01:17:52.900]  Naunahan lang namin ng ANN,\n",
            "[01:17:52.900 --> 01:17:53.900]  kasi, siyempre,\n",
            "[01:17:53.900 --> 01:17:56.900]  sa ICS nakicollaborate yung si FNRF.\n",
            "[01:17:56.900 --> 01:17:57.900]  Pero, alam kong FPRDI,\n",
            "[01:17:57.900 --> 01:17:59.900]  meron din yan sila,\n",
            "[01:17:59.900 --> 01:18:00.900]  na si,\n",
            "[01:18:00.900 --> 01:18:02.900]  taga ito,\n",
            "[01:18:02.900 --> 01:18:04.900]  CNN based.\n",
            "[01:18:04.900 --> 01:18:06.900]  O baka yung ibang grupo,\n",
            "[01:18:06.900 --> 01:18:07.900]  anong kausap ko?\n",
            "[01:18:07.900 --> 01:18:08.900]  Kasi,\n",
            "[01:18:08.900 --> 01:18:09.900]  hindi, ganito kasi.\n",
            "[01:18:09.900 --> 01:18:10.900]  Sige.\n",
            "[01:18:10.900 --> 01:18:11.900]  Last one.\n",
            "[01:18:11.900 --> 01:18:12.900]  Ano naman siya?\n",
            "[01:18:12.900 --> 01:18:13.900]  Public.\n",
            "[01:18:13.900 --> 01:18:14.900]  Ano naman siya?\n",
            "[01:18:14.900 --> 01:18:15.900]  Sa duplication.\n",
            "[01:18:15.900 --> 01:18:16.900]  Sige, sige, sir.\n",
            "[01:18:16.900 --> 01:18:17.900]  Sa duplication.\n",
            "[01:18:17.900 --> 01:18:18.900]  Yun nga,\n",
            "[01:18:18.900 --> 01:18:19.900]  inisipan ko.\n",
            "[01:18:19.900 --> 01:18:20.900]  Kasi, tinignan ko talaga yung sa saray.\n",
            "[01:18:20.900 --> 01:18:22.900]  When Ma'am Can was presenting saray\n",
            "[01:18:22.900 --> 01:18:23.900]  in the alumni,\n",
            "[01:18:23.900 --> 01:18:25.900]  nung successful na yung saray,\n",
            "[01:18:25.900 --> 01:18:27.900]  she really mentioned that there was\n",
            "[01:18:27.900 --> 01:18:30.900]  a lot of prototype SPs done\n",
            "[01:18:30.900 --> 01:18:32.900]  and they just throw it away.\n",
            "[01:18:32.900 --> 01:18:33.900]  And they only have a handful na,\n",
            "[01:18:33.900 --> 01:18:34.900]  ito na ngayon,\n",
            "[01:18:34.900 --> 01:18:36.900]  yung tanggap na ng stakeholders.\n",
            "[01:18:36.900 --> 01:18:38.900]  So, for me, I was inspired na\n",
            "[01:18:38.900 --> 01:18:40.900]  don't create silos.\n",
            "[01:18:40.900 --> 01:18:41.900]  Kunyari, may ginagawa\n",
            "[01:18:41.900 --> 01:18:42.900]  yung kapitbahay mo na AI\n",
            "[01:18:42.900 --> 01:18:43.900]  on ganito.\n",
            "[01:18:43.900 --> 01:18:44.900]  Hayaan mo lang.\n",
            "[01:18:44.900 --> 01:18:46.900]  Gawa ka din.\n",
            "[01:18:46.900 --> 01:18:47.900]  Then, later,\n",
            "[01:18:47.900 --> 01:18:48.900]  pag may nagawa na,\n",
            "[01:18:48.900 --> 01:18:49.900]  dun saka mag-share.\n",
            "[01:18:49.900 --> 01:18:50.900]  Huwag yung pipigilan mo\n",
            "[01:18:50.900 --> 01:18:52.900]  yung pag-start ng kapitbahay\n",
            "[01:18:52.900 --> 01:18:55.900]  kasi porket ginagawa na nila.\n",
            "[01:18:55.900 --> 01:18:56.900]  Sometimes, you just have to do it\n",
            "[01:18:56.900 --> 01:18:58.900]  together at the same time.\n",
            "[01:18:58.900 --> 01:18:59.900]  And then, share notes\n",
            "[01:18:59.900 --> 01:19:00.900]  pag na-build na.\n",
            "[01:19:00.900 --> 01:19:01.900]  And then, in fact,\n",
            "[01:19:01.900 --> 01:19:02.900]  hindi pa ngayon tatanggapin\n",
            "[01:19:02.900 --> 01:19:04.900]  ng stakeholders agad eh.\n",
            "[01:19:04.900 --> 01:19:06.900]  So, it will take a long while.\n",
            "[01:19:06.900 --> 01:19:07.900]  So, dahil doon,\n",
            "[01:19:07.900 --> 01:19:08.900]  na-inspire ako na\n",
            "[01:19:08.900 --> 01:19:10.900]  huwag mag-turfing.\n",
            "[01:19:10.900 --> 01:19:11.900]  Gawa lang ng gawa\n",
            "[01:19:11.900 --> 01:19:12.900]  and then,\n",
            "[01:19:12.900 --> 01:19:13.900]  just like sa Rai,\n",
            "[01:19:13.900 --> 01:19:15.900]  come up with something na\n",
            "[01:19:15.900 --> 01:19:16.900]  viable sa stakeholders.\n",
            "[01:19:16.900 --> 01:19:17.900]  And then, after six months,\n",
            "[01:19:17.900 --> 01:19:19.900]  one year,\n",
            "[01:19:19.900 --> 01:19:21.900]  ah, because technology moves,\n",
            "[01:19:21.900 --> 01:19:22.900]  baka hindi na rin\n",
            "[01:19:22.900 --> 01:19:24.900]  yung natanggap ng stakeholders,\n",
            "[01:19:24.900 --> 01:19:25.900]  baka hindi na rin yung\n",
            "[01:19:25.900 --> 01:19:27.900]  aged na rin.\n",
            "[01:19:27.900 --> 01:19:28.900]  Kaya dapat tuloy-tuloy\n",
            "[01:19:28.900 --> 01:19:29.900]  ang development.\n",
            "[01:19:29.900 --> 01:19:30.900]  So, walang ano,\n",
            "[01:19:30.900 --> 01:19:32.900]  walang, kumbaga sa akin lang,\n",
            "[01:19:32.900 --> 01:19:34.900]  huwag harangan yung mga kapitbahay\n",
            "[01:19:34.900 --> 01:19:39.900]  na gumagawa ng similar task.\n",
            "[01:19:39.900 --> 01:19:41.900]  Merong isang ongoing ngayon\n",
            "[01:19:41.900 --> 01:19:42.900]  na,\n",
            "[01:19:42.900 --> 01:19:44.900]  parang itanong siya,\n",
            "[01:19:44.900 --> 01:19:46.900]  pero for policy.\n",
            "[01:19:46.900 --> 01:19:49.900]  So, ang kakolaborate namin dito\n",
            "[01:19:49.900 --> 01:19:51.900]  eh, College of,\n",
            "[01:19:51.900 --> 01:19:52.900]  ano ba yun,\n",
            "[01:19:52.900 --> 01:19:53.900]  PAF?\n",
            "[01:19:53.900 --> 01:19:55.900]  Ah, Public Affairs ba yun?\n",
            "[01:19:55.900 --> 01:19:56.900]  College of?\n",
            "[01:19:56.900 --> 01:19:57.900]  Sa UP Manila,\n",
            "[01:19:57.900 --> 01:19:58.900]  ganun din eh.\n",
            "[01:19:58.900 --> 01:19:59.900]  May ginagawa din po sa\n",
            "[01:19:59.900 --> 01:20:00.900]  UP Manila na ganun.\n",
            "[01:20:00.900 --> 01:20:01.900]  Si PAF.\n",
            "[01:20:01.900 --> 01:20:02.900]  Si PAF.\n",
            "[01:20:02.900 --> 01:20:03.900]  Si PAF.\n",
            "[01:20:03.900 --> 01:20:04.900]  Sa,\n",
            "[01:20:04.900 --> 01:20:05.900]  yun po, marami pong ganun.\n",
            "[01:20:05.900 --> 01:20:06.900]  Kasi nga,\n",
            "[01:20:06.900 --> 01:20:07.900]  because of the advent of\n",
            "[01:20:07.900 --> 01:20:08.900]  large language models,\n",
            "[01:20:08.900 --> 01:20:09.900]  actually, sa DOST,\n",
            "[01:20:09.900 --> 01:20:11.900]  we're also trying that.\n",
            "[01:20:11.900 --> 01:20:12.900]  Sa Central Office,\n",
            "[01:20:12.900 --> 01:20:14.900]  actually, may two projects na,\n",
            "[01:20:14.900 --> 01:20:15.900]  na,\n",
            "[01:20:15.900 --> 01:20:16.900]  na,\n",
            "[01:20:16.900 --> 01:20:17.900]  gumagawa nun.\n",
            "[01:20:17.900 --> 01:20:18.900]  No?\n",
            "[01:20:18.900 --> 01:20:19.900]  Tapos sa UP Manila,\n",
            "[01:20:19.900 --> 01:20:20.900]  yun din,\n",
            "[01:20:20.900 --> 01:20:21.900]  yung,\n",
            "[01:20:21.900 --> 01:20:22.900]  ano,\n",
            "[01:20:22.900 --> 01:20:23.900]  parang,\n",
            "[01:20:23.900 --> 01:20:24.900]  Kasi yung RAG?\n",
            "[01:20:24.900 --> 01:20:25.900]  Oo, yung RAG.\n",
            "[01:20:25.900 --> 01:20:26.900]  Oo.\n",
            "[01:20:26.900 --> 01:20:27.900]  RAG po,\n",
            "[01:20:27.900 --> 01:20:28.900]  RAG po yung ginagamit.\n",
            "[01:20:28.900 --> 01:20:29.900]  Yung technology,\n",
            "[01:20:29.900 --> 01:20:30.900]  generic technology that you can use naman,\n",
            "[01:20:30.900 --> 01:20:31.900]  or any,\n",
            "[01:20:31.900 --> 01:20:32.900]  any documents,\n",
            "[01:20:32.900 --> 01:20:33.900]  baka ano,\n",
            "[01:20:33.900 --> 01:20:34.900]  pwede sa policy,\n",
            "[01:20:34.900 --> 01:20:35.900]  pwede sa ano.\n",
            "[01:20:35.900 --> 01:20:36.900]  Oo, kasi parang use case,\n",
            "[01:20:36.900 --> 01:20:37.900]  ayun ang hinahanap niyo,\n",
            "[01:20:37.900 --> 01:20:38.900]  ano,\n",
            "[01:20:38.900 --> 01:20:39.900]  parang use cases.\n",
            "[01:20:39.900 --> 01:20:40.900]  Apo.\n",
            "[01:20:40.900 --> 01:20:42.900]  Yung mga use cases po ng AI.\n",
            "[01:20:42.900 --> 01:20:43.900]  And, kasi,\n",
            "[01:20:43.900 --> 01:20:45.900]  hindi po limited dun sa computer vision lang,\n",
            "[01:20:45.900 --> 01:20:46.900]  pati po sa,\n",
            "[01:20:46.900 --> 01:20:47.900]  ah,\n",
            "[01:20:47.900 --> 01:20:48.900]  mga RAG na,\n",
            "[01:20:48.900 --> 01:20:49.900]  natural language processing,\n",
            "[01:20:49.900 --> 01:20:50.900]  LLMs,\n",
            "[01:20:50.900 --> 01:20:51.900]  yun po.\n",
            "[01:20:52.900 --> 01:20:53.900]  Paano yung tapos na?\n",
            "[01:20:53.900 --> 01:20:55.900]  May mga SP ako na,\n",
            "[01:20:55.900 --> 01:20:56.900]  ah,\n",
            "[01:20:56.900 --> 01:20:57.900]  fake news.\n",
            "[01:20:57.900 --> 01:20:59.900]  Ah, madami yan.\n",
            "[01:20:59.900 --> 01:21:00.900]  Oo, mga.\n",
            "[01:21:00.900 --> 01:21:01.900]  Oo.\n",
            "[01:21:03.900 --> 01:21:04.900]  Pero kasi, ang maganda po,\n",
            "[01:21:04.900 --> 01:21:05.900]  ganito, no,\n",
            "[01:21:05.900 --> 01:21:06.900]  ah, usually kasi,\n",
            "[01:21:06.900 --> 01:21:07.900]  like,\n",
            "[01:21:07.900 --> 01:21:08.900]  what we have started with ALAM,\n",
            "[01:21:08.900 --> 01:21:09.900]  what I told them,\n",
            "[01:21:10.900 --> 01:21:11.900]  ah,\n",
            "[01:21:11.900 --> 01:21:12.900]  is,\n",
            "[01:21:12.900 --> 01:21:13.900]  hand up kayo stakeholders,\n",
            "[01:21:13.900 --> 01:21:14.900]  dapat,\n",
            "[01:21:14.900 --> 01:21:15.900]  kung may research kayo,\n",
            "[01:21:15.900 --> 01:21:16.900]  merong magagamit.\n",
            "[01:21:16.900 --> 01:21:17.900]  May mapapasaan kayo,\n",
            "[01:21:17.900 --> 01:21:18.900]  may magbe-benefit.\n",
            "[01:21:18.900 --> 01:21:19.900]  At saka,\n",
            "[01:21:19.900 --> 01:21:20.900]  later on,\n",
            "[01:21:20.900 --> 01:21:22.900]  dapat may publication din yan.\n",
            "[01:21:22.900 --> 01:21:23.900]  May,\n",
            "[01:21:23.900 --> 01:21:24.900]  merong kayo mapapublish na paper.\n",
            "[01:21:24.900 --> 01:21:26.900]  So, yun po yung mga requirements\n",
            "[01:21:26.900 --> 01:21:27.900]  for every use cases,\n",
            "[01:21:27.900 --> 01:21:30.900]  may isang tututok na AI engineer,\n",
            "[01:21:30.900 --> 01:21:31.900]  tapos,\n",
            "[01:21:31.900 --> 01:21:32.900]  ah,\n",
            "[01:21:32.900 --> 01:21:33.900]  dapat may publication later on,\n",
            "[01:21:33.900 --> 01:21:34.900]  tapos may magagamit.\n",
            "[01:21:34.900 --> 01:21:35.900]  Halimbawa,\n",
            "[01:21:35.900 --> 01:21:36.900]  yung kay John po,\n",
            "[01:21:36.900 --> 01:21:37.900]  na ano,\n",
            "[01:21:37.900 --> 01:21:38.900]  nakahanap siya ng stakeholder niya.\n",
            "[01:21:38.900 --> 01:21:39.900]  May technology siya,\n",
            "[01:21:39.900 --> 01:21:41.900]  yung 3D reconstruction,\n",
            "[01:21:41.900 --> 01:21:42.900]  nakahanap siya ng stakeholder niya,\n",
            "[01:21:42.900 --> 01:21:44.900]  yung Museum of Natural History.\n",
            "[01:21:44.900 --> 01:21:45.900]  So,\n",
            "[01:21:45.900 --> 01:21:46.900]  ganun din po sa ibang ano,\n",
            "[01:21:46.900 --> 01:21:47.900]  like,\n",
            "[01:21:47.900 --> 01:21:48.900]  yung isang AI engineer namin,\n",
            "[01:21:48.900 --> 01:21:49.900]  naganap siya yung stakeholder,\n",
            "[01:21:49.900 --> 01:21:51.900]  nahanap niya yung PRISM,\n",
            "[01:21:51.900 --> 01:21:53.900]  yung sa Nueva Ecija.\n",
            "[01:21:53.900 --> 01:21:54.900]  Tapos,\n",
            "[01:21:54.900 --> 01:21:55.900]  yung isa,\n",
            "[01:21:55.900 --> 01:21:56.900]  MMDA naman yung stakeholder nila.\n",
            "[01:21:56.900 --> 01:21:57.900]  May magagamit ng ano.\n",
            "[01:21:57.900 --> 01:21:58.900]  So,\n",
            "[01:21:58.900 --> 01:21:59.900]  ganun po sana yung idea po\n",
            "[01:21:59.900 --> 01:22:00.900]  ng mga use cases.\n",
            "[01:22:00.900 --> 01:22:01.900]  Na,\n",
            "[01:22:01.900 --> 01:22:02.900]  halimbawa,\n",
            "[01:22:02.900 --> 01:22:03.900]  yung mga research,\n",
            "[01:22:03.900 --> 01:22:04.900]  katulad yung Wood AI,\n",
            "[01:22:04.900 --> 01:22:05.900]  ang stakeholder namin,\n",
            "[01:22:05.900 --> 01:22:06.900]  yung FPRDI.\n",
            "[01:22:06.900 --> 01:22:07.900]  O kaya,\n",
            "[01:22:07.900 --> 01:22:08.900]  yung ganun po,\n",
            "[01:22:08.900 --> 01:22:09.900]  meron tayong research\n",
            "[01:22:09.900 --> 01:22:10.900]  ng Wood AI,\n",
            "[01:22:10.900 --> 01:22:11.900]  tapos,\n",
            "[01:22:11.900 --> 01:22:12.900]  meron talaga kaming\n",
            "[01:22:12.900 --> 01:22:13.900]  pagpapasahan\n",
            "[01:22:13.900 --> 01:22:14.900]  na magbabenefit po.\n",
            "[01:22:14.900 --> 01:22:15.900]  Pwedeng LGU,\n",
            "[01:22:15.900 --> 01:22:17.900]  pwedeng MSMEs,\n",
            "[01:22:17.900 --> 01:22:18.900]  ganun po.\n",
            "[01:22:27.900 --> 01:22:28.900]  So,\n",
            "[01:22:28.900 --> 01:22:29.900]  siguro ganito,\n",
            "[01:22:29.900 --> 01:22:30.900]  dahil mas,\n",
            "[01:22:30.900 --> 01:22:31.900]  mas kabisado ninyo,\n",
            "[01:22:31.900 --> 01:22:32.900]  itong mga,\n",
            "[01:22:32.900 --> 01:22:34.900]  ano yung papasok na ano,\n",
            "[01:22:34.900 --> 01:22:35.900]  di,\n",
            "[01:22:35.900 --> 01:22:37.900]  pwede sigurong\n",
            "[01:22:37.900 --> 01:22:38.900]  another meeting\n",
            "[01:22:38.900 --> 01:22:39.900]  o ano,\n",
            "[01:22:39.900 --> 01:22:41.900]  para yung\n",
            "[01:22:41.900 --> 01:22:42.900]  meeting of the mind.\n",
            "[01:22:42.900 --> 01:22:44.900]  Saan kami pwedeng pumasok?\n",
            "[01:22:44.900 --> 01:22:45.900]  Opo,\n",
            "[01:22:45.900 --> 01:22:46.900]  kung sakaling,\n",
            "[01:22:46.900 --> 01:22:47.900]  let's say,\n",
            "[01:22:47.900 --> 01:22:48.900]  ayun po,\n",
            "[01:22:48.900 --> 01:22:49.900]  na-present na namin,\n",
            "[01:22:49.900 --> 01:22:50.900]  tapos,\n",
            "[01:22:50.900 --> 01:22:51.900]  biglang meron kayong,\n",
            "[01:22:51.900 --> 01:22:52.900]  tingin nyo,\n",
            "[01:22:52.900 --> 01:22:53.900]  ito yung pinaka-pressing\n",
            "[01:22:53.900 --> 01:22:54.900]  issue na\n",
            "[01:22:54.900 --> 01:22:55.900]  kailangan nyo.\n",
            "[01:22:55.900 --> 01:22:56.900]  O yung kanulad ng\n",
            "[01:22:56.900 --> 01:22:57.900]  bilanggit ni Mamayla kanina,\n",
            "[01:22:57.900 --> 01:22:58.900]  na yung parang,\n",
            "[01:22:58.900 --> 01:22:59.900]  yung parang\n",
            "[01:22:59.900 --> 01:23:00.900]  missing link daw\n",
            "[01:23:00.900 --> 01:23:01.900]  dun sa ano.\n",
            "[01:23:01.900 --> 01:23:02.900]  Or,\n",
            "[01:23:02.900 --> 01:23:03.900]  mag-identify po kayo\n",
            "[01:23:03.900 --> 01:23:04.900]  siguro.\n",
            "[01:23:04.900 --> 01:23:05.900]  Ito po yung aking suggestion\n",
            "[01:23:05.900 --> 01:23:06.900]  siguro for,\n",
            "[01:23:06.900 --> 01:23:07.900]  for next action item.\n",
            "[01:23:07.900 --> 01:23:08.900]  It's possible po,\n",
            "[01:23:08.900 --> 01:23:09.900]  it's possible po,\n",
            "[01:23:09.900 --> 01:23:10.900]  na magkaroon tayo ng\n",
            "[01:23:10.900 --> 01:23:11.900]  follow-up meeting.\n",
            "[01:23:11.900 --> 01:23:12.900]  Pero in that follow-up meeting,\n",
            "[01:23:12.900 --> 01:23:14.900]  mas detalyado na po.\n",
            "[01:23:14.900 --> 01:23:15.900]  Yung katulad din ang sinasabi ni\n",
            "[01:23:15.900 --> 01:23:16.900]  Sir Arian,\n",
            "[01:23:16.900 --> 01:23:17.900]  we need to identify\n",
            "[01:23:17.900 --> 01:23:18.900]  mga low-hanging fruits.\n",
            "[01:23:18.900 --> 01:23:19.900]  We start with small.\n",
            "[01:23:19.900 --> 01:23:20.900]  Tapos,\n",
            "[01:23:20.900 --> 01:23:21.900]  basta lang po na,\n",
            "[01:23:21.900 --> 01:23:22.900]  we can\n",
            "[01:23:22.900 --> 01:23:23.900]  actually work\n",
            "[01:23:23.900 --> 01:23:24.900]  with,\n",
            "[01:23:24.900 --> 01:23:25.900]  like yung federated learning,\n",
            "[01:23:25.900 --> 01:23:26.900]  na,\n",
            "[01:23:26.900 --> 01:23:27.900]  quite without even,\n",
            "[01:23:27.900 --> 01:23:28.900]  ano,\n",
            "[01:23:28.900 --> 01:23:29.900]  sharing the data sets.\n",
            "[01:23:29.900 --> 01:23:30.900]  Siguro yun po,\n",
            "[01:23:30.900 --> 01:23:32.900]  I would suggest,\n",
            "[01:23:32.900 --> 01:23:33.900]  na,\n",
            "[01:23:33.900 --> 01:23:34.900]  pwede naman po,\n",
            "[01:23:34.900 --> 01:23:35.900]  halimbawa,\n",
            "[01:23:35.900 --> 01:23:36.900]  let's say,\n",
            "[01:23:36.900 --> 01:23:37.900]  marami kayong maisip.\n",
            "[01:23:37.900 --> 01:23:38.900]  Tapos,\n",
            "[01:23:38.900 --> 01:23:39.900]  yung specific\n",
            "[01:23:39.900 --> 01:23:40.900]  researchers\n",
            "[01:23:40.900 --> 01:23:41.900]  or yung faculty na lang,\n",
            "[01:23:41.900 --> 01:23:42.900]  with that yung,\n",
            "[01:23:42.900 --> 01:23:43.900]  yung parang\n",
            "[01:23:43.900 --> 01:23:44.900]  magli-lead po doon,\n",
            "[01:23:44.900 --> 01:23:45.900]  we can meet with them\n",
            "[01:23:45.900 --> 01:23:46.900]  and we can\n",
            "[01:23:46.900 --> 01:23:47.900]  meet with,\n",
            "[01:23:47.900 --> 01:23:48.900]  kunyari,\n",
            "[01:23:48.900 --> 01:23:49.900]  iba naman yung,\n",
            "[01:23:49.900 --> 01:23:50.900]  ibang meeting naman yung\n",
            "[01:23:50.900 --> 01:23:51.900]  kay Sir Arian\n",
            "[01:23:51.900 --> 01:23:52.900]  about with AI naman po yan.\n",
            "[01:23:52.900 --> 01:23:53.900]  Parang gano'n.\n",
            "[01:23:53.900 --> 01:23:54.900]  Pwede po siguro yung mga\n",
            "[01:23:54.900 --> 01:23:55.900]  succeeding meetings natin,\n",
            "[01:23:55.900 --> 01:23:57.900]  more on mas specific na.\n",
            "[01:23:57.900 --> 01:23:59.900]  Kung meron po kayo na-identify,\n",
            "[01:23:59.900 --> 01:24:00.900]  na pwede tayo,\n",
            "[01:24:00.900 --> 01:24:01.900]  ano,\n",
            "[01:24:01.900 --> 01:24:02.900]  and if,\n",
            "[01:24:02.900 --> 01:24:03.900]  ano po,\n",
            "[01:24:03.900 --> 01:24:04.900]  we would really parang\n",
            "[01:24:04.900 --> 01:24:05.900]  appreciate po talagang\n",
            "[01:24:05.900 --> 01:24:06.900]  kung maging interested po\n",
            "[01:24:06.900 --> 01:24:07.900]  kayo,\n",
            "[01:24:07.900 --> 01:24:08.900]  in partnering with us\n",
            "[01:24:08.900 --> 01:24:10.900]  on a specific\n",
            "[01:24:10.900 --> 01:24:11.900]  use case po\n",
            "[01:24:11.900 --> 01:24:12.900]  or research.\n",
            "[01:24:16.900 --> 01:24:17.900]  So,\n",
            "[01:24:17.900 --> 01:24:18.900]  magsimula tayo doon\n",
            "[01:24:18.900 --> 01:24:19.900]  sa student,\n",
            "[01:24:19.900 --> 01:24:20.900]  ano,\n",
            "[01:24:20.900 --> 01:24:21.900]  kasi ang student ata\n",
            "[01:24:21.900 --> 01:24:22.900]  ang mag-a-apply,\n",
            "[01:24:22.900 --> 01:24:23.900]  ano?\n",
            "[01:24:23.900 --> 01:24:24.900]  Opo,\n",
            "[01:24:24.900 --> 01:24:25.900]  bali ganito po,\n",
            "[01:24:25.900 --> 01:24:26.900]  sige,\n",
            "[01:24:26.900 --> 01:24:27.900]  Kurt will send you the MOU,\n",
            "[01:24:27.900 --> 01:24:28.900]  tapos,\n",
            "[01:24:28.900 --> 01:24:29.900]  I'm gonna\n",
            "[01:24:29.900 --> 01:24:30.900]  run this\n",
            "[01:24:30.900 --> 01:24:31.900]  by our HR\n",
            "[01:24:31.900 --> 01:24:32.900]  kasi we need to involve\n",
            "[01:24:32.900 --> 01:24:33.900]  our HR po\n",
            "[01:24:33.900 --> 01:24:34.900]  regarding this.\n",
            "[01:24:34.900 --> 01:24:35.900]  Tapos,\n",
            "[01:24:35.900 --> 01:24:36.900]  tinan po namin kung\n",
            "[01:24:36.900 --> 01:24:37.900]  okay po sa kanila,\n",
            "[01:24:37.900 --> 01:24:38.900]  eto po,\n",
            "[01:24:38.900 --> 01:24:39.900]  i-proceed po namin\n",
            "[01:24:39.900 --> 01:24:40.900]  itong mga forms na to,\n",
            "[01:24:40.900 --> 01:24:42.900]  i-fill out namin itong mga forms na to\n",
            "[01:24:42.900 --> 01:24:44.900]  para po mag-proceed tayo doon sa\n",
            "[01:24:44.900 --> 01:24:45.900]  internship.\n",
            "[01:24:45.900 --> 01:24:47.900]  So, that's one po, no?\n",
            "[01:24:47.900 --> 01:24:48.900]  And then,\n",
            "[01:24:48.900 --> 01:24:49.900]  ayun po,\n",
            "[01:24:49.900 --> 01:24:50.900]  yun yung mga ano,\n",
            "[01:24:50.900 --> 01:24:52.900]  possible na route po natin.\n",
            "[01:24:56.900 --> 01:24:57.900]  Sir Aryan?\n",
            "[01:24:58.900 --> 01:24:59.900]  I'm reminded of\n",
            "[01:24:59.900 --> 01:25:01.900]  Sir Andre's suggestion.\n",
            "[01:25:01.900 --> 01:25:02.900]  Ang ganda nun eh,\n",
            "[01:25:02.900 --> 01:25:03.900]  kasi yun talagang tinatanong namin\n",
            "[01:25:03.900 --> 01:25:05.900]  sa pag nag-ESPY proposal sila.\n",
            "[01:25:05.900 --> 01:25:06.900]  May labeled data,\n",
            "[01:25:06.900 --> 01:25:07.900]  may labeled data ka ba?\n",
            "[01:25:07.900 --> 01:25:08.900]  Kaya maganda yung tanong niya kanina\n",
            "[01:25:08.900 --> 01:25:09.900]  na may,\n",
            "[01:25:09.900 --> 01:25:10.900]  tapos itong pinadala ni\n",
            "[01:25:10.900 --> 01:25:11.900]  Bani na katalog.\n",
            "[01:25:11.900 --> 01:25:12.900]  Ang ganda nito eh,\n",
            "[01:25:12.900 --> 01:25:13.900]  isa rin itong source ng\n",
            "[01:25:13.900 --> 01:25:15.900]  low-hanging topics.\n",
            "[01:25:15.900 --> 01:25:16.900]  Pili lang kayo sa Akabay,\n",
            "[01:25:16.900 --> 01:25:18.900]  alin dyan yung hindi pa masyadong\n",
            "[01:25:18.900 --> 01:25:19.900]  na mind,\n",
            "[01:25:19.900 --> 01:25:20.900]  or may interest kayo,\n",
            "[01:25:20.900 --> 01:25:22.900]  kasi kapit-bahay nyo yan.\n",
            "[01:25:22.900 --> 01:25:23.900]  And then,\n",
            "[01:25:23.900 --> 01:25:24.900]  bigay nyo ka agad sa amin,\n",
            "[01:25:24.900 --> 01:25:26.900]  kasi may mga techniques din yan sila\n",
            "[01:25:26.900 --> 01:25:27.900]  na pwedeng itry eh.\n",
            "[01:25:27.900 --> 01:25:28.900]  No?\n",
            "[01:25:28.900 --> 01:25:29.900]  Sir Andre?\n",
            "[01:25:29.900 --> 01:25:30.900]  Baka pwede ikaw\n",
            "[01:25:30.900 --> 01:25:31.900]  isa sa mga,\n",
            "[01:25:31.900 --> 01:25:32.900]  ano nyan,\n",
            "[01:25:32.900 --> 01:25:33.900]  mentor ng mga students\n",
            "[01:25:33.900 --> 01:25:34.900]  even as early as,\n",
            "[01:25:34.900 --> 01:25:35.900]  ano,\n",
            "[01:25:35.900 --> 01:25:36.900]  now.\n",
            "[01:25:36.900 --> 01:25:37.900]  Maganda yan eh.\n",
            "[01:25:37.900 --> 01:25:38.900]  Kasi kami,\n",
            "[01:25:38.900 --> 01:25:39.900]  hindi kami basta pumapayag\n",
            "[01:25:39.900 --> 01:25:40.900]  pag walang labeled data\n",
            "[01:25:40.900 --> 01:25:41.900]  yung estudyante,\n",
            "[01:25:41.900 --> 01:25:43.900]  kasi ang tagal natatapos.\n",
            "[01:25:43.900 --> 01:25:45.900]  Kababwa sila.\n",
            "[01:25:47.900 --> 01:25:48.900]  Ayun.\n",
            "[01:25:48.900 --> 01:25:49.900]  Tama po yan.\n",
            "[01:25:49.900 --> 01:25:50.900]  Maganda.\n",
            "[01:25:50.900 --> 01:25:51.900]  Para at least ano.\n",
            "[01:25:51.900 --> 01:25:52.900]  Kasi minsan naman,\n",
            "[01:25:52.900 --> 01:25:53.900]  ang hirap,\n",
            "[01:25:53.900 --> 01:25:54.900]  kunyari nagkumuha kami ng intern.\n",
            "[01:25:54.900 --> 01:25:56.900]  May mga kiloko kami interns\n",
            "[01:25:56.900 --> 01:25:57.900]  na ang gagawin lang nila\n",
            "[01:25:57.900 --> 01:25:58.900]  mag-label ng data.\n",
            "[01:25:58.900 --> 01:25:59.900]  May mga gano'n,\n",
            "[01:25:59.900 --> 01:26:00.900]  pero nakaka,\n",
            "[01:26:00.900 --> 01:26:01.900]  ano din yung,\n",
            "[01:26:01.900 --> 01:26:02.900]  yung mga,\n",
            "[01:26:02.900 --> 01:26:03.900]  like for example,\n",
            "[01:26:03.900 --> 01:26:04.900]  yung sa,\n",
            "[01:26:04.900 --> 01:26:05.900]  sa UP Minda,\n",
            "[01:26:05.900 --> 01:26:06.900]  PISAI students yata,\n",
            "[01:26:06.900 --> 01:26:07.900]  high school students,\n",
            "[01:26:07.900 --> 01:26:08.900]  sila yung mga nagbe-label\n",
            "[01:26:08.900 --> 01:26:09.900]  ng data.\n",
            "[01:26:09.900 --> 01:26:10.900]  May mga gano'n po\n",
            "[01:26:10.900 --> 01:26:11.900]  na nag-a-annotate talaga\n",
            "[01:26:11.900 --> 01:26:12.900]  ng mga data sets,\n",
            "[01:26:12.900 --> 01:26:13.900]  which is,\n",
            "[01:26:13.900 --> 01:26:14.900]  nakaka,\n",
            "[01:26:14.900 --> 01:26:15.900]  ano.\n",
            "[01:26:15.900 --> 01:26:17.900]  Hindi kami pumapayag.\n",
            "[01:26:17.900 --> 01:26:18.900]  Sayang naman yung,\n",
            "[01:26:18.900 --> 01:26:19.900]  ano nila.\n",
            "[01:26:19.900 --> 01:26:20.900]  Oo.\n",
            "[01:26:20.900 --> 01:26:21.900]  Oo po.\n",
            "[01:26:23.900 --> 01:26:24.900]  Okay.\n",
            "[01:26:24.900 --> 01:26:25.900]  So,\n",
            "[01:26:25.900 --> 01:26:26.900]  anong,\n",
            "[01:26:26.900 --> 01:26:27.900]  ano natin?\n",
            "[01:26:27.900 --> 01:26:28.900]  So,\n",
            "[01:26:28.900 --> 01:26:29.900]  yan po yung aking suggestion\n",
            "[01:26:29.900 --> 01:26:30.900]  moving forward.\n",
            "[01:26:32.900 --> 01:26:33.900]  Tingnan natin yung\n",
            "[01:26:33.900 --> 01:26:34.900]  low hanging,\n",
            "[01:26:34.900 --> 01:26:35.900]  ah,\n",
            "[01:26:35.900 --> 01:26:36.900]  fruits na\n",
            "[01:26:36.900 --> 01:26:37.900]  data set.\n",
            "[01:26:37.900 --> 01:26:38.900]  And then,\n",
            "[01:26:38.900 --> 01:26:39.900]  ayun po,\n",
            "[01:26:39.900 --> 01:26:40.900]  ah,\n",
            "[01:26:40.900 --> 01:26:41.900]  Kurt will summarize this,\n",
            "[01:26:41.900 --> 01:26:42.900]  ano,\n",
            "[01:26:42.900 --> 01:26:43.900]  this meeting po.\n",
            "[01:26:43.900 --> 01:26:44.900]  Will give you a copy.\n",
            "[01:26:44.900 --> 01:26:45.900]  And then,\n",
            "[01:26:45.900 --> 01:26:46.900]  ah,\n",
            "[01:26:46.900 --> 01:26:47.900]  ilagay na lang din po natin dun\n",
            "[01:26:47.900 --> 01:26:48.900]  yung mga next action items,\n",
            "[01:26:48.900 --> 01:26:49.900]  which includes po yung,\n",
            "[01:26:49.900 --> 01:26:50.900]  ito nga,\n",
            "[01:26:50.900 --> 01:26:51.900]  yung,\n",
            "[01:26:51.900 --> 01:26:52.900]  ah,\n",
            "[01:26:52.900 --> 01:26:53.900]  moving forward with the internship.\n",
            "[01:26:53.900 --> 01:26:54.900]  Tapos,\n",
            "[01:26:54.900 --> 01:26:55.900]  ah,\n",
            "[01:26:55.900 --> 01:26:56.900]  siguro,\n",
            "[01:26:56.900 --> 01:26:57.900]  you can specify po\n",
            "[01:26:57.900 --> 01:26:58.900]  on your end\n",
            "[01:26:58.900 --> 01:26:59.900]  kung ano-ano yung mga,\n",
            "[01:26:59.900 --> 01:27:00.900]  ah,\n",
            "[01:27:00.900 --> 01:27:01.900]  use cases\n",
            "[01:27:01.900 --> 01:27:02.900]  or research,\n",
            "[01:27:02.900 --> 01:27:03.900]  ah,\n",
            "[01:27:03.900 --> 01:27:04.900]  ah,\n",
            "[01:27:04.900 --> 01:27:05.900]  possibilities po\n",
            "[01:27:05.900 --> 01:27:06.900]  na pwede po natin gawin.\n",
            "[01:27:06.900 --> 01:27:07.900]  Yun po siguro yung aking\n",
            "[01:27:07.900 --> 01:27:08.900]  suggestion po,\n",
            "[01:27:08.900 --> 01:27:09.900]  no?\n",
            "[01:27:09.900 --> 01:27:10.900]  And,\n",
            "[01:27:10.900 --> 01:27:11.900]  ah,\n",
            "[01:27:11.900 --> 01:27:13.900]  yung sa capacity building,\n",
            "[01:27:13.900 --> 01:27:15.900]  ah,\n",
            "[01:27:15.900 --> 01:27:16.900]  tingnan po natin\n",
            "[01:27:16.900 --> 01:27:17.900]  kung paano yung,\n",
            "[01:27:17.900 --> 01:27:18.900]  kung paano yung,\n",
            "[01:27:18.900 --> 01:27:19.900]  ano,\n",
            "[01:27:19.900 --> 01:27:20.900]  ah,\n",
            "[01:27:20.900 --> 01:27:21.900]  kung paano natin ma,\n",
            "[01:27:21.900 --> 01:27:22.900]  magagawa yun\n",
            "[01:27:22.900 --> 01:27:23.900]  yung capacity building\n",
            "[01:27:23.900 --> 01:27:24.900]  kung,\n",
            "[01:27:24.900 --> 01:27:25.900]  ano,\n",
            "[01:27:25.900 --> 01:27:26.900]  kasi ito,\n",
            "[01:27:26.900 --> 01:27:27.900]  isa nga po yung,\n",
            "[01:27:27.900 --> 01:27:28.900]  isa na rin yun,\n",
            "[01:27:28.900 --> 01:27:29.900]  yung sa,\n",
            "[01:27:29.900 --> 01:27:30.900]  sa internship\n",
            "[01:27:30.900 --> 01:27:31.900]  as capacity building,\n",
            "[01:27:31.900 --> 01:27:32.900]  yung sabi ni Sir Arian kanina na\n",
            "[01:27:32.900 --> 01:27:33.900]  first few,\n",
            "[01:27:33.900 --> 01:27:34.900]  ah,\n",
            "[01:27:34.900 --> 01:27:35.900]  we can train them,\n",
            "[01:27:35.900 --> 01:27:36.900]  yung gano'n.\n",
            "[01:27:36.900 --> 01:27:37.900]  So,\n",
            "[01:27:37.900 --> 01:27:38.900]  yun po,\n",
            "[01:27:38.900 --> 01:27:39.900]  looking forward po sa,\n",
            "[01:27:39.900 --> 01:27:40.900]  ah,\n",
            "[01:27:40.900 --> 01:27:41.900]  although ngayon hindi pa siya gano'n\n",
            "[01:27:41.900 --> 01:27:42.900]  ka-concrete\n",
            "[01:27:42.900 --> 01:27:43.900]  at ka-detailed,\n",
            "[01:27:43.900 --> 01:27:44.900]  bakit later on po\n",
            "[01:27:44.900 --> 01:27:45.900]  kapag ka,\n",
            "[01:27:45.900 --> 01:27:46.900]  sa next meeting natin\n",
            "[01:27:46.900 --> 01:27:47.900]  or\n",
            "[01:27:47.900 --> 01:27:48.900]  mas specific\n",
            "[01:27:48.900 --> 01:27:50.900]  usapan natin.\n",
            "[01:27:50.900 --> 01:27:51.900]  And hopefully by then,\n",
            "[01:27:51.900 --> 01:27:52.900]  ah,\n",
            "[01:27:52.900 --> 01:27:54.900]  ang utang namin po\n",
            "[01:27:54.900 --> 01:27:55.900]  is itong,\n",
            "[01:27:55.900 --> 01:27:56.900]  ano,\n",
            "[01:27:56.900 --> 01:27:57.900]  ah,\n",
            "[01:27:57.900 --> 01:27:58.900]  sa HR\n",
            "[01:27:58.900 --> 01:27:59.900]  at sa ka,\n",
            "[01:27:59.900 --> 01:28:00.900]  eh,\n",
            "[01:28:00.900 --> 01:28:01.900]  Kurt,\n",
            "[01:28:01.900 --> 01:28:02.900]  nabigay mo na ba yung,\n",
            "[01:28:02.900 --> 01:28:03.900]  ano,\n",
            "[01:28:03.900 --> 01:28:04.900]  and,\n",
            "[01:28:04.900 --> 01:28:05.900]  sige,\n",
            "[01:28:05.900 --> 01:28:06.900]  si Jom muna.\n",
            "[01:28:06.900 --> 01:28:07.900]  Jom?\n",
            "[01:28:07.900 --> 01:28:08.900]  Ah,\n",
            "[01:28:08.900 --> 01:28:09.900]  sir,\n",
            "[01:28:09.900 --> 01:28:10.900]  question lang po dun sa internship.\n",
            "[01:28:10.900 --> 01:28:11.900]  Ah,\n",
            "[01:28:11.900 --> 01:28:12.900]  pag,\n",
            "[01:28:12.900 --> 01:28:13.900]  after po ba ng internship nila,\n",
            "[01:28:13.900 --> 01:28:14.900]  are we still allowing them to access po\n",
            "[01:28:14.900 --> 01:28:15.900]  yung HPC's natin\n",
            "[01:28:15.900 --> 01:28:16.900]  or\n",
            "[01:28:16.900 --> 01:28:17.900]  during the internship lang po?\n",
            "[01:28:17.900 --> 01:28:18.900]  During lang siguro.\n",
            "[01:28:18.900 --> 01:28:19.900]  And then,\n",
            "[01:28:19.900 --> 01:28:20.900]  another agreement,\n",
            "[01:28:20.900 --> 01:28:21.900]  pagkayon din ang kanilang thesis\n",
            "[01:28:21.900 --> 01:28:22.900]  or SP.\n",
            "[01:28:22.900 --> 01:28:23.900]  Tama ba?\n",
            "[01:28:23.900 --> 01:28:24.900]  Nung during lang siguro.\n",
            "[01:28:24.900 --> 01:28:25.900]  And then,\n",
            "[01:28:25.900 --> 01:28:26.900]  another agreement,\n",
            "[01:28:26.900 --> 01:28:27.900]  pagkayon din ang kanilang thesis\n",
            "[01:28:27.900 --> 01:28:28.900]  or SP.\n",
            "[01:28:28.900 --> 01:28:29.900]  Tama ba?\n",
            "[01:28:29.900 --> 01:28:30.900]  Nung during lang siguro,\n",
            "[01:28:30.900 --> 01:28:31.900]  ah,\n",
            "[01:28:31.900 --> 01:28:32.900]  ah,\n",
            "[01:28:32.900 --> 01:28:33.900]  nung duration lang ng,\n",
            "[01:28:33.900 --> 01:28:34.900]  ano,\n",
            "[01:28:34.900 --> 01:28:35.900]  na practicum.\n",
            "[01:28:35.900 --> 01:28:36.900]  Yeah,\n",
            "[01:28:36.900 --> 01:28:37.900]  ah,\n",
            "[01:28:37.900 --> 01:28:38.900]  siguro,\n",
            "[01:28:38.900 --> 01:28:39.900]  pero,\n",
            "[01:28:39.900 --> 01:28:40.900]  ah,\n",
            "[01:28:40.900 --> 01:28:42.900]  in special instance,\n",
            "[01:28:42.900 --> 01:28:43.900]  bakit mo pala naitanong,\n",
            "[01:28:43.900 --> 01:28:44.900]  ano,\n",
            "[01:28:44.900 --> 01:28:45.900]  Jom?\n",
            "[01:28:45.900 --> 01:28:46.900]  Ah,\n",
            "[01:28:46.900 --> 01:28:47.900]  kasi yung,\n",
            "[01:28:47.900 --> 01:28:48.900]  ano po,\n",
            "[01:28:48.900 --> 01:28:49.900]  yung interns ko po\n",
            "[01:28:49.900 --> 01:28:50.900]  from last year po,\n",
            "[01:28:50.900 --> 01:28:51.900]  from EE po,\n",
            "[01:28:51.900 --> 01:28:52.900]  ah,\n",
            "[01:28:52.900 --> 01:28:53.900]  nag-message,\n",
            "[01:28:53.900 --> 01:28:54.900]  nag-message po sila\n",
            "[01:28:54.900 --> 01:28:55.900]  if they can,\n",
            "[01:28:55.900 --> 01:28:56.900]  ah,\n",
            "[01:28:56.900 --> 01:28:57.900]  use yung facilities po\n",
            "[01:28:57.900 --> 01:28:58.900]  ng core.\n",
            "[01:28:58.900 --> 01:28:59.900]  Kasi,\n",
            "[01:28:59.900 --> 01:29:00.900]  yung keys po nila ngayon\n",
            "[01:29:00.900 --> 01:29:01.900]  need po kasi ng HPC\n",
            "[01:29:01.900 --> 01:29:02.900]  ah,\n",
            "[01:29:02.900 --> 01:29:03.900]  ano yata,\n",
            "[01:29:03.900 --> 01:29:04.900]  nagbago na ng,\n",
            "[01:29:04.900 --> 01:29:05.900]  ano,\n",
            "[01:29:05.900 --> 01:29:06.900]  so,\n",
            "[01:29:06.900 --> 01:29:07.900]  we would abide doon sa\n",
            "[01:29:07.900 --> 01:29:08.900]  terms and conditions\n",
            "[01:29:08.900 --> 01:29:10.900]  ng usage ng core.\n",
            "[01:29:10.900 --> 01:29:11.900]  Baka meron silang,\n",
            "[01:29:11.900 --> 01:29:12.900]  ano,\n",
            "[01:29:12.900 --> 01:29:13.900]  doon specific na,\n",
            "[01:29:13.900 --> 01:29:14.900]  ano,\n",
            "[01:29:14.900 --> 01:29:15.900]  kasi dati,\n",
            "[01:29:15.900 --> 01:29:16.900]  no,\n",
            "[01:29:16.900 --> 01:29:17.900]  nagpumapayag na individual na,\n",
            "[01:29:17.900 --> 01:29:18.900]  nung ngayon,\n",
            "[01:29:18.900 --> 01:29:19.900]  kaya yata institutional na.\n",
            "[01:29:19.900 --> 01:29:20.900]  So,\n",
            "[01:29:20.900 --> 01:29:21.900]  meron namang,\n",
            "[01:29:21.900 --> 01:29:22.900]  ano,\n",
            "[01:29:22.900 --> 01:29:23.900]  terms and conditions\n",
            "[01:29:23.900 --> 01:29:24.900]  ng usage ng,\n",
            "[01:29:24.900 --> 01:29:25.900]  ng core.\n",
            "[01:29:26.900 --> 01:29:27.900]  Rox?\n",
            "[01:29:29.900 --> 01:29:30.900]  Yes,\n",
            "[01:29:30.900 --> 01:29:31.900]  Sir Elmer.\n",
            "[01:29:31.900 --> 01:29:32.900]  Just to add doon kay John,\n",
            "[01:29:32.900 --> 01:29:33.900]  baka if\n",
            "[01:29:33.900 --> 01:29:35.900]  ongoing naman yung,\n",
            "[01:29:35.900 --> 01:29:36.900]  may ongoing na,\n",
            "[01:29:36.900 --> 01:29:37.900]  ano,\n",
            "[01:29:37.900 --> 01:29:38.900]  na cooperation\n",
            "[01:29:38.900 --> 01:29:39.900]  or\n",
            "[01:29:39.900 --> 01:29:40.900]  collaboration\n",
            "[01:29:40.900 --> 01:29:41.900]  through\n",
            "[01:29:41.900 --> 01:29:42.900]  a formal MOA\n",
            "[01:29:42.900 --> 01:29:43.900]  or MOA,\n",
            "[01:29:43.900 --> 01:29:44.900]  I think,\n",
            "[01:29:44.900 --> 01:29:45.900]  yun yung,\n",
            "[01:29:45.900 --> 01:29:46.900]  ano eh,\n",
            "[01:29:46.900 --> 01:29:47.900]  parang isang basis\n",
            "[01:29:47.900 --> 01:29:48.900]  kasi yung nandun sa,\n",
            "[01:29:48.900 --> 01:29:49.900]  ano natin,\n",
            "[01:29:49.900 --> 01:29:50.900]  diba,\n",
            "[01:29:50.900 --> 01:29:51.900]  sa user,\n",
            "[01:29:51.900 --> 01:29:52.900]  parang sign up natin.\n",
            "[01:29:52.900 --> 01:29:53.900]  If we have an existing MOA,\n",
            "[01:29:53.900 --> 01:29:54.900]  tapos university ka,\n",
            "[01:29:54.900 --> 01:29:55.900]  yun,\n",
            "[01:29:55.900 --> 01:29:56.900]  tama yun,\n",
            "[01:29:56.900 --> 01:29:57.900]  hindi siya pwedeng individual lang na,\n",
            "[01:29:57.900 --> 01:29:58.900]  ah,\n",
            "[01:29:58.900 --> 01:29:59.900]  you're just an individual researcher\n",
            "[01:29:59.900 --> 01:30:00.900]  or student wanting to access yung\n",
            "[01:30:00.900 --> 01:30:02.900]  HPC,\n",
            "[01:30:02.900 --> 01:30:03.900]  yun yata yung hindi na-allow\n",
            "[01:30:03.900 --> 01:30:04.900]  kasi masyadong,\n",
            "[01:30:04.900 --> 01:30:05.900]  um,\n",
            "[01:30:05.900 --> 01:30:06.900]  parang limited na yung resource natin.\n",
            "[01:30:06.900 --> 01:30:07.900]  Pero kapag institution nga,\n",
            "[01:30:07.900 --> 01:30:08.900]  yun,\n",
            "[01:30:08.900 --> 01:30:09.900]  like university,\n",
            "[01:30:09.900 --> 01:30:10.900]  I think,\n",
            "[01:30:10.900 --> 01:30:11.900]  ina-allow naman\n",
            "[01:30:11.900 --> 01:30:12.900]  if may ongoing MOA\n",
            "[01:30:12.900 --> 01:30:13.900]  as long as yung output pa rin\n",
            "[01:30:13.900 --> 01:30:15.900]  is related doon sa,\n",
            "[01:30:15.900 --> 01:30:16.900]  um,\n",
            "[01:30:16.900 --> 01:30:18.900]  na-define natin na scope of cooperation\n",
            "[01:30:18.900 --> 01:30:19.900]  and yung\n",
            "[01:30:19.900 --> 01:30:20.900]  output na\n",
            "[01:30:20.900 --> 01:30:21.900]  intended talaga\n",
            "[01:30:21.900 --> 01:30:23.900]  for HPC's use.\n",
            "[01:30:23.900 --> 01:30:24.900]  Ah,\n",
            "[01:30:24.900 --> 01:30:25.900]  yung comment ko siguro,\n",
            "[01:30:25.900 --> 01:30:26.900]  just to add lang,\n",
            "[01:30:26.900 --> 01:30:27.900]  I think,\n",
            "[01:30:27.900 --> 01:30:28.900]  na-mentioned kanina kasi ni Sir Aryan,\n",
            "[01:30:28.900 --> 01:30:29.900]  na yung ibang institutions,\n",
            "[01:30:29.900 --> 01:30:30.900]  no,\n",
            "[01:30:30.900 --> 01:30:31.900]  they're providing,\n",
            "[01:30:31.900 --> 01:30:32.900]  ah,\n",
            "[01:30:32.900 --> 01:30:33.900]  salary doon sa mga interns.\n",
            "[01:30:33.900 --> 01:30:35.900]  Na-mentioned ni Sir Elmer na,\n",
            "[01:30:35.900 --> 01:30:36.900]  ah,\n",
            "[01:30:36.900 --> 01:30:37.900]  wala rin talaga kami,\n",
            "[01:30:37.900 --> 01:30:38.900]  ano,\n",
            "[01:30:38.900 --> 01:30:39.900]  parang hindi paid yung mga interns namin.\n",
            "[01:30:39.900 --> 01:30:40.900]  But we have,\n",
            "[01:30:40.900 --> 01:30:41.900]  parang,\n",
            "[01:30:41.900 --> 01:30:42.900]  like,\n",
            "[01:30:42.900 --> 01:30:43.900]  Sir Elmer,\n",
            "[01:30:43.900 --> 01:30:44.900]  di ba,\n",
            "[01:30:44.900 --> 01:30:45.900]  we have presidential youth program\n",
            "[01:30:45.900 --> 01:30:46.900]  and we have experiences before,\n",
            "[01:30:46.900 --> 01:30:47.900]  like,\n",
            "[01:30:47.900 --> 01:30:48.900]  in TIPT-UP na,\n",
            "[01:30:48.900 --> 01:30:49.900]  nag-provide talaga tayo ng salary.\n",
            "[01:30:49.900 --> 01:30:50.900]  Kaya lang may mga\n",
            "[01:30:50.900 --> 01:30:51.900]  minimum number of training hours,\n",
            "[01:30:51.900 --> 01:30:52.900]  yun,\n",
            "[01:30:52.900 --> 01:30:53.900]  like,\n",
            "[01:30:53.900 --> 01:30:54.900]  ah,\n",
            "[01:30:54.900 --> 01:30:55.900]  kahit tapos na,\n",
            "[01:30:55.900 --> 01:30:56.900]  like,\n",
            "[01:30:56.900 --> 01:30:57.900]  240 hours for DOS,\n",
            "[01:30:57.900 --> 01:30:58.900]  yata,\n",
            "[01:30:58.900 --> 01:30:59.900]  eh,\n",
            "[01:30:59.900 --> 01:31:00.900]  ah,\n",
            "[01:31:00.900 --> 01:31:01.900]  like,\n",
            "[01:31:01.900 --> 01:31:02.900]  3 months.\n",
            "[01:31:02.900 --> 01:31:03.900]  Pero meron,\n",
            "[01:31:03.900 --> 01:31:04.900]  yun yung kasi minimum.\n",
            "[01:31:04.900 --> 01:31:05.900]  Ah,\n",
            "[01:31:05.900 --> 01:31:06.900]  I think,\n",
            "[01:31:06.900 --> 01:31:07.900]  around 11k per month nga lang.\n",
            "[01:31:07.900 --> 01:31:08.900]  Parang allowance lang din talaga.\n",
            "[01:31:08.900 --> 01:31:09.900]  And,\n",
            "[01:31:09.900 --> 01:31:10.900]  ang maganda lang din doon kasi,\n",
            "[01:31:10.900 --> 01:31:11.900]  yun nga,\n",
            "[01:31:11.900 --> 01:31:12.900]  they can continue yung output nila\n",
            "[01:31:12.900 --> 01:31:13.900]  hanggang doon sa thesis nila.\n",
            "[01:31:13.900 --> 01:31:14.900]  Yun,\n",
            "[01:31:14.900 --> 01:31:15.900]  parang ginagawa na nila yun,\n",
            "[01:31:15.900 --> 01:31:16.900]  ah,\n",
            "[01:31:16.900 --> 01:31:17.900]  practicum or internship program.\n",
            "[01:31:17.900 --> 01:31:18.900]  Tapos,\n",
            "[01:31:18.900 --> 01:31:19.900]  yun nga,\n",
            "[01:31:19.900 --> 01:31:20.900]  they have access to resources.\n",
            "[01:31:20.900 --> 01:31:21.900]  Tapos,\n",
            "[01:31:21.900 --> 01:31:22.900]  if ever na yung use case mismo,\n",
            "[01:31:22.900 --> 01:31:23.900]  kasi yung nangyayari po ngayon\n",
            "[01:31:23.900 --> 01:31:24.900]  doon sa Project ALAM,\n",
            "[01:31:24.900 --> 01:31:25.900]  as mentioned by Sir Elmer,\n",
            "[01:31:25.900 --> 01:31:26.900]  na,\n",
            "[01:31:26.900 --> 01:31:27.900]  um,\n",
            "[01:31:27.900 --> 01:31:28.900]  yung mga projects,\n",
            "[01:31:28.900 --> 01:31:29.900]  ah,\n",
            "[01:31:29.900 --> 01:31:30.900]  component leaders na,\n",
            "[01:31:30.900 --> 01:31:32.900]  yung mga AI engineers sa ASCII,\n",
            "[01:31:32.900 --> 01:31:34.900]  they're partnering with different institutions\n",
            "[01:31:34.900 --> 01:31:35.900]  like,\n",
            "[01:31:35.900 --> 01:31:36.900]  ah,\n",
            "[01:31:36.900 --> 01:31:37.900]  NGAs,\n",
            "[01:31:37.900 --> 01:31:38.900]  ah,\n",
            "[01:31:38.900 --> 01:31:39.900]  LGUs,\n",
            "[01:31:39.900 --> 01:31:40.900]  nagpaprovide sila ng data.\n",
            "[01:31:40.900 --> 01:31:41.900]  Tapos,\n",
            "[01:31:41.900 --> 01:31:42.900]  merong separate group na\n",
            "[01:31:42.900 --> 01:31:43.900]  naglilabel.\n",
            "[01:31:43.900 --> 01:31:44.900]  Then,\n",
            "[01:31:44.900 --> 01:31:45.900]  yung output na yun,\n",
            "[01:31:45.900 --> 01:31:46.900]  yun yung ginagawa,\n",
            "[01:31:46.900 --> 01:31:47.900]  parang ginagawang training data.\n",
            "[01:31:47.900 --> 01:31:48.900]  So,\n",
            "[01:31:48.900 --> 01:31:49.900]  kung may mga naipon na na-data\n",
            "[01:31:49.900 --> 01:31:50.900]  from ALAM,\n",
            "[01:31:50.900 --> 01:31:51.900]  we can utilize that.\n",
            "[01:31:51.900 --> 01:31:52.900]  Diba,\n",
            "[01:31:52.900 --> 01:31:53.900]  may traffic data at tayo.\n",
            "[01:31:53.900 --> 01:31:54.900]  Kasi yun nga,\n",
            "[01:31:54.900 --> 01:31:55.900]  yung 3D reconstruction ngayon,\n",
            "[01:31:55.900 --> 01:31:56.900]  we're trying to also,\n",
            "[01:31:56.900 --> 01:31:57.900]  um,\n",
            "[01:31:57.900 --> 01:31:58.900]  mag-populate yun.\n",
            "[01:31:58.900 --> 01:31:59.900]  So,\n",
            "[01:31:59.900 --> 01:32:00.900]  mag-populate ng data.\n",
            "[01:32:00.900 --> 01:32:01.900]  And,\n",
            "[01:32:01.900 --> 01:32:02.900]  yun,\n",
            "[01:32:02.900 --> 01:32:03.900]  they can use that.\n",
            "[01:32:03.900 --> 01:32:04.900]  And,\n",
            "[01:32:04.900 --> 01:32:05.900]  may salary.\n",
            "[01:32:05.900 --> 01:32:06.900]  Also,\n",
            "[01:32:06.900 --> 01:32:07.900]  no,\n",
            "[01:32:07.900 --> 01:32:08.900]  parang in consideration din,\n",
            "[01:32:08.900 --> 01:32:09.900]  kung wala yung PSY,\n",
            "[01:32:09.900 --> 01:32:10.900]  ah,\n",
            "[01:32:10.900 --> 01:32:11.900]  yung Presidential Youth Program,\n",
            "[01:32:11.900 --> 01:32:12.900]  na yun.\n",
            "[01:32:12.900 --> 01:32:13.900]  Kasi nire-request din po namin yun.\n",
            "[01:32:13.900 --> 01:32:14.900]  And,\n",
            "[01:32:14.900 --> 01:32:15.900]  nag-agrant naman,\n",
            "[01:32:15.900 --> 01:32:16.900]  kasi we have interns talaga na,\n",
            "[01:32:16.900 --> 01:32:17.900]  nasaswelduhan.\n",
            "[01:32:17.900 --> 01:32:18.900]  Pero,\n",
            "[01:32:18.900 --> 01:32:19.900]  Sir Elmer,\n",
            "[01:32:19.900 --> 01:32:20.900]  meron kasing allocation sa LIE.\n",
            "[01:32:20.900 --> 01:32:21.900]  Maliit lang din naman kasi yung,\n",
            "[01:32:21.900 --> 01:32:22.900]  ano,\n",
            "[01:32:22.900 --> 01:32:23.900]  internship,\n",
            "[01:32:23.900 --> 01:32:24.900]  yata,\n",
            "[01:32:24.900 --> 01:32:25.900]  na,\n",
            "[01:32:25.900 --> 01:32:26.900]  ah,\n",
            "[01:32:26.900 --> 01:32:27.900]  parang may rates yata sila per day.\n",
            "[01:32:27.900 --> 01:32:28.900]  I'm not sure,\n",
            "[01:32:28.900 --> 01:32:29.900]  ah,\n",
            "[01:32:29.900 --> 01:32:30.900]  I'm not sure kung magkano.\n",
            "[01:32:30.900 --> 01:32:31.900]  May 600,\n",
            "[01:32:31.900 --> 01:32:32.900]  700 per day.\n",
            "[01:32:32.900 --> 01:32:33.900]  Um,\n",
            "[01:32:33.900 --> 01:32:34.900]  para sa allowance ng interns.\n",
            "[01:32:34.900 --> 01:32:36.900]  Yung scholarship and training expenses,\n",
            "[01:32:36.900 --> 01:32:37.900]  dun,\n",
            "[01:32:37.900 --> 01:32:38.900]  dun siya nilalagay kapag,\n",
            "[01:32:38.900 --> 01:32:39.900]  nag,\n",
            "[01:32:39.900 --> 01:32:40.900]  ah,\n",
            "[01:32:40.900 --> 01:32:41.900]  ano kami,\n",
            "[01:32:41.900 --> 01:32:42.900]  nagpo-propose kami ng GIA project.\n",
            "[01:32:42.900 --> 01:32:43.900]  Ah,\n",
            "[01:32:43.900 --> 01:32:45.900]  maybe we can consider dun sa next preprogramming,\n",
            "[01:32:45.900 --> 01:32:47.900]  if we want to onboard talaga,\n",
            "[01:32:47.900 --> 01:32:49.900]  interns na,\n",
            "[01:32:49.900 --> 01:32:50.900]  ah,\n",
            "[01:32:50.900 --> 01:32:51.900]  capable,\n",
            "[01:32:51.900 --> 01:32:53.900]  na pwede nating bayaran.\n",
            "[01:32:53.900 --> 01:32:54.900]  So,\n",
            "[01:32:54.900 --> 01:32:56.900]  yun yung isang nakikita kong,\n",
            "[01:32:56.900 --> 01:32:57.900]  ano,\n",
            "[01:32:57.900 --> 01:32:58.900]  hindi naman talaga\n",
            "[01:32:58.900 --> 01:32:59.900]  totally,\n",
            "[01:32:59.900 --> 01:33:00.900]  wala talagang bayar ng interns.\n",
            "[01:33:00.900 --> 01:33:01.900]  Pero,\n",
            "[01:33:01.900 --> 01:33:04.900]  kailangan lang i-allocate sa line item project.\n",
            "[01:33:04.900 --> 01:33:05.900]  Kaya,\n",
            "[01:33:05.900 --> 01:33:06.900]  nagawa na rin naman namin ito before.\n",
            "[01:33:06.900 --> 01:33:07.900]  So,\n",
            "[01:33:07.900 --> 01:33:08.900]  kung magiging\n",
            "[01:33:08.900 --> 01:33:09.900]  continuous yung,\n",
            "[01:33:09.900 --> 01:33:10.900]  ah,\n",
            "[01:33:10.900 --> 01:33:11.900]  um,\n",
            "[01:33:11.900 --> 01:33:12.900]  collab natin on,\n",
            "[01:33:12.900 --> 01:33:13.900]  ah,\n",
            "[01:33:13.900 --> 01:33:14.900]  internship,\n",
            "[01:33:14.900 --> 01:33:15.900]  ah,\n",
            "[01:33:15.900 --> 01:33:16.900]  with ICS,\n",
            "[01:33:16.900 --> 01:33:17.900]  yun po,\n",
            "[01:33:17.900 --> 01:33:18.900]  pwedeng i-consider sa succeeding,\n",
            "[01:33:18.900 --> 01:33:19.900]  ah,\n",
            "[01:33:19.900 --> 01:33:20.900]  kasi ngayon parang hindi naabot eh,\n",
            "[01:33:20.900 --> 01:33:21.900]  this June.\n",
            "[01:33:21.900 --> 01:33:22.900]  So,\n",
            "[01:33:22.900 --> 01:33:23.900]  magre-reprogram pa kasi.\n",
            "[01:33:23.900 --> 01:33:24.900]  So,\n",
            "[01:33:24.900 --> 01:33:25.900]  yun,\n",
            "[01:33:25.900 --> 01:33:26.900]  maliit lang naman na budget din sa ELMO.\n",
            "[01:33:26.900 --> 01:33:27.900]  Yung mga,\n",
            "[01:33:27.900 --> 01:33:28.900]  ano natin,\n",
            "[01:33:28.900 --> 01:33:31.900]  yung pwede natin i-realign ulit\n",
            "[01:33:31.900 --> 01:33:32.900]  sa,\n",
            "[01:33:32.900 --> 01:33:33.900]  sa next re-programming natin.\n",
            "[01:33:33.900 --> 01:33:34.900]  Suggestion lang po.\n",
            "[01:33:34.900 --> 01:33:35.900]  Pero,\n",
            "[01:33:35.900 --> 01:33:36.900]  hindi namin,\n",
            "[01:33:36.900 --> 01:33:37.900]  hindi kami nagpa-promise ng kahit ano.\n",
            "[01:33:37.900 --> 01:33:38.900]  Pero,\n",
            "[01:33:38.900 --> 01:33:39.900]  ah,\n",
            "[01:33:39.900 --> 01:33:40.900]  yun yung isang pwede namin nakitang,\n",
            "[01:33:40.900 --> 01:33:41.900]  ano,\n",
            "[01:33:41.900 --> 01:33:42.900]  ah,\n",
            "[01:33:42.900 --> 01:33:43.900]  nakikitang way\n",
            "[01:33:43.900 --> 01:33:44.900]  to compensate din\n",
            "[01:33:44.900 --> 01:33:45.900]  yung time\n",
            "[01:33:45.900 --> 01:33:46.900]  and capacity\n",
            "[01:33:46.900 --> 01:33:47.900]  ng students.\n",
            "[01:33:47.900 --> 01:33:48.900]  Ayun.\n",
            "[01:33:48.900 --> 01:33:49.900]  Thank you.\n",
            "[01:33:49.900 --> 01:33:50.900]  Thank you,\n",
            "[01:33:50.900 --> 01:33:51.900]  Ms. Rox.\n",
            "[01:33:51.900 --> 01:33:52.900]  Ah,\n",
            "[01:33:52.900 --> 01:33:53.900]  ayun,\n",
            "[01:33:53.900 --> 01:33:54.900]  talk for that,\n",
            "[01:33:54.900 --> 01:33:55.900]  ah,\n",
            "[01:33:55.900 --> 01:33:56.900]  information.\n",
            "[01:33:56.900 --> 01:33:57.900]  Yun po.\n",
            "[01:33:57.900 --> 01:33:58.900]  Teka lang.\n",
            "[01:33:58.900 --> 01:34:00.900]  Ang practicum sa ICS ay,\n",
            "[01:34:00.900 --> 01:34:02.900]  parang 4 weeks lang.\n",
            "[01:34:02.900 --> 01:34:03.900]  Hindi naman siya mahaba\n",
            "[01:34:03.900 --> 01:34:05.900]  katulad nung nabanggit na 3 months.\n",
            "[01:34:05.900 --> 01:34:07.900]  Parang 1 month lang.\n",
            "[01:34:07.900 --> 01:34:10.900]  Except for DOST scholars na,\n",
            "[01:34:10.900 --> 01:34:11.900]  ilan yung ano nila?\n",
            "[01:34:11.900 --> 01:34:12.900]  250,\n",
            "[01:34:12.900 --> 01:34:13.900]  240 ba?\n",
            "[01:34:13.900 --> 01:34:15.900]  Pag DOST scholars.\n",
            "[01:34:15.900 --> 01:34:16.900]  So,\n",
            "[01:34:16.900 --> 01:34:19.900]  parang hindi pa rin naabot siya ng 3 months.\n",
            "[01:34:19.900 --> 01:34:20.900]  Ah,\n",
            "[01:34:20.900 --> 01:34:21.900]  tapos,\n",
            "[01:34:21.900 --> 01:34:23.900]  yung nabanggit ni Sir Arya na,\n",
            "[01:34:23.900 --> 01:34:25.900]  idedesign na lang na halimbawa,\n",
            "[01:34:25.900 --> 01:34:26.900]  bak kung papayag kayo\n",
            "[01:34:26.900 --> 01:34:27.900]  na once a week lang sila,\n",
            "[01:34:27.900 --> 01:34:29.900]  na on-site,\n",
            "[01:34:29.900 --> 01:34:30.900]  tapos online yung\n",
            "[01:34:30.900 --> 01:34:32.900]  the rest of the days.\n",
            "[01:34:32.900 --> 01:34:33.900]  Baka,\n",
            "[01:34:33.900 --> 01:34:34.900]  mainganyo,\n",
            "[01:34:34.900 --> 01:34:36.900]  kasi kung wala naman silang allowance,\n",
            "[01:34:36.900 --> 01:34:38.900]  tapos pupunta sila everyday,\n",
            "[01:34:38.900 --> 01:34:40.900]  baka madiscouraged na.\n",
            "[01:34:40.900 --> 01:34:41.900]  Oo.\n",
            "[01:34:41.900 --> 01:34:42.900]  Oo.\n",
            "[01:34:42.900 --> 01:34:43.900]  So,\n",
            "[01:34:43.900 --> 01:34:44.900]  idesign na lang in such a way na\n",
            "[01:34:44.900 --> 01:34:45.900]  maging enticing.\n",
            "[01:34:47.900 --> 01:34:48.900]  Okay po.\n",
            "[01:34:48.900 --> 01:34:49.900]  That is something that I can\n",
            "[01:34:49.900 --> 01:34:52.900]  ask po yung HRD namin doon sa,\n",
            "[01:34:52.900 --> 01:34:53.900]  with regards to the\n",
            "[01:34:53.900 --> 01:34:55.900]  internship program ng ASTI.\n",
            "[01:34:55.900 --> 01:34:56.900]  Okay.\n",
            "[01:34:57.900 --> 01:34:58.900]  Ah,\n",
            "[01:34:58.900 --> 01:34:59.900]  John?\n",
            "[01:34:59.900 --> 01:35:00.900]  Ah,\n",
            "[01:35:00.900 --> 01:35:01.900]  Sir,\n",
            "[01:35:01.900 --> 01:35:02.900]  mention ko lang po yung ano,\n",
            "[01:35:02.900 --> 01:35:03.900]  ah,\n",
            "[01:35:03.900 --> 01:35:04.900]  yung current\n",
            "[01:35:04.900 --> 01:35:05.900]  ah,\n",
            "[01:35:05.900 --> 01:35:06.900]  MOU po kasi,\n",
            "[01:35:06.900 --> 01:35:08.900]  wala po kasi nakalagay specific doon na,\n",
            "[01:35:08.900 --> 01:35:09.900]  ah,\n",
            "[01:35:09.900 --> 01:35:11.900]  pwedeng gumamit po ng core services po yung UPLG.\n",
            "[01:35:11.900 --> 01:35:12.900]  Kaya po nung,\n",
            "[01:35:12.900 --> 01:35:13.900]  ah,\n",
            "[01:35:13.900 --> 01:35:14.900]  last internship po,\n",
            "[01:35:14.900 --> 01:35:16.900]  medyo nahirapan din po doon sa pag-access.\n",
            "[01:35:16.900 --> 01:35:17.900]  Ah,\n",
            "[01:35:17.900 --> 01:35:18.900]  especially when it comes to their,\n",
            "[01:35:18.900 --> 01:35:19.900]  ano po,\n",
            "[01:35:19.900 --> 01:35:20.900]  thesis na.\n",
            "[01:35:20.900 --> 01:35:21.900]  So,\n",
            "[01:35:21.900 --> 01:35:22.900]  ah,\n",
            "[01:35:22.900 --> 01:35:23.900]  as per kuya HRD po,\n",
            "[01:35:23.900 --> 01:35:24.900]  baka daw po,\n",
            "[01:35:24.900 --> 01:35:25.900]  para po\n",
            "[01:35:25.900 --> 01:35:26.900]  ma-formalize yung paggamit po nung,\n",
            "[01:35:26.900 --> 01:35:27.900]  ah,\n",
            "[01:35:27.900 --> 01:35:28.900]  core system po,\n",
            "[01:35:28.900 --> 01:35:29.900]  ah,\n",
            "[01:35:29.900 --> 01:35:30.900]  I think need daw pong\n",
            "[01:35:30.900 --> 01:35:31.900]  another MOU po.\n",
            "[01:35:31.900 --> 01:35:33.900]  Especially nakalagay po na\n",
            "[01:35:33.900 --> 01:35:36.900]  institutional user po yung UPLG po.\n",
            "[01:35:38.900 --> 01:35:39.900]  Yun po.\n",
            "[01:35:39.900 --> 01:35:40.900]  Thank you.\n",
            "[01:35:42.900 --> 01:35:43.900]  Sige.\n",
            "[01:35:43.900 --> 01:35:44.900]  Baka ano,\n",
            "[01:35:44.900 --> 01:35:46.900]  papasok siya doon sa sinasabi ko kanina na parang\n",
            "[01:35:46.900 --> 01:35:49.900]  addendum to the MOU na lang din.\n",
            "[01:35:49.900 --> 01:35:51.900]  Para at least ma-specify natin\n",
            "[01:35:51.900 --> 01:35:53.900]  kung ano yung mga kailangan natin.\n",
            "[01:35:53.900 --> 01:35:55.900]  Like yung mga pinag-uusapan natin,\n",
            "[01:35:55.900 --> 01:35:57.900]  pinag-discuss natin dito ngayon.\n",
            "[01:35:57.900 --> 01:35:58.900]  Sige po.\n",
            "[01:35:58.900 --> 01:35:59.900]  I-re-review po namin itong,\n",
            "[01:35:59.900 --> 01:36:00.900]  ano,\n",
            "[01:36:00.900 --> 01:36:01.900]  itong recording\n",
            "[01:36:01.900 --> 01:36:02.900]  para ma-i-a,\n",
            "[01:36:02.900 --> 01:36:04.900]  i-document po natin yan.\n",
            "[01:36:04.900 --> 01:36:05.900]  Sir,\n",
            "[01:36:05.900 --> 01:36:06.900]  Aryan?\n",
            "[01:36:08.900 --> 01:36:09.900]  Info lang doon sa ano,\n",
            "[01:36:09.900 --> 01:36:10.900]  yung sa,\n",
            "[01:36:10.900 --> 01:36:11.900]  ano nga,\n",
            "[01:36:11.900 --> 01:36:12.900]  yung sa institutional use.\n",
            "[01:36:12.900 --> 01:36:13.900]  Ang alam ko ang IPB\n",
            "[01:36:13.900 --> 01:36:14.900]  through Darlon Lantican.\n",
            "[01:36:14.900 --> 01:36:16.900]  May pinadala kasi siyang MOU with,\n",
            "[01:36:16.900 --> 01:36:17.900]  ah,\n",
            "[01:36:17.900 --> 01:36:18.900]  MOA with CoR.\n",
            "[01:36:18.900 --> 01:36:19.900]  So,\n",
            "[01:36:19.900 --> 01:36:20.900]  parang,\n",
            "[01:36:20.900 --> 01:36:21.900]  I don't know kung kaya yung buong UPLB.\n",
            "[01:36:21.900 --> 01:36:22.900]  Kasi parang,\n",
            "[01:36:22.900 --> 01:36:23.900]  di ba,\n",
            "[01:36:23.900 --> 01:36:24.900]  si Mamayla individual.\n",
            "[01:36:24.900 --> 01:36:25.900]  Si Darlon,\n",
            "[01:36:25.900 --> 01:36:27.900]  ang alam ko bago siya pumunta ng Florida,\n",
            "[01:36:27.900 --> 01:36:28.900]  nagpadala siya sa akin ng,\n",
            "[01:36:28.900 --> 01:36:29.900]  ano eh,\n",
            "[01:36:29.900 --> 01:36:32.900]  MOU to use CoR\n",
            "[01:36:33.900 --> 01:36:34.900]  through IPB\n",
            "[01:36:35.900 --> 01:36:37.900]  within UPLB.\n",
            "[01:36:38.900 --> 01:36:40.900]  Kaya tingnan natin yung mga patterns na ganun.\n",
            "[01:36:40.900 --> 01:36:41.900]  Paano ba to?\n",
            "[01:36:41.900 --> 01:36:43.900]  Parang akabay with ICS\n",
            "[01:36:44.900 --> 01:36:45.900]  na usage ng CoR?\n",
            "[01:36:45.900 --> 01:36:46.900]  I don't know.\n",
            "[01:36:47.900 --> 01:36:48.900]  Sana po,\n",
            "[01:36:48.900 --> 01:36:49.900]  ano,\n",
            "[01:36:49.900 --> 01:36:50.900]  pagdasal natin.\n",
            "[01:36:50.900 --> 01:36:51.900]  Ay, sige, sige.\n",
            "[01:36:51.900 --> 01:36:52.900]  Sir Vanny.\n",
            "[01:36:52.900 --> 01:36:53.900]  Sir Vanny.\n",
            "[01:36:53.900 --> 01:36:54.900]  Sir Aryan,\n",
            "[01:36:54.900 --> 01:36:55.900]  ang,\n",
            "[01:36:55.900 --> 01:36:56.900]  ang,\n",
            "[01:36:56.900 --> 01:36:59.900]  ang ICS po ba nage-enter ng mga MOA?\n",
            "[01:36:59.900 --> 01:37:00.900]  Kasi,\n",
            "[01:37:00.900 --> 01:37:01.900]  ako,\n",
            "[01:37:01.900 --> 01:37:02.900]  unless,\n",
            "[01:37:02.900 --> 01:37:03.900]  unless mas,\n",
            "[01:37:03.900 --> 01:37:06.900]  ang protocol po sa inyo ay all the way sa top ng UPLB.\n",
            "[01:37:06.900 --> 01:37:08.900]  Baka mas madali po na,\n",
            "[01:37:08.900 --> 01:37:09.900]  ano eh,\n",
            "[01:37:09.900 --> 01:37:10.900]  sa ICS ang MOA.\n",
            "[01:37:10.900 --> 01:37:11.900]  Oo nga.\n",
            "[01:37:11.900 --> 01:37:12.900]  Kaya,\n",
            "[01:37:12.900 --> 01:37:13.900]  kaya ako nagkakabi ng,\n",
            "[01:37:13.900 --> 01:37:15.900]  I was thinking of,\n",
            "[01:37:15.900 --> 01:37:16.900]  ah,\n",
            "[01:37:16.900 --> 01:37:17.900]  kami ni Mamayla na,\n",
            "[01:37:17.900 --> 01:37:18.900]  i-ano na nga,\n",
            "[01:37:18.900 --> 01:37:19.900]  iuna na\n",
            "[01:37:19.900 --> 01:37:20.900]  before pa may gumamit.\n",
            "[01:37:20.900 --> 01:37:21.900]  Hindi lang namin na-push.\n",
            "[01:37:21.900 --> 01:37:22.900]  So,\n",
            "[01:37:22.900 --> 01:37:23.900]  maybe it's high time,\n",
            "[01:37:23.900 --> 01:37:24.900]  may special na,\n",
            "[01:37:24.900 --> 01:37:25.900]  gawa rin tayo ng,\n",
            "[01:37:25.900 --> 01:37:26.900]  ano,\n",
            "[01:37:26.900 --> 01:37:27.900]  with co-worker.\n",
            "[01:37:27.900 --> 01:37:28.900]  Kaso,\n",
            "[01:37:28.900 --> 01:37:29.900]  yung,\n",
            "[01:37:29.900 --> 01:37:30.900]  kaya yata ako napatrust nun,\n",
            "[01:37:30.900 --> 01:37:31.900]  kasi si Darlon,\n",
            "[01:37:31.900 --> 01:37:32.900]  may project siya.\n",
            "[01:37:32.900 --> 01:37:33.900]  So,\n",
            "[01:37:33.900 --> 01:37:34.900]  very specific yung usage request niya.\n",
            "[01:37:34.900 --> 01:37:35.900]  Tayo kasi,\n",
            "[01:37:35.900 --> 01:37:36.900]  parang titignan pa natin eh,\n",
            "[01:37:36.900 --> 01:37:37.900]  kung anong actual usage.\n",
            "[01:37:37.900 --> 01:37:38.900]  Sige na lang,\n",
            "[01:37:38.900 --> 01:37:39.900]  pag-usapan na lang siguro next time yung details ng,\n",
            "[01:37:39.900 --> 01:37:40.900]  ano na yun.\n",
            "[01:37:40.900 --> 01:37:41.900]  Sa practicum,\n",
            "[01:37:41.900 --> 01:37:42.900]  sir,\n",
            "[01:37:42.900 --> 01:37:43.900]  wala,\n",
            "[01:37:43.900 --> 01:37:44.900]  hindi ba tayo nage-enter na hanggang sa atin lang yung agreement between the ICS and the company?\n",
            "[01:37:44.900 --> 01:37:45.900]  Hindi ba tayo nage-enter na hanggang sa atin lang yung agreement between the ICS and the company?\n",
            "[01:37:45.900 --> 01:37:53.900]  Hindi ba tayo nage-enter na hanggang sa atin lang yung agreement between the ICS and the company?\n",
            "[01:37:53.900 --> 01:37:54.900]  Ay meron yata yun ma'am,\n",
            "[01:37:54.900 --> 01:37:55.900]  hanggang ano?\n",
            "[01:37:55.900 --> 01:37:56.900]  Hanggang,\n",
            "[01:37:56.900 --> 01:37:57.900]  Pero sa practicum,\n",
            "[01:37:57.900 --> 01:37:58.900]  at least,\n",
            "[01:37:58.900 --> 01:37:59.900]  practicum?\n",
            "[01:37:59.900 --> 01:38:00.900]  Hmm,\n",
            "[01:38:00.900 --> 01:38:01.900]  kasolve natin hanggang doon,\n",
            "[01:38:01.900 --> 01:38:03.900]  tapos habang inaayos natin yung,\n",
            "[01:38:03.900 --> 01:38:05.900]  para sa next,\n",
            "[01:38:05.900 --> 01:38:06.900]  ano,\n",
            "[01:38:06.900 --> 01:38:07.900]  like SP.\n",
            "[01:38:07.900 --> 01:38:08.900]  Okay.\n",
            "[01:38:08.900 --> 01:38:09.900]  Like SP.\n",
            "[01:38:09.900 --> 01:38:10.900]  Meron ba tayong ganon?\n",
            "[01:38:10.900 --> 01:38:11.900]  Parang,\n",
            "[01:38:11.900 --> 01:38:12.900]  Ma'am,\n",
            "[01:38:12.900 --> 01:38:13.900]  required ang alam ko sa practicum hanggang dean's office yata eh.\n",
            "[01:38:13.900 --> 01:38:14.900]  Ma'am,\n",
            "[01:38:14.900 --> 01:38:15.900]  required ang alam ko sa practicum hanggang dean's office yata eh.\n",
            "[01:38:15.900 --> 01:38:16.900]  Ayan.\n",
            "[01:38:16.900 --> 01:38:17.900]  May requirement.\n",
            "[01:38:17.900 --> 01:38:18.900]  So starting with CIF,\n",
            "[01:38:18.900 --> 01:38:19.900]  so starting with CIF,\n",
            "[01:38:19.900 --> 01:38:20.900]  tapos,\n",
            "[01:38:20.900 --> 01:38:21.900]  ano nga tawag doon mamayla?\n",
            "[01:38:21.900 --> 01:38:22.900]  Ano nga tawag doon mamayla?\n",
            "[01:38:22.900 --> 01:38:23.900]  Meron yan doon sa guide na pinadala ni mamayla\n",
            "[01:38:23.900 --> 01:38:24.900]  Meron yan doon sa guide na pinadala ni mamayla\n",
            "[01:38:24.900 --> 01:38:25.900]  na pinipirmahan yung dean's office\n",
            "[01:38:25.900 --> 01:38:26.900]  na pinipirmahan yung dean's office\n",
            "[01:38:26.900 --> 01:38:27.900]  na pinipirmahan yung dean's office\n",
            "[01:38:27.900 --> 01:38:28.900]  or practicum.\n",
            "[01:38:28.900 --> 01:38:29.900]  or practicum.\n",
            "[01:38:29.900 --> 01:38:30.900]  Pero yung siya kuwar,\n",
            "[01:38:30.900 --> 01:38:32.900]  gusto ko lang i-info na,\n",
            "[01:38:32.900 --> 01:38:33.900]  IPB has kuwar,\n",
            "[01:38:33.900 --> 01:38:34.900]  institutional MOA.\n",
            "[01:38:34.900 --> 01:38:35.900]  IPB has kuwar,\n",
            "[01:38:35.900 --> 01:38:36.900]  institutional MOA.\n",
            "[01:38:36.900 --> 01:38:37.900]  Ayan,\n",
            "[01:38:37.900 --> 01:38:38.900]  merong link.\n",
            "[01:38:38.900 --> 01:38:39.900]  Ano yung link na iyon ma'am?\n",
            "[01:38:39.900 --> 01:38:41.100]  Ano yung link na yun, ma'am?\n",
            "[01:38:42.440 --> 01:38:43.720]  Yeah, ito po yung\n",
            "[01:38:43.720 --> 01:38:45.800]  letter of agreement between\n",
            "[01:38:45.800 --> 01:38:47.040]  ICS and\n",
            "[01:38:47.040 --> 01:38:49.580]  company. In this case,\n",
            "[01:38:49.760 --> 01:38:50.260]  DOST\n",
            "[01:38:50.260 --> 01:38:52.840]  ST. Tama ba?\n",
            "[01:38:53.360 --> 01:38:55.340]  Yeah. So,\n",
            "[01:38:55.740 --> 01:38:57.620]  ano po? Yun, meron\n",
            "[01:38:57.620 --> 01:38:58.380]  naman ho ito.\n",
            "[01:38:59.920 --> 01:39:00.900]  Hanggang din ba daw?\n",
            "[01:39:00.900 --> 01:39:01.460]  Ano daw sabi?\n",
            "[01:39:03.060 --> 01:39:04.020]  Parang, parang.\n",
            "[01:39:04.460 --> 01:39:05.760]  Naka-record eh.\n",
            "[01:39:09.900 --> 01:39:12.040]  Sino ang pipirma din ito?\n",
            "[01:39:12.600 --> 01:39:13.900]  Hanggang din. Okay.\n",
            "[01:39:14.960 --> 01:39:15.920]  Pwede natin i-try.\n",
            "[01:39:22.700 --> 01:39:24.940]  Yung sasabihin ko po sana dati\n",
            "[01:39:24.940 --> 01:39:26.520]  kasi ito nga, since\n",
            "[01:39:26.520 --> 01:39:28.620]  na talaga ang\n",
            "[01:39:28.620 --> 01:39:30.400]  DOST na mag-lead dun sa ano,\n",
            "[01:39:31.040 --> 01:39:31.980]  sana lang bigyan din\n",
            "[01:39:31.980 --> 01:39:34.720]  naka-akibat na resources\n",
            "[01:39:34.720 --> 01:39:36.060]  sa DOST. Like,\n",
            "[01:39:36.480 --> 01:39:39.020]  ma-pondohan\n",
            "[01:39:39.020 --> 01:39:39.660]  yung mga\n",
            "[01:39:39.660 --> 01:39:41.140]  high-performance\n",
            "[01:39:41.140 --> 01:39:44.060]  computer infrastructure para at least\n",
            "[01:39:44.060 --> 01:39:46.720]  hindi na, ano. Kasi honestly po,\n",
            "[01:39:47.240 --> 01:39:48.100]  nung nag-assess kami\n",
            "[01:39:48.100 --> 01:39:50.280]  sa court, tinignan namin yung\n",
            "[01:39:50.280 --> 01:39:52.460]  ano, sabi ni Doc Franz kanina.\n",
            "[01:39:53.020 --> 01:39:54.560]  Sa atin pa lang, baka ano na\n",
            "[01:39:54.560 --> 01:39:56.000]  yung gamit pa lang. Because yung\n",
            "[01:39:56.000 --> 01:39:58.020]  dami nga ng mga AI projects.\n",
            "[01:39:58.020 --> 01:40:00.140]  Tapos mag-share pa tayo, parang ganon.\n",
            "[01:40:00.580 --> 01:40:01.820]  So, parang na-\n",
            "[01:40:01.820 --> 01:40:04.180]  imagine ko, we really need\n",
            "[01:40:04.180 --> 01:40:05.700]  to, ano. Yun po yung sa\n",
            "[01:40:05.700 --> 01:40:08.200]  Akabay naman, talagang pibili kami\n",
            "[01:40:08.200 --> 01:40:09.480]  ng ano. And hopefully,\n",
            "[01:40:09.660 --> 01:40:11.740]  pag merong mga,\n",
            "[01:40:12.160 --> 01:40:13.700]  yun nga, yung mga use cases na ano,\n",
            "[01:40:13.880 --> 01:40:16.060]  magamit po natin itong mga, ano na to.\n",
            "[01:40:16.860 --> 01:40:18.140]  Super high-performance\n",
            "[01:40:18.140 --> 01:40:19.460]  computers na to.\n",
            "[01:40:20.420 --> 01:40:21.600]  Yung HPC ng\n",
            "[01:40:21.600 --> 01:40:24.080]  UPLB, sorry ha, kasi\n",
            "[01:40:24.080 --> 01:40:25.840]  parang internal yung\n",
            "[01:40:25.840 --> 01:40:27.500]  dynamics, ano.\n",
            "[01:40:28.000 --> 01:40:30.520]  Pero, since hindi nagagamit,\n",
            "[01:40:30.660 --> 01:40:31.600]  possible ba na\n",
            "[01:40:31.600 --> 01:40:34.040]  parang i-introduce kami\n",
            "[01:40:34.040 --> 01:40:36.180]  ng ASCII? Hindi ko alam paano yun. Kasi parang\n",
            "[01:40:36.180 --> 01:40:38.100]  tatawid kami sa ibang\n",
            "[01:40:38.100 --> 01:40:38.720]  college.\n",
            "[01:40:39.660 --> 01:40:41.760]  So, may mga ganong dynamics, ano,\n",
            "[01:40:41.860 --> 01:40:42.640]  recorded kasi.\n",
            "[01:40:44.180 --> 01:40:45.940]  So, hindi ko alam how\n",
            "[01:40:45.940 --> 01:40:47.820]  we are going to, ano.\n",
            "[01:40:48.920 --> 01:40:50.120]  Ang pagkakalam ko po kasi,\n",
            "[01:40:50.260 --> 01:40:51.760]  yun mga yun ay donated by the\n",
            "[01:40:51.760 --> 01:40:53.360]  OSP. Pero,\n",
            "[01:40:53.820 --> 01:40:55.880]  dinonate yun sa, merong mga\n",
            "[01:40:55.880 --> 01:40:57.780]  recipient po eh. Kunyari in your case,\n",
            "[01:40:57.840 --> 01:40:59.640]  yata ang recipient, yan si Sir JP\n",
            "[01:40:59.640 --> 01:41:01.420]  Ramoso, ng\n",
            "[01:41:01.420 --> 01:41:04.020]  Department of Electrical Engineering.\n",
            "[01:41:04.720 --> 01:41:05.920]  Yata po. Tapos,\n",
            "[01:41:06.300 --> 01:41:07.920]  dito naman po, meron din, kumbaga,\n",
            "[01:41:08.120 --> 01:41:08.460]  naka-\n",
            "[01:41:08.460 --> 01:41:10.620]  kay Sir Peter, yung\n",
            "[01:41:10.620 --> 01:41:12.020]  nakapangalan. May mga, ano.\n",
            "[01:41:12.600 --> 01:41:14.680]  So, hindi ko po alam kung paano\n",
            "[01:41:14.680 --> 01:41:16.140]  yung, ano,\n",
            "[01:41:16.340 --> 01:41:18.980]  nung ganon. Hindi ko alam din kung ano yung\n",
            "[01:41:18.980 --> 01:41:20.640]  utilization nung, ano.\n",
            "[01:41:20.860 --> 01:41:22.900]  Kasi nga, tinitina din namin, baka\n",
            "[01:41:22.900 --> 01:41:24.880]  what we wanted to, ano,\n",
            "[01:41:24.980 --> 01:41:26.240]  doon sana, like,\n",
            "[01:41:26.800 --> 01:41:28.820]  yung mga na, ano na yun, baka naman kasi\n",
            "[01:41:28.820 --> 01:41:30.720]  meron doon mga underutilized, yung iban\n",
            "[01:41:30.720 --> 01:41:32.720]  man sobrang, ano, parang kung\n",
            "[01:41:32.720 --> 01:41:34.660]  ano sana ma-utilize natin\n",
            "[01:41:34.660 --> 01:41:35.800]  ng mabuti. But, anyway.\n",
            "[01:41:36.260 --> 01:41:36.700]  Anyway.\n",
            "[01:41:38.460 --> 01:41:40.460]  Suggestion ka, Sir Aryan, hindi ko alam\n",
            "[01:41:40.460 --> 01:41:42.100]  masyado ang dynamics dyan.\n",
            "[01:41:42.340 --> 01:41:44.360]  Kami, ma'am, kaka-app ko lang\n",
            "[01:41:44.360 --> 01:41:46.280]  banin yung, ano, Rock M. Nagro-Rock M\n",
            "[01:41:46.280 --> 01:41:47.960]  ba kayo? Parang hindi yata kayo nagro-Rock M.\n",
            "[01:41:48.140 --> 01:41:50.020]  Mayaman ng, ano, DOST.\n",
            "[01:41:50.320 --> 01:41:51.280]  Kuda kayo, e, no?\n",
            "[01:41:52.400 --> 01:41:54.360]  Actually, yan yung ano ko dito, e. Parang\n",
            "[01:41:54.360 --> 01:41:56.200]  come on, e. Na-interest ako na pa\n",
            "[01:41:56.200 --> 01:41:58.200]  bilisin yung five days na run ni\n",
            "[01:41:58.200 --> 01:42:00.180]  Actually, rerun niya na yun\n",
            "[01:42:00.180 --> 01:42:02.180]  ni Doc Val. Sabihin ko sa kanya\n",
            "[01:42:02.180 --> 01:42:04.380]  na may maganda. Actually, nag-shot ko na yata\n",
            "[01:42:04.380 --> 01:42:06.280]  siya, e. Nabalita ako\n",
            "[01:42:06.280 --> 01:42:08.160]  may maganda kayong GPU. Sa,\n",
            "[01:42:08.460 --> 01:42:10.160]  lab kasi natin, ma'am, Hymem yung sa\n",
            "[01:42:10.160 --> 01:42:12.520]  PGC. Pero, may isa doon\n",
            "[01:42:12.520 --> 01:42:14.360]  yung sa IBS. Kakaroon ko lang last week\n",
            "[01:42:14.360 --> 01:42:16.540]  na pag-ana na finally yung AMD\n",
            "[01:42:16.540 --> 01:42:18.080]  Rock M. So,\n",
            "[01:42:18.320 --> 01:42:19.960]  pero, hindi kasi yung standard, e.\n",
            "[01:42:20.020 --> 01:42:22.260]  Ang malimitan, pag may mga\n",
            "[01:42:22.260 --> 01:42:24.640]  software, kuda agad yan, e.\n",
            "[01:42:24.660 --> 01:42:25.500]  Kuda. Kuda.\n",
            "[01:42:25.820 --> 01:42:27.580]  So, yung Rock M, nag-ahabol pa lang.\n",
            "[01:42:27.800 --> 01:42:30.160]  Kami, nasa ano kami? R&D kami ng Rock M\n",
            "[01:42:30.160 --> 01:42:30.760]  ngayon, Bani.\n",
            "[01:42:31.900 --> 01:42:34.160]  Mag-praran pala kami, aside from Wood-Eye,\n",
            "[01:42:34.160 --> 01:42:35.220]  ng Gromax.\n",
            "[01:42:35.880 --> 01:42:38.320]  Nag-praran din si... Yung Gromax, ano yun, ma'am?\n",
            "[01:42:38.460 --> 01:42:39.760]  Yung mga molecular dynamics.\n",
            "[01:42:40.740 --> 01:42:41.800]  Tapos, ayun, yung\n",
            "[01:42:41.800 --> 01:42:43.920]  isa yun sa pwedeng application din ng\n",
            "[01:42:43.920 --> 01:42:45.540]  Akabay. Baka\n",
            "[01:42:45.540 --> 01:42:47.920]  si Sir Andy Montecilio, meron siyang\n",
            "[01:42:47.920 --> 01:42:49.900]  PhD students. Wala pa nga\n",
            "[01:42:49.900 --> 01:42:50.500]  experience.\n",
            "[01:42:52.180 --> 01:42:53.960]  De, pero, at the end of the day,\n",
            "[01:42:54.020 --> 01:42:55.800]  it's just a job that will require your\n",
            "[01:42:55.800 --> 01:42:57.700]  high-end GPU.\n",
            "[01:42:58.260 --> 01:42:58.420]  Naks.\n",
            "[01:42:59.460 --> 01:43:02.260]  Si Ma'am Mayla, ang dami din ginagawa niyan.\n",
            "[01:43:02.260 --> 01:43:03.040]  Ano siya?\n",
            "[01:43:03.640 --> 01:43:06.140]  BS CompSci, tapos, nag-masteral\n",
            "[01:43:06.140 --> 01:43:08.420]  sa genetics. Kaya, ang mga publications\n",
            "[01:43:08.460 --> 01:43:10.100]  niya, related sa mga ganon.\n",
            "[01:43:10.460 --> 01:43:12.100]  Ma'am, kasi may mga\n",
            "[01:43:12.100 --> 01:43:14.320]  wood, ano, wood AI.\n",
            "[01:43:14.760 --> 01:43:16.280]  Pero, actually, yung core po, ginagamit\n",
            "[01:43:16.280 --> 01:43:18.060]  na sa omics, I think, kasi, tama ba\n",
            "[01:43:18.060 --> 01:43:19.940]  Sir Bani, meron sa PGC?\n",
            "[01:43:20.160 --> 01:43:22.200]  Or sa IRI? Sa IRI, pala.\n",
            "[01:43:22.860 --> 01:43:24.000]  Meron po.\n",
            "[01:43:26.120 --> 01:43:28.260]  Yes po, ginagamit po nila sa IRI po.\n",
            "[01:43:28.440 --> 01:43:29.200]  Tsaka sa PGC.\n",
            "[01:43:30.140 --> 01:43:31.680]  Yung HPC po ng\n",
            "[01:43:31.680 --> 01:43:33.980]  Philippine Genome, si Asti po yung\n",
            "[01:43:33.980 --> 01:43:36.400]  nagtulong mag-architect at mag-develop po.\n",
            "[01:43:37.380 --> 01:43:37.700]  Tapos,\n",
            "[01:43:37.800 --> 01:43:38.280]  ah,\n",
            "[01:43:38.460 --> 01:43:40.460]  yung kakulangan na nakikita po\n",
            "[01:43:40.460 --> 01:43:42.280]  natin sa computing, isa po\n",
            "[01:43:42.280 --> 01:43:44.260]  sa gustong gawin ni Asti,\n",
            "[01:43:44.340 --> 01:43:45.680]  although naka-pipeline pa po,\n",
            "[01:43:46.180 --> 01:43:48.000]  yung federation,\n",
            "[01:43:48.240 --> 01:43:50.460]  federated na HPC infrastructure.\n",
            "[01:43:51.140 --> 01:43:52.260]  So, kung matuloy\n",
            "[01:43:52.260 --> 01:43:54.080]  man po yun, at makakuha ng\n",
            "[01:43:54.080 --> 01:43:56.320]  pondo, baka interested\n",
            "[01:43:56.320 --> 01:43:58.360]  kayo sa ICS po, na\n",
            "[01:43:58.360 --> 01:44:00.320]  maging hub ng isang\n",
            "[01:44:00.320 --> 01:44:02.120]  HPC facility po,\n",
            "[01:44:02.420 --> 01:44:03.580]  dyan sa UPLB.\n",
            "[01:44:04.100 --> 01:44:05.340]  Yun, thank you Sir Bani.\n",
            "[01:44:06.460 --> 01:44:08.000]  Pero, nasa pipeline pa po yun, ah.\n",
            "[01:44:08.460 --> 01:44:09.880]  Luto pa ng proposal.\n",
            "[01:44:10.680 --> 01:44:12.920]  Wala, nakalimutan ko pala.\n",
            "[01:44:14.300 --> 01:44:15.780]  Tama, yun po, isa pa lang\n",
            "[01:44:15.780 --> 01:44:16.620]  reason ko bakit\n",
            "[01:44:16.620 --> 01:44:20.340]  kung bakit tayo nagpa-meeting.\n",
            "[01:44:20.720 --> 01:44:22.800]  Yung sinasabi ni Sir Bani.\n",
            "[01:44:22.940 --> 01:44:24.200]  At saka yun po yung sinasabi ko\n",
            "[01:44:24.200 --> 01:44:26.320]  na ipag-usal natin, na sana mapondohan,\n",
            "[01:44:26.940 --> 01:44:28.000]  mabigyan. Pero,\n",
            "[01:44:28.380 --> 01:44:30.060]  kasi nakikita namin talaga na\n",
            "[01:44:30.060 --> 01:44:32.320]  yung kailangan naman i-diff up\n",
            "[01:44:32.320 --> 01:44:33.940]  yung ano, tapos, yung\n",
            "[01:44:33.940 --> 01:44:36.280]  kanina pinakita ko yung sa map, na ano,\n",
            "[01:44:36.960 --> 01:44:38.380]  parang, yun nga po, yung parang\n",
            "[01:44:38.380 --> 01:44:40.280]  grid computing siya. Grid computing siya\n",
            "[01:44:40.280 --> 01:44:41.880]  since, ano, pero\n",
            "[01:44:41.880 --> 01:44:43.940]  yung control, like for example,\n",
            "[01:44:44.120 --> 01:44:45.460]  meron kayo, like yung, yung,\n",
            "[01:44:46.120 --> 01:44:48.080]  meron kayong ano dyan. We're actually\n",
            "[01:44:48.080 --> 01:44:50.060]  looking into this, na\n",
            "[01:44:50.060 --> 01:44:53.000]  paano yung makikipag-contribute\n",
            "[01:44:53.000 --> 01:44:54.260]  yung may mga compute\n",
            "[01:44:54.260 --> 01:44:56.000]  facilities\n",
            "[01:44:56.000 --> 01:44:58.460]  sa isang federation,\n",
            "[01:44:58.520 --> 01:45:00.020]  sa isang group, wherein\n",
            "[01:45:00.020 --> 01:45:01.920]  hindi pa rin, hindi nila kailangan\n",
            "[01:45:01.920 --> 01:45:04.220]  i-yield yung administrative control\n",
            "[01:45:04.220 --> 01:45:06.180]  nila dun sa ano. But they can still share\n",
            "[01:45:06.180 --> 01:45:07.660]  yung computing kung sakaling under\n",
            "[01:45:07.660 --> 01:45:09.560]  underutilized, parang gano'n.\n",
            "[01:45:10.260 --> 01:45:11.820]  So, yun po yung idea\n",
            "[01:45:11.820 --> 01:45:13.360]  doon sa aming, ano,\n",
            "[01:45:13.920 --> 01:45:16.040]  yung nire-research namin\n",
            "[01:45:16.040 --> 01:45:17.760]  ngayon. And later on po, yun nga,\n",
            "[01:45:17.800 --> 01:45:19.100]  sinasabi ni Sir Van, halimbawa,\n",
            "[01:45:19.260 --> 01:45:21.780]  maging node kayo, ayun po, magiging\n",
            "[01:45:21.780 --> 01:45:24.220]  part kayo nung, ano, nung parang\n",
            "[01:45:24.220 --> 01:45:25.900]  federated computing po\n",
            "[01:45:25.900 --> 01:45:26.720]  na, ano, na\n",
            "[01:45:26.720 --> 01:45:29.920]  isabing po sa aim ng NICE-PH.\n",
            "[01:45:37.660 --> 01:45:42.020]  Ayan, yes daw\n",
            "[01:45:42.020 --> 01:45:44.040]  ang sagot nila, yes. O yun, meron na tayo\n",
            "[01:45:44.040 --> 01:45:45.560]  Sir Vani, sana matuloy.\n",
            "[01:45:46.060 --> 01:45:47.520]  Isang node na itong UPLV.\n",
            "[01:45:49.360 --> 01:45:50.380]  Vani, akala ko\n",
            "[01:45:50.380 --> 01:45:51.180]  malaki na yung\n",
            "[01:45:51.180 --> 01:45:54.180]  akala ko malaki na yung 2TB RAM\n",
            "[01:45:54.180 --> 01:45:56.000]  sa 1TB RAM\n",
            "[01:45:56.000 --> 01:45:57.820]  ng IBS, pinahiya ni\n",
            "[01:45:57.820 --> 01:46:00.140]  Sir Andy Montesilio.\n",
            "[01:46:00.740 --> 01:46:02.520]  Soon to be, Doc, Andy Montesilio\n",
            "[01:46:02.520 --> 01:46:03.800]  1TB, ubus.\n",
            "[01:46:04.400 --> 01:46:06.140]  Sabi niya, hindi na akong mag-8 thread, Sir,\n",
            "[01:46:06.260 --> 01:46:07.500]  kasi sa 4 threads pa lang na nilalagay.\n",
            "[01:46:07.500 --> 01:46:09.500]  Na nirarun niya na by Informatics Pipeline,\n",
            "[01:46:09.620 --> 01:46:11.720]  ubus ang, ano, 1TB RAM.\n",
            "[01:46:12.480 --> 01:46:14.040]  So, may taga, ano na kami\n",
            "[01:46:14.040 --> 01:46:15.960]  dito. Kami bahala sa usage.\n",
            "[01:46:17.300 --> 01:46:18.380]  To justify.\n",
            "[01:46:21.320 --> 01:46:21.800]  Madaming\n",
            "[01:46:21.800 --> 01:46:23.800]  data dito sa, ano, UPLV.\n",
            "[01:46:24.900 --> 01:46:26.020]  Pero sa akabay, ma'am,\n",
            "[01:46:26.140 --> 01:46:27.820]  parang, ito, yung GPU,\n",
            "[01:46:28.060 --> 01:46:29.820]  ngayon ako nakakakita ng, parang, ano,\n",
            "[01:46:30.060 --> 01:46:31.900]  very demanding na,\n",
            "[01:46:32.180 --> 01:46:33.840]  ano, use for GPU.\n",
            "[01:46:34.920 --> 01:46:35.820]  Kaya, we can\n",
            "[01:46:35.820 --> 01:46:36.440]  start with that.\n",
            "[01:46:37.500 --> 01:46:39.740]  Actually, po, isa rin, isa lang yan yung mga\n",
            "[01:46:39.740 --> 01:46:42.260]  napagsapang. Hindi pa natin, ibabalikan ko\n",
            "[01:46:42.260 --> 01:46:44.040]  lang yung, ano, yung\n",
            "[01:46:44.040 --> 01:46:46.340]  parang itanong o yung chatbot.\n",
            "[01:46:47.040 --> 01:46:48.360]  Isa rin po yun na\n",
            "[01:46:48.360 --> 01:46:50.100]  mga very heavy\n",
            "[01:46:50.100 --> 01:46:51.780]  naman sa DRAM at saka sa\n",
            "[01:46:51.780 --> 01:46:54.040]  GPU. Kasi, hindi na natin\n",
            "[01:46:54.040 --> 01:46:56.320]  kailangan mag-rely sa chat GPT.\n",
            "[01:46:56.840 --> 01:46:58.240]  Basi, bali, magda-download\n",
            "[01:46:58.240 --> 01:46:59.920]  tayo ng open source LLM.\n",
            "[01:47:00.140 --> 01:47:02.040]  Marami na ngayon, eh. Meron, hindi lang meta\n",
            "[01:47:02.040 --> 01:47:03.700]  yung nag-ano, pati yung mga Chinese na,\n",
            "[01:47:04.220 --> 01:47:06.260]  ano, pero pwede tayo mag-run locally\n",
            "[01:47:06.260 --> 01:47:07.420]  ng mga large,\n",
            "[01:47:07.500 --> 01:47:09.180]  language models. Tapos,\n",
            "[01:47:09.560 --> 01:47:13.220]  i-fine-tune natin yun\n",
            "[01:47:13.220 --> 01:47:14.160]  doon sa mga\n",
            "[01:47:14.160 --> 01:47:15.460]  policies or\n",
            "[01:47:15.460 --> 01:47:18.080]  like that, dyan sa, ano, yung mga documents\n",
            "[01:47:18.080 --> 01:47:19.160]  dyan sa, ano. Mga legal.\n",
            "[01:47:19.740 --> 01:47:21.900]  Opo, mga legal. O kung ano yung mga\n",
            "[01:47:21.900 --> 01:47:24.500]  frequently asked questions\n",
            "[01:47:24.500 --> 01:47:26.100]  na, ano, parang ganun po\n",
            "[01:47:26.100 --> 01:47:28.240]  yung isa rin na tinitingnan\n",
            "[01:47:28.240 --> 01:47:30.160]  mga possible use\n",
            "[01:47:30.160 --> 01:47:31.340]  cases po na, ano.\n",
            "[01:47:32.500 --> 01:47:32.700]  Ayan.\n",
            "[01:47:36.140 --> 01:47:37.340]  May question,\n",
            "[01:47:37.500 --> 01:47:37.960]  kapo ba?\n",
            "[01:47:42.040 --> 01:47:43.900]  Sanggalingan dito nyo sa, ano,\n",
            "[01:47:44.120 --> 01:47:46.020]  sa Tagalog.\n",
            "[01:47:46.120 --> 01:47:47.480]  Eh, Tagalog ba yun? O,\n",
            "[01:47:47.640 --> 01:47:48.860]  multilingual ba yun?\n",
            "[01:47:49.700 --> 01:47:50.900]  Ay, wala si Ayo dito.\n",
            "[01:47:51.400 --> 01:47:53.380]  Ano po, halo-halo.\n",
            "[01:47:53.520 --> 01:47:55.480]  Meron kaming in-scrape\n",
            "[01:47:55.480 --> 01:47:56.860]  before na\n",
            "[01:47:56.860 --> 01:47:59.540]  yung Philippine, ah, yung Supreme Court\n",
            "[01:47:59.540 --> 01:48:01.540]  decisions from 1900s\n",
            "[01:48:01.540 --> 01:48:02.800]  to 2020.\n",
            "[01:48:03.720 --> 01:48:05.280]  May ganun kami. Meron din\n",
            "[01:48:05.280 --> 01:48:07.480]  kaming mga, yung\n",
            "[01:48:07.500 --> 01:48:08.780]  ano po, ah,\n",
            "[01:48:09.300 --> 01:48:11.700]  tawag doon, sa Project Gutenberg,\n",
            "[01:48:11.840 --> 01:48:13.620]  mga Tagalog na libro, nandun.\n",
            "[01:48:13.760 --> 01:48:15.420]  Tapos, Wikipedia Tagalog.\n",
            "[01:48:15.860 --> 01:48:17.240]  At saka, mga,\n",
            "[01:48:18.240 --> 01:48:19.420]  hindi ko alam kung saan pinagkukuha\n",
            "[01:48:19.420 --> 01:48:21.600]  ni Ali yun. Iba sa mga telenovela\n",
            "[01:48:21.600 --> 01:48:23.260]  na mga transcripts sa YouTube,\n",
            "[01:48:23.480 --> 01:48:25.540]  mga ganun. Yan yung iba\n",
            "[01:48:25.540 --> 01:48:27.000]  po na, ano, ano po ba?\n",
            "[01:48:27.260 --> 01:48:29.680]  Alam mo, yung isang dream ko,\n",
            "[01:48:31.340 --> 01:48:31.780]  ah,\n",
            "[01:48:32.940 --> 01:48:34.300]  pwede tayo kasing gumawa\n",
            "[01:48:34.300 --> 01:48:36.360]  ng, alimbawa, makikipag-partner\n",
            "[01:48:36.360 --> 01:48:37.440]  tayo. Kasi yung iba,\n",
            "[01:48:37.500 --> 01:48:39.440]  kinukuha lang, halimbawa, Avante.\n",
            "[01:48:40.020 --> 01:48:42.140]  Pero, sasabihin natin kay Avante,\n",
            "[01:48:42.340 --> 01:48:43.940]  gagawa namin kayo ng corpus,\n",
            "[01:48:44.040 --> 01:48:46.080]  Avante corpus, para win-win.\n",
            "[01:48:46.280 --> 01:48:47.720]  Hindi natin basta kinuha lang\n",
            "[01:48:47.720 --> 01:48:49.740]  sa kanila. Tapos, ang isa\n",
            "[01:48:49.740 --> 01:48:51.700]  pang iniisip ko, halimbawa, yung mga\n",
            "[01:48:51.700 --> 01:48:53.060]  hindi na daw kasi,\n",
            "[01:48:53.840 --> 01:48:55.700]  hindi na maningil sila? Baka maningil\n",
            "[01:48:55.700 --> 01:48:57.820]  sila? O, di kong maningil\n",
            "[01:48:57.820 --> 01:48:59.640]  sila. O, kaya, sasabihin natin\n",
            "[01:48:59.640 --> 01:49:01.440]  for research purposes. So, kailangan\n",
            "[01:49:01.440 --> 01:49:03.140]  i-approach natin yung ano,\n",
            "[01:49:03.420 --> 01:49:05.620]  hindi basta kinuha natin yung data nila.\n",
            "[01:49:06.340 --> 01:49:07.420]  Tapos, yung halimbawa,\n",
            "[01:49:07.560 --> 01:49:09.020]  hindi na daw ABS-CBN.\n",
            "[01:49:09.240 --> 01:49:11.000]  Di ba, pagka nagbiyahi ka,\n",
            "[01:49:11.300 --> 01:49:13.500]  iba yung local, eh. Local language.\n",
            "[01:49:13.620 --> 01:49:14.680]  Meron siyang video.\n",
            "[01:49:15.460 --> 01:49:17.560]  Meron siyang script. Kasi may script\n",
            "[01:49:17.560 --> 01:49:19.020]  naman yun. Binabasa yun, eh.\n",
            "[01:49:19.220 --> 01:49:21.400]  Oo. Transcript sa YouTube.\n",
            "[01:49:21.620 --> 01:49:23.740]  E di, localize ang language.\n",
            "[01:49:23.900 --> 01:49:25.280]  Alam mo, yun yung isang dream ko.\n",
            "[01:49:25.540 --> 01:49:27.640]  Pwede ba natin i-project yun? Isama natin\n",
            "[01:49:27.640 --> 01:49:27.940]  dyan?\n",
            "[01:49:29.480 --> 01:49:31.580]  Actually, we can build on top of yung mga\n",
            "[01:49:31.580 --> 01:49:33.440]  DOST projects na related sa\n",
            "[01:49:33.440 --> 01:49:35.820]  language. Meron\n",
            "[01:49:35.820 --> 01:49:37.380]  kami, meron di\n",
            "[01:49:37.380 --> 01:49:39.460]  ko lang ma-enumerate\n",
            "[01:49:39.460 --> 01:49:40.940]  lahat ng mga sources namin.\n",
            "[01:49:41.140 --> 01:49:43.200]  Yung nabanggit ko kanina, those are some of the sources.\n",
            "[01:49:43.380 --> 01:49:45.220]  Pero meron pa pong iba silang\n",
            "[01:49:45.220 --> 01:49:46.940]  pinagkuhanan yung\n",
            "[01:49:46.940 --> 01:49:48.240]  sa itanong. Pero,\n",
            "[01:49:48.460 --> 01:49:50.820]  i-approach natin yung ano,\n",
            "[01:49:51.080 --> 01:49:52.080]  para win-win.\n",
            "[01:49:53.420 --> 01:49:55.440]  Meron silang corpus in the end.\n",
            "[01:49:55.680 --> 01:49:57.340]  O kaya, halimbawa, ABS-CBN\n",
            "[01:49:57.340 --> 01:49:59.420]  corpus, o kung ano man yun, di ba?\n",
            "[01:49:59.960 --> 01:50:00.940]  O yung mga\n",
            "[01:50:00.940 --> 01:50:03.340]  official gazette. Pero, di-share nila sa atin.\n",
            "[01:50:03.440 --> 01:50:05.120]  Parang ganun. O, hindi. May\n",
            "[01:50:05.120 --> 01:50:07.320]  agreement na, o sige, for research\n",
            "[01:50:07.320 --> 01:50:09.060]  purposes, o kung ano ba yung\n",
            "[01:50:09.060 --> 01:50:10.900]  mga IP levels.\n",
            "[01:50:12.680 --> 01:50:13.240]  Di ba?\n",
            "[01:50:13.740 --> 01:50:15.100]  Actually, yun po yung ano eh,\n",
            "[01:50:15.180 --> 01:50:17.380]  hinihingi sa amin, kung baga\n",
            "[01:50:17.380 --> 01:50:18.980]  interested ang AI Singapore,\n",
            "[01:50:19.260 --> 01:50:21.040]  yung project nila,\n",
            "[01:50:21.120 --> 01:50:22.760]  William, yung pumunta po dito.\n",
            "[01:50:22.960 --> 01:50:24.360]  Kung may project kami,\n",
            "[01:50:24.900 --> 01:50:27.160]  may project kami, ang kinuha\n",
            "[01:50:27.160 --> 01:50:29.060]  namin, official gazette,\n",
            "[01:50:29.460 --> 01:50:30.940]  kasi yun, ano yun eh, yung\n",
            "[01:50:30.940 --> 01:50:33.140]  Office of the President.\n",
            "[01:50:33.940 --> 01:50:35.180]  So, kinlassify\n",
            "[01:50:35.180 --> 01:50:37.280]  namin, informal form.\n",
            "[01:50:37.320 --> 01:50:39.080]  10,000 words yun.\n",
            "[01:50:39.180 --> 01:50:41.120]  Ongoing yung, ano, tatlo yung\n",
            "[01:50:41.120 --> 01:50:42.860]  ginagawa namin.\n",
            "[01:50:43.040 --> 01:50:44.660]  Named entity recognition.\n",
            "[01:50:46.140 --> 01:50:47.160]  Semantic role\n",
            "[01:50:47.160 --> 01:50:48.340]  labeling kami ngayon.\n",
            "[01:50:49.220 --> 01:50:50.380]  Tapos, isa,\n",
            "[01:50:50.980 --> 01:50:52.440]  co-reference resolution.\n",
            "[01:50:53.140 --> 01:50:55.220]  Tapos, ipapasa namin yun sa kanila.\n",
            "[01:50:55.760 --> 01:50:57.080]  I-train nila\n",
            "[01:50:57.080 --> 01:50:59.560]  sa kung anumang model yung\n",
            "[01:50:59.560 --> 01:51:01.060]  ano. Tapos, publication.\n",
            "[01:51:01.600 --> 01:51:03.120]  Joint publication.\n",
            "[01:51:04.420 --> 01:51:05.420]  Ang mga kasama ko\n",
            "[01:51:05.420 --> 01:51:07.040]  dito, yung taga-Filipino,\n",
            "[01:51:07.320 --> 01:51:09.040]  department ng iba't-ibang schools.\n",
            "[01:51:10.420 --> 01:51:12.560]  Sila yung nag-label.\n",
            "[01:51:14.000 --> 01:51:15.780]  Saka, ano, hindi lang siguro po\n",
            "[01:51:15.780 --> 01:51:17.060]  Pilipino, pati other\n",
            "[01:51:17.060 --> 01:51:18.460]  languages.\n",
            "[01:51:18.900 --> 01:51:20.540]  Ah, yun ang dream ko.\n",
            "[01:51:20.800 --> 01:51:22.720]  Yun ang dream ko talaga. Kasi sa\n",
            "[01:51:22.720 --> 01:51:24.520]  Ethnologue, 175\n",
            "[01:51:24.520 --> 01:51:26.500]  Philippine languages.\n",
            "[01:51:27.340 --> 01:51:28.700]  Wala pa doon yung mga\n",
            "[01:51:28.700 --> 01:51:30.820]  dialect.\n",
            "[01:51:31.200 --> 01:51:32.020]  Hindi kasama to.\n",
            "[01:51:32.040 --> 01:51:35.060]  Ang dami. Kaya hindi\n",
            "[01:51:35.060 --> 01:51:36.460]  nag-work yung ano eh.\n",
            "[01:51:37.320 --> 01:51:38.800]  Ang mother tongue.\n",
            "[01:51:39.180 --> 01:51:40.940]  Kasi hindi naman mother tongue talaga\n",
            "[01:51:40.940 --> 01:51:42.520]  yung ginagamit. Kung hindi yung\n",
            "[01:51:42.520 --> 01:51:44.680]  language sa bayan,\n",
            "[01:51:44.980 --> 01:51:45.540]  sa city.\n",
            "[01:51:47.380 --> 01:51:49.180]  Eh, doon sa kasulok-sulokan\n",
            "[01:51:49.180 --> 01:51:50.040]  ng island.\n",
            "[01:51:51.300 --> 01:51:53.100]  Hindi naman pareho doon sa city.\n",
            "[01:51:53.920 --> 01:51:55.340]  Kaya yung materials,\n",
            "[01:51:55.560 --> 01:51:56.440]  hindi rin siya local.\n",
            "[01:51:58.300 --> 01:51:59.240]  Hindi rin siya\n",
            "[01:51:59.240 --> 01:52:00.240]  mother tongue eh.\n",
            "[01:52:01.220 --> 01:52:02.440]  Pwede natin yung\n",
            "[01:52:02.440 --> 01:52:05.040]  sa language naman.\n",
            "[01:52:05.540 --> 01:52:06.860]  Yan po, yun yung\n",
            "[01:52:06.860 --> 01:52:08.780]  pwede nating mga ano dito\n",
            "[01:52:08.780 --> 01:52:10.260]  under akabay.\n",
            "[01:52:10.820 --> 01:52:11.920]  Sir Andre?\n",
            "[01:52:14.120 --> 01:52:16.040]  At saka scripting, sir.\n",
            "[01:52:16.160 --> 01:52:17.560]  Mga scripting languages.\n",
            "[01:52:17.940 --> 01:52:19.180]  Ang dami pa natin nun.\n",
            "[01:52:20.280 --> 01:52:21.540]  Mostly, ano lang eh.\n",
            "[01:52:21.680 --> 01:52:22.380]  Ba, ano yan?\n",
            "[01:52:24.540 --> 01:52:26.420]  Ba, ba ang umpisa.\n",
            "[01:52:28.040 --> 01:52:29.460]  Yung scripting,\n",
            "[01:52:31.460 --> 01:52:32.560]  ang dami pala natin\n",
            "[01:52:32.560 --> 01:52:34.500]  mga indigenous na scripting eh.\n",
            "[01:52:34.920 --> 01:52:35.880]  Ah, talaga po ba?\n",
            "[01:52:35.880 --> 01:52:36.080]  Oo.\n",
            "[01:52:36.860 --> 01:52:37.580]  Kasi tayo Latin,\n",
            "[01:52:37.700 --> 01:52:39.000]  A, B, C, D tayo, diba?\n",
            "[01:52:39.220 --> 01:52:39.240]  Oo.\n",
            "[01:52:39.520 --> 01:52:40.660]  Mga alibata, ganun?\n",
            "[01:52:40.820 --> 01:52:42.000]  O yun, alibata,\n",
            "[01:52:42.180 --> 01:52:42.800]  A pala.\n",
            "[01:52:43.120 --> 01:52:43.820]  Hindi pala B.\n",
            "[01:52:44.800 --> 01:52:45.760]  Alibata, ano,\n",
            "[01:52:46.340 --> 01:52:47.860]  yun ang karamihan ginagamit.\n",
            "[01:52:47.980 --> 01:52:48.760]  Pero marami tayong\n",
            "[01:52:48.760 --> 01:52:50.040]  ibang scripting.\n",
            "[01:52:50.300 --> 01:52:50.860]  Kasi may isang\n",
            "[01:52:50.860 --> 01:52:52.020]  master and student ako\n",
            "[01:52:52.020 --> 01:52:53.080]  yun ang ginawa eh.\n",
            "[01:52:54.340 --> 01:52:54.800]  Yun naman.\n",
            "[01:52:55.160 --> 01:52:56.740]  Tatlo ang consider niya.\n",
            "[01:52:56.860 --> 01:52:57.500]  Oo, tatlo.\n",
            "[01:52:59.980 --> 01:53:00.720]  Sige po.\n",
            "[01:53:00.940 --> 01:53:02.000]  Iyan yung maganda rin po yan\n",
            "[01:53:02.000 --> 01:53:03.240]  para ma-preserve yung ano.\n",
            "[01:53:03.740 --> 01:53:03.940]  Oo.\n",
            "[01:53:04.280 --> 01:53:05.500]  Yun talaga dream ko.\n",
            "[01:53:05.500 --> 01:53:05.900]  Oo.\n",
            "[01:53:06.860 --> 01:53:09.780]  Go on, sir.\n",
            "[01:53:09.780 --> 01:53:10.960]  Saan pwede pumasok yun?\n",
            "[01:53:11.040 --> 01:53:13.040]  Saan pwede pumasok dyan sa ano mo?\n",
            "[01:53:15.720 --> 01:53:17.720]  Pwede po isang use case din po yun\n",
            "[01:53:17.720 --> 01:53:19.220]  doon sa ano, sa Akabay.\n",
            "[01:53:19.340 --> 01:53:19.820]  Akabay.\n",
            "[01:53:20.080 --> 01:53:20.420]  Sige.\n",
            "[01:53:21.480 --> 01:53:22.280]  Sir Andre?\n",
            "[01:53:23.560 --> 01:53:24.060]  Hello po.\n",
            "[01:53:24.500 --> 01:53:25.640]  Pwede na rin po bang magpano\n",
            "[01:53:25.640 --> 01:53:28.200]  regarding po kung may current seminars po ba kayo\n",
            "[01:53:28.200 --> 01:53:30.200]  or trainings na pwede pong ma-applyan po?\n",
            "[01:53:31.760 --> 01:53:32.640]  Regarding AI po.\n",
            "[01:53:34.240 --> 01:53:35.440]  Seminars or training\n",
            "[01:53:35.440 --> 01:53:35.740]  na\n",
            "[01:53:35.740 --> 01:53:36.500]  ah.\n",
            "[01:53:36.860 --> 01:53:38.520]  Na-provided po ng DOSD po.\n",
            "[01:53:38.980 --> 01:53:40.020]  Paano ginagawa nyo?\n",
            "[01:53:40.100 --> 01:53:41.580]  Napunta kayo sa locality?\n",
            "[01:53:41.780 --> 01:53:42.280]  Ganun ba yun?\n",
            "[01:53:43.380 --> 01:53:44.480]  Pwede po yung ganun.\n",
            "[01:53:45.060 --> 01:53:45.800]  Pumapunta kami.\n",
            "[01:53:45.940 --> 01:53:46.640]  Pwede rin virtual.\n",
            "[01:53:46.860 --> 01:53:47.580]  Pero mostly po,\n",
            "[01:53:47.660 --> 01:53:48.600]  mas effective kasi\n",
            "[01:53:48.600 --> 01:53:49.280]  yung pupunta kami.\n",
            "[01:53:49.920 --> 01:53:51.820]  We need that doon\n",
            "[01:53:51.820 --> 01:53:52.960]  sa Bacolod.\n",
            "[01:53:53.680 --> 01:53:55.900]  We also have\n",
            "[01:53:55.900 --> 01:53:56.660]  mga virtual naman,\n",
            "[01:53:56.740 --> 01:53:57.960]  mga lecture series.\n",
            "[01:53:58.760 --> 01:53:59.820]  Karoon din kami\n",
            "[01:53:59.820 --> 01:54:00.780]  ng ano dyan sa\n",
            "[01:54:00.780 --> 01:54:01.420]  NIP,\n",
            "[01:54:01.600 --> 01:54:02.560]  yung recently lang\n",
            "[01:54:02.560 --> 01:54:03.680]  sa quantum computing\n",
            "[01:54:03.680 --> 01:54:04.360]  naman yun.\n",
            "[01:54:05.020 --> 01:54:05.720]  Pero sa\n",
            "[01:54:05.720 --> 01:54:06.720]  AI po,\n",
            "[01:54:06.860 --> 01:54:08.140]  yung sa Akabay naman po,\n",
            "[01:54:08.140 --> 01:54:09.040]  more on AI,\n",
            "[01:54:09.980 --> 01:54:11.040]  pwede po tayo mag-ano.\n",
            "[01:54:11.700 --> 01:54:12.560]  Like for example,\n",
            "[01:54:13.620 --> 01:54:17.440]  sabihin nyo lang po kung ano yung\n",
            "[01:54:17.440 --> 01:54:20.040]  pwede natin i-under siya ng Akabay\n",
            "[01:54:20.040 --> 01:54:22.040]  kasi part naman po ng deliverables namin\n",
            "[01:54:22.040 --> 01:54:22.560]  yung training.\n",
            "[01:54:23.300 --> 01:54:23.600]  Like,\n",
            "[01:54:24.120 --> 01:54:25.360]  ngayon may kausap kami,\n",
            "[01:54:25.560 --> 01:54:26.000]  DAP,\n",
            "[01:54:26.820 --> 01:54:28.500]  Development Academy of the Philippines.\n",
            "[01:54:28.620 --> 01:54:29.580]  May mga ano po kami,\n",
            "[01:54:29.700 --> 01:54:31.340]  yung upcoming training in the pipeline.\n",
            "[01:54:31.460 --> 01:54:32.020]  Yung sa DAP,\n",
            "[01:54:32.140 --> 01:54:33.440]  next month po.\n",
            "[01:54:34.380 --> 01:54:34.900]  Tapos,\n",
            "[01:54:34.900 --> 01:54:36.520]  may series ng mga,\n",
            "[01:54:36.860 --> 01:54:37.660]  training po kami sa\n",
            "[01:54:37.660 --> 01:54:39.420]  Development Academy of the Philippines.\n",
            "[01:54:40.500 --> 01:54:41.020]  Ano yun?\n",
            "[01:54:41.140 --> 01:54:42.700]  Parang AI for managers?\n",
            "[01:54:43.000 --> 01:54:43.560]  Parang mga gano'n?\n",
            "[01:54:43.560 --> 01:54:43.800]  Opo,\n",
            "[01:54:43.940 --> 01:54:44.160]  opo,\n",
            "[01:54:44.220 --> 01:54:44.380]  tama.\n",
            "[01:54:44.520 --> 01:54:46.180]  AI for project managers po.\n",
            "[01:54:46.920 --> 01:54:47.260]  Yung ano,\n",
            "[01:54:47.380 --> 01:54:48.560]  kaya yung sinabi,\n",
            "[01:54:48.620 --> 01:54:49.700]  yung tanong niya po kanina,\n",
            "[01:54:49.860 --> 01:54:51.080]  kung meron kaming catalog,\n",
            "[01:54:51.220 --> 01:54:52.700]  na-customize po usually.\n",
            "[01:54:53.340 --> 01:54:53.560]  Like,\n",
            "[01:54:53.600 --> 01:54:54.420]  kung ano yung need\n",
            "[01:54:54.420 --> 01:54:55.400]  ng organization.\n",
            "[01:54:56.460 --> 01:54:57.420]  Tungkol ba saan?\n",
            "[01:54:58.420 --> 01:55:00.220]  Mga technical ba itong a-attend?\n",
            "[01:55:00.320 --> 01:55:01.580]  Mga coders ba ito?\n",
            "[01:55:02.080 --> 01:55:02.460]  Kasi kung,\n",
            "[01:55:02.720 --> 01:55:03.640]  doon po namin\n",
            "[01:55:03.640 --> 01:55:04.900]  i-customize yung aming\n",
            "[01:55:04.900 --> 01:55:05.720]  training plan.\n",
            "[01:55:05.900 --> 01:55:06.060]  Kung,\n",
            "[01:55:06.060 --> 01:55:06.740]  kung marunang,\n",
            "[01:55:06.740 --> 01:55:07.780]  marunang ba sila mag-code\n",
            "[01:55:07.780 --> 01:55:08.420]  o kung hindi.\n",
            "[01:55:08.600 --> 01:55:09.240]  Kasi kung hindi,\n",
            "[01:55:09.680 --> 01:55:10.600]  mga no-code po.\n",
            "[01:55:10.720 --> 01:55:11.220]  O kaya mga,\n",
            "[01:55:11.360 --> 01:55:12.100]  tuturoan namin sila\n",
            "[01:55:12.100 --> 01:55:13.060]  kung paano gumamit\n",
            "[01:55:13.060 --> 01:55:14.940]  ng mga AI tools,\n",
            "[01:55:15.060 --> 01:55:15.680]  mga gano'n.\n",
            "[01:55:15.800 --> 01:55:16.200]  Pero kung,\n",
            "[01:55:16.320 --> 01:55:17.180]  saka mga programmer,\n",
            "[01:55:17.360 --> 01:55:17.700]  yun po.\n",
            "[01:55:18.140 --> 01:55:19.200]  Meron din kaming patraining\n",
            "[01:55:19.200 --> 01:55:20.220]  before naman\n",
            "[01:55:20.220 --> 01:55:21.080]  sa ano naman,\n",
            "[01:55:21.580 --> 01:55:22.700]  more on,\n",
            "[01:55:23.360 --> 01:55:24.640]  tawag doon,\n",
            "[01:55:25.060 --> 01:55:25.840]  remote sensing\n",
            "[01:55:25.840 --> 01:55:28.060]  and introduction to AI.\n",
            "[01:55:28.240 --> 01:55:29.220]  Yung sa isang project po,\n",
            "[01:55:29.260 --> 01:55:29.860]  yung sa DATAS\n",
            "[01:55:29.860 --> 01:55:30.520]  and SARWISE.\n",
            "[01:55:30.820 --> 01:55:32.200]  Nag-co-conduct din po\n",
            "[01:55:32.200 --> 01:55:34.660]  ng gano'ng mga patraining.\n",
            "[01:55:34.860 --> 01:55:34.980]  So,\n",
            "[01:55:35.100 --> 01:55:35.900]  usually po,\n",
            "[01:55:35.900 --> 01:55:37.660]  yung aming training\n",
            "[01:55:37.660 --> 01:55:38.880]  naka-ano po\n",
            "[01:55:38.880 --> 01:55:41.180]  sa project talaga namin.\n",
            "[01:55:43.320 --> 01:55:44.780]  Part po siya ng project.\n",
            "[01:55:44.960 --> 01:55:45.700]  Bali, gano'n po.\n",
            "[01:55:46.120 --> 01:55:46.580]  Kung sakali,\n",
            "[01:55:46.640 --> 01:55:47.900]  halimbawa may needs kayo.\n",
            "[01:55:48.740 --> 01:55:50.500]  Like yung tanong ni Sir Andre,\n",
            "[01:55:50.620 --> 01:55:51.660]  ano po ba yung ano?\n",
            "[01:55:52.340 --> 01:55:53.000]  Katulad noon,\n",
            "[01:55:53.180 --> 01:55:54.800]  nagpunta kami sa UPLB,\n",
            "[01:55:55.400 --> 01:55:56.460]  sa IPB,\n",
            "[01:55:56.600 --> 01:55:57.580]  nag-train din kami.\n",
            "[01:55:58.000 --> 01:55:59.480]  Parang one day lang yun.\n",
            "[01:55:59.960 --> 01:56:01.200]  Pwede kasing one day lang\n",
            "[01:56:01.200 --> 01:56:02.280]  o pwede talagang\n",
            "[01:56:02.280 --> 01:56:03.560]  mag-design kami\n",
            "[01:56:03.560 --> 01:56:04.360]  for one week\n",
            "[01:56:04.360 --> 01:56:05.200]  and then at the end\n",
            "[01:56:05.200 --> 01:56:05.880]  of the training,\n",
            "[01:56:05.900 --> 01:56:07.100]  meron kayong dapat\n",
            "[01:56:07.100 --> 01:56:07.900]  output\n",
            "[01:56:07.900 --> 01:56:09.360]  o may artifacts\n",
            "[01:56:09.360 --> 01:56:10.340]  na mapoproduce,\n",
            "[01:56:10.400 --> 01:56:11.680]  may app kayo na-develop,\n",
            "[01:56:12.200 --> 01:56:13.220]  yung mga gano'n po.\n",
            "[01:56:13.800 --> 01:56:14.740]  Ano yung training nyo\n",
            "[01:56:14.740 --> 01:56:15.640]  sa IPB?\n",
            "[01:56:17.000 --> 01:56:18.000]  Naalala ko kasi\n",
            "[01:56:18.000 --> 01:56:19.960]  parang at apat na topics yun.\n",
            "[01:56:20.040 --> 01:56:21.180]  I'm one of the speakers.\n",
            "[01:56:21.320 --> 01:56:22.780]  Ako parang introduction to AI\n",
            "[01:56:22.780 --> 01:56:23.980]  lang po yung train ko\n",
            "[01:56:23.980 --> 01:56:25.620]  noong time na yun.\n",
            "[01:56:25.740 --> 01:56:26.740]  That was a long time ago.\n",
            "[01:56:26.840 --> 01:56:28.000]  Mga four years ago pa yun\n",
            "[01:56:28.000 --> 01:56:29.660]  before the pandemic pa po yata.\n",
            "[01:56:30.400 --> 01:56:32.020]  Mag-request kaya tayo ulit?\n",
            "[01:56:32.160 --> 01:56:34.220]  Kasi ongoing yung aming\n",
            "[01:56:34.220 --> 01:56:35.880]  mga possible\n",
            "[01:56:35.900 --> 01:56:37.900]  collaboration with IPB,\n",
            "[01:56:38.160 --> 01:56:40.760]  with College of Forestry.\n",
            "[01:56:42.320 --> 01:56:43.700]  Pwede po natin gawin ganito.\n",
            "[01:56:44.020 --> 01:56:45.100]  Gawa tayo ng program\n",
            "[01:56:45.100 --> 01:56:46.000]  tapos under natin\n",
            "[01:56:46.000 --> 01:56:46.560]  ng Akabay\n",
            "[01:56:46.560 --> 01:56:49.000]  tapos I'll assemble the team\n",
            "[01:56:49.000 --> 01:56:50.340]  i-plan po natin yan\n",
            "[01:56:50.340 --> 01:56:51.820]  tapos we can go there\n",
            "[01:56:51.820 --> 01:56:54.020]  tapos you can invite\n",
            "[01:56:54.020 --> 01:56:54.680]  parang ano\n",
            "[01:56:54.680 --> 01:56:55.480]  yung gano'n\n",
            "[01:56:55.480 --> 01:56:56.600]  pwede natin\n",
            "[01:56:56.600 --> 01:56:57.600]  i-ano yan\n",
            "[01:56:57.600 --> 01:57:00.520]  parang isang pangalakasang training\n",
            "[01:57:00.520 --> 01:57:01.520]  tapos ilagay po namin\n",
            "[01:57:01.520 --> 01:57:02.360]  sa ano namin.\n",
            "[01:57:02.960 --> 01:57:04.280]  Kasi part naman po\n",
            "[01:57:04.280 --> 01:57:05.420]  ng deliverables namin\n",
            "[01:57:05.420 --> 01:57:05.760]  yung capacity\n",
            "[01:57:05.900 --> 01:57:06.920]  building eh.\n",
            "[01:57:07.440 --> 01:57:08.800]  So that will be\n",
            "[01:57:08.800 --> 01:57:10.500]  something na pwede po\n",
            "[01:57:10.500 --> 01:57:11.520]  namin gawing activity.\n",
            "[01:57:14.820 --> 01:57:15.720]  Tapos ano po\n",
            "[01:57:15.720 --> 01:57:17.320]  katulad nung ginawa namin sa\n",
            "[01:57:17.320 --> 01:57:19.060]  John, naalala namin\n",
            "[01:57:19.060 --> 01:57:20.740]  ginawa natin sa SEAT?\n",
            "[01:57:23.280 --> 01:57:24.600]  Yes po yung ano sir\n",
            "[01:57:24.600 --> 01:57:27.180]  may ginawa po kami sa SEAT\n",
            "[01:57:27.180 --> 01:57:30.160]  exhibit na mga projects\n",
            "[01:57:30.160 --> 01:57:31.700]  tapos parang gano'n po\n",
            "[01:57:31.700 --> 01:57:33.240]  sa SEAT po nagawa namin eh\n",
            "[01:57:33.240 --> 01:57:35.520]  tapos may mga interns din.\n",
            "[01:57:35.900 --> 01:57:36.520]  Doon din yata\n",
            "[01:57:36.520 --> 01:57:37.220]  nakuha ni John\n",
            "[01:57:37.220 --> 01:57:38.340]  yung mga interns niya.\n",
            "[01:57:38.800 --> 01:57:39.000]  Bale,\n",
            "[01:57:39.120 --> 01:57:40.560]  nagpunta po kami doon\n",
            "[01:57:40.560 --> 01:57:41.420]  yung CSD\n",
            "[01:57:41.420 --> 01:57:43.280]  tapos pinresent po namin\n",
            "[01:57:43.280 --> 01:57:44.540]  yung mga projects namin\n",
            "[01:57:44.540 --> 01:57:45.680]  tapos meron pong\n",
            "[01:57:45.680 --> 01:57:47.000]  parang mga booth\n",
            "[01:57:47.000 --> 01:57:49.060]  maliit na booth lang naman\n",
            "[01:57:49.060 --> 01:57:49.780]  doon sa\n",
            "[01:57:49.780 --> 01:57:50.760]  anong building ba yung\n",
            "[01:57:50.760 --> 01:57:51.420]  John?\n",
            "[01:57:51.880 --> 01:57:52.320]  Parang gano'n\n",
            "[01:57:52.320 --> 01:57:53.600]  for one day event\n",
            "[01:57:53.600 --> 01:57:54.100]  yan tapos.\n",
            "[01:57:54.120 --> 01:57:54.920]  I-e-building po.\n",
            "[01:57:55.660 --> 01:57:55.980]  Yun.\n",
            "[01:57:56.120 --> 01:57:57.080]  I-e-building po sir.\n",
            "[01:57:57.700 --> 01:57:58.760]  Nag gano'n po kami.\n",
            "[01:57:59.020 --> 01:58:00.680]  We can do that sa ICS\n",
            "[01:58:00.680 --> 01:58:01.300]  o sa ano.\n",
            "[01:58:01.300 --> 01:58:01.820]  Pwede.\n",
            "[01:58:02.280 --> 01:58:02.340]  Oo.\n",
            "[01:58:03.460 --> 01:58:05.080]  Tapos i-invite natin\n",
            "[01:58:05.080 --> 01:58:05.860]  yung ibang ano.\n",
            "[01:58:05.900 --> 01:58:06.840]  Kasi tatlo na yung\n",
            "[01:58:06.840 --> 01:58:07.600]  kausap namin.\n",
            "[01:58:07.920 --> 01:58:08.360]  IPB,\n",
            "[01:58:08.520 --> 01:58:09.640]  College of Forestry\n",
            "[01:58:09.640 --> 01:58:10.860]  and Natural Resources\n",
            "[01:58:10.860 --> 01:58:12.940]  tsaka College of Public Affairs.\n",
            "[01:58:13.420 --> 01:58:14.060]  Tatlo na yun.\n",
            "[01:58:14.140 --> 01:58:14.820]  College of Forestry\n",
            "[01:58:14.820 --> 01:58:15.500]  doon sa ano\n",
            "[01:58:15.500 --> 01:58:16.520]  with AI na\n",
            "[01:58:16.520 --> 01:58:17.540]  use case namin.\n",
            "[01:58:19.280 --> 01:58:19.760]  Ayan.\n",
            "[01:58:19.840 --> 01:58:20.580]  Sir John, sige.\n",
            "[01:58:22.040 --> 01:58:23.340]  Share ko lang po na\n",
            "[01:58:23.340 --> 01:58:24.060]  yung ano po.\n",
            "[01:58:24.840 --> 01:58:25.860]  I think okay din po siya\n",
            "[01:58:25.860 --> 01:58:27.000]  kasi most of the students\n",
            "[01:58:27.000 --> 01:58:27.780]  po sa LB\n",
            "[01:58:27.780 --> 01:58:28.920]  hindi po kilala yung ASTI\n",
            "[01:58:28.920 --> 01:58:30.000]  like nung time ko po\n",
            "[01:58:30.000 --> 01:58:31.340]  hindi po kilala yung ASTI.\n",
            "[01:58:32.000 --> 01:58:32.800]  And yung mga\n",
            "[01:58:32.800 --> 01:58:34.640]  yung isang student po namin\n",
            "[01:58:34.640 --> 01:58:35.880]  na naging intern ko\n",
            "[01:58:35.900 --> 01:58:37.320]  ayaw nabanggit ko po\n",
            "[01:58:37.320 --> 01:58:38.200]  kanina nakapag\n",
            "[01:58:38.200 --> 01:58:39.400]  ginawa niya po\n",
            "[01:58:39.400 --> 01:58:40.080]  yung thesis niya\n",
            "[01:58:40.080 --> 01:58:40.740]  with us.\n",
            "[01:58:41.440 --> 01:58:42.480]  Tukuhan niya po yung topic\n",
            "[01:58:42.480 --> 01:58:43.980]  from my presentation po\n",
            "[01:58:43.980 --> 01:58:45.120]  and yung ginawa niya\n",
            "[01:58:45.120 --> 01:58:45.660]  yung thesis\n",
            "[01:58:45.660 --> 01:58:47.560]  and eventually\n",
            "[01:58:47.560 --> 01:58:48.280]  he'll be\n",
            "[01:58:48.280 --> 01:58:50.040]  working with the project po\n",
            "[01:58:50.040 --> 01:58:50.860]  so punting niya po\n",
            "[01:58:50.860 --> 01:58:52.200]  yung research po\n",
            "[01:58:52.200 --> 01:58:53.100]  na ginawa niya po.\n",
            "[01:58:53.920 --> 01:58:54.520]  Ay John,\n",
            "[01:58:55.500 --> 01:58:56.220]  iilagay mo yan\n",
            "[01:58:56.220 --> 01:58:57.800]  sa terminal report natin ha.\n",
            "[01:58:57.900 --> 01:58:59.140]  Impact yan ng project.\n",
            "[01:58:59.660 --> 01:59:00.140]  Yes po.\n",
            "[01:59:00.320 --> 01:59:00.760]  Yes po.\n",
            "[01:59:00.760 --> 01:59:01.180]  Yes po.\n",
            "[01:59:01.480 --> 01:59:01.600]  Sige.\n",
            "[01:59:02.160 --> 01:59:03.340]  1 student.\n",
            "[01:59:03.700 --> 01:59:04.000]  Diba?\n",
            "[01:59:04.260 --> 01:59:05.880]  Kasi students binibilang.\n",
            "[01:59:05.900 --> 01:59:06.560]  Ano yung topic?\n",
            "[01:59:06.560 --> 01:59:06.580]  Oo.\n",
            "[01:59:07.320 --> 01:59:08.920]  Kailan gumraduate?\n",
            "[01:59:08.920 --> 01:59:08.940]  Kailan gumraduate?\n",
            "[01:59:08.940 --> 01:59:08.980]  Kailan gumraduate?\n",
            "[01:59:08.980 --> 01:59:09.760]  Ano yung report siya?\n",
            "[01:59:09.920 --> 01:59:10.020]  Oo.\n",
            "[01:59:10.780 --> 01:59:12.220]  Meron pa palang isa.\n",
            "[01:59:12.460 --> 01:59:12.700]  Ano?\n",
            "[01:59:12.980 --> 01:59:13.580]  Biotech.\n",
            "[01:59:14.320 --> 01:59:15.220]  Kakatatanggap ko lang\n",
            "[01:59:15.220 --> 01:59:15.820]  nung email.\n",
            "[01:59:16.020 --> 01:59:16.620]  Biotech.\n",
            "[01:59:16.840 --> 01:59:17.900]  Pinapagawa daw sila\n",
            "[01:59:17.900 --> 01:59:19.000]  ng AI roadmap.\n",
            "[01:59:20.580 --> 01:59:21.780]  Ang tindi nito\n",
            "[01:59:21.780 --> 01:59:23.000]  kasi ang daming data.\n",
            "[01:59:23.740 --> 01:59:24.920]  Ang tagay na niyang\n",
            "[01:59:24.920 --> 01:59:25.720]  biotech eh.\n",
            "[01:59:26.500 --> 01:59:26.860]  Yan ma,\n",
            "[01:59:26.900 --> 01:59:27.920]  mas maganda kung maka\n",
            "[01:59:27.920 --> 01:59:28.160]  ano,\n",
            "[01:59:28.320 --> 01:59:29.180]  pwedeng something\n",
            "[01:59:29.180 --> 01:59:29.740]  that ano,\n",
            "[01:59:29.940 --> 01:59:30.480]  pwede na\n",
            "[01:59:30.480 --> 01:59:31.300]  i-kula,\n",
            "[01:59:31.840 --> 01:59:32.920]  i-ano nyo yung mga\n",
            "[01:59:32.920 --> 01:59:33.360]  ano,\n",
            "[01:59:33.520 --> 01:59:35.240]  parang isahan na lang po\n",
            "[01:59:35.240 --> 01:59:35.820]  ay pe-present\n",
            "[01:59:35.820 --> 01:59:36.520]  namin yung\n",
            "[01:59:36.520 --> 01:59:37.500]  Naira\n",
            "[01:59:37.500 --> 01:59:38.220]  doon.\n",
            "[01:59:38.400 --> 01:59:39.400]  Tapos may konting\n",
            "[01:59:39.400 --> 01:59:40.880]  capacity building na rin.\n",
            "[01:59:41.400 --> 01:59:42.360]  We can have that\n",
            "[01:59:42.360 --> 01:59:42.660]  ano.\n",
            "[01:59:43.480 --> 01:59:44.780]  So, bali may isa tayo\n",
            "[01:59:44.780 --> 01:59:45.740]  for parang\n",
            "[01:59:45.740 --> 01:59:46.660]  administrators.\n",
            "[01:59:47.060 --> 01:59:47.480]  Ganun ba yun?\n",
            "[01:59:47.540 --> 01:59:48.280]  And faculty.\n",
            "[01:59:48.660 --> 01:59:49.000]  Tapos,\n",
            "[01:59:49.300 --> 01:59:50.440]  next for SEM\n",
            "[01:59:50.440 --> 01:59:51.820]  with students.\n",
            "[01:59:51.980 --> 01:59:52.480]  Students.\n",
            "[01:59:52.620 --> 01:59:53.120]  Pwede po.\n",
            "[01:59:53.320 --> 01:59:54.040]  O, pwede natin\n",
            "[01:59:54.040 --> 01:59:55.160]  i-ano ganun yung training.\n",
            "[01:59:55.180 --> 01:59:55.660]  Kasi ngayon,\n",
            "[01:59:55.780 --> 01:59:57.180]  wala nang mga students eh.\n",
            "[01:59:57.400 --> 01:59:58.520]  Pero pwede sigurong\n",
            "[01:59:58.520 --> 01:59:59.480]  dalawang level\n",
            "[01:59:59.480 --> 02:00:00.780]  or isa lang\n",
            "[02:00:00.780 --> 02:00:01.500]  puntahan.\n",
            "[02:00:01.640 --> 02:00:02.560]  Isang puntahan.\n",
            "[02:00:02.640 --> 02:00:03.340]  Isang puntahan.\n",
            "[02:00:03.340 --> 02:00:04.160]  Sa faculty.\n",
            "[02:00:05.100 --> 02:00:05.800]  Sa hapo.\n",
            "[02:00:05.820 --> 02:00:07.160]  Puntok sa students.\n",
            "[02:00:07.360 --> 02:00:07.480]  Oo.\n",
            "[02:00:07.740 --> 02:00:09.140]  Pwede namin i-ano,\n",
            "[02:00:09.360 --> 02:00:10.640]  pwede kami mag-design\n",
            "[02:00:10.640 --> 02:00:11.860]  ng training plan.\n",
            "[02:00:12.440 --> 02:00:12.860]  Tapos,\n",
            "[02:00:12.980 --> 02:00:13.220]  siguro,\n",
            "[02:00:13.360 --> 02:00:14.200]  mayroong one day,\n",
            "[02:00:14.300 --> 02:00:14.560]  kunyari,\n",
            "[02:00:14.680 --> 02:00:15.500]  or two days,\n",
            "[02:00:15.880 --> 02:00:16.400]  siguro,\n",
            "[02:00:16.620 --> 02:00:17.440]  tapos the rest\n",
            "[02:00:17.440 --> 02:00:18.380]  would be virtual.\n",
            "[02:00:18.680 --> 02:00:18.960]  Ganun.\n",
            "[02:00:19.120 --> 02:00:19.940]  May mga ganun po\n",
            "[02:00:19.940 --> 02:00:21.000]  kaming class in training.\n",
            "[02:00:21.400 --> 02:00:22.400]  We conducted training\n",
            "[02:00:22.400 --> 02:00:23.700]  sa pag-asa din pala.\n",
            "[02:00:23.960 --> 02:00:24.960]  Naalala ko yun yun.\n",
            "[02:00:25.840 --> 02:00:26.080]  Kaya,\n",
            "[02:00:26.140 --> 02:00:26.780]  ang masyempre ko sa inyo,\n",
            "[02:00:26.860 --> 02:00:28.060]  customized po yung aming\n",
            "[02:00:28.060 --> 02:00:29.600]  training design.\n",
            "[02:00:29.980 --> 02:00:30.860]  Kung ano yung need\n",
            "[02:00:30.860 --> 02:00:31.620]  na pwede natin,\n",
            "[02:00:31.700 --> 02:00:31.900]  ano.\n",
            "[02:00:32.460 --> 02:00:33.460]  Since this is\n",
            "[02:00:33.460 --> 02:00:34.500]  part of the project,\n",
            "[02:00:34.500 --> 02:00:35.800]  we can have that po.\n",
            "[02:00:35.820 --> 02:00:37.140]  We can plan that.\n",
            "[02:00:37.720 --> 02:00:37.980]  Tapos,\n",
            "[02:00:38.060 --> 02:00:38.820]  gawin natin sa UPLB.\n",
            "[02:00:39.520 --> 02:00:39.720]  Ayun.\n",
            "[02:00:39.860 --> 02:00:40.680]  Check na yung aming\n",
            "[02:00:40.680 --> 02:00:41.660]  deliverables.\n",
            "[02:00:41.860 --> 02:00:42.480]  Anong project yan?\n",
            "[02:00:42.560 --> 02:00:43.320]  Under saan?\n",
            "[02:00:43.380 --> 02:00:43.820]  Naira?\n",
            "[02:00:44.080 --> 02:00:44.860]  Sa Naira po.\n",
            "[02:00:45.740 --> 02:00:46.900]  Yung train 600\n",
            "[02:00:46.900 --> 02:00:50.500]  students and professionals.\n",
            "[02:00:50.840 --> 02:00:51.120]  Doon po.\n",
            "[02:00:51.680 --> 02:00:53.100]  Sa mga work plan po\n",
            "[02:00:53.100 --> 02:00:53.720]  namin yun eh.\n",
            "[02:00:55.140 --> 02:00:55.660]  So, yun.\n",
            "[02:00:55.800 --> 02:00:56.180]  Pwede po.\n",
            "[02:00:56.280 --> 02:00:57.040]  Pwede siguro,\n",
            "[02:00:57.240 --> 02:00:58.520]  parang meron tayong\n",
            "[02:00:58.520 --> 02:00:58.820]  ano,\n",
            "[02:00:58.980 --> 02:01:00.320]  parang AI day\n",
            "[02:01:00.320 --> 02:01:01.220]  or something.\n",
            "[02:01:01.400 --> 02:01:01.580]  Oo.\n",
            "[02:01:01.760 --> 02:01:02.980]  Parang AI festival.\n",
            "[02:01:03.360 --> 02:01:03.560]  O ganun.\n",
            "[02:01:03.580 --> 02:01:04.560]  AI festival.\n",
            "[02:01:04.560 --> 02:01:05.060]  Tapos,\n",
            "[02:01:05.140 --> 02:01:05.760]  doon natin\n",
            "[02:01:05.760 --> 02:01:07.200]  papupuntahin yung\n",
            "[02:01:07.200 --> 02:01:07.800]  ASTI.\n",
            "[02:01:08.020 --> 02:01:08.280]  Tapos,\n",
            "[02:01:08.360 --> 02:01:08.920]  kung may mga\n",
            "[02:01:08.920 --> 02:01:10.300]  industry partners.\n",
            "[02:01:10.940 --> 02:01:11.460]  Or even,\n",
            "[02:01:11.540 --> 02:01:12.040]  we can have\n",
            "[02:01:12.040 --> 02:01:12.860]  hackathons.\n",
            "[02:01:13.060 --> 02:01:13.800]  Mga ganun.\n",
            "[02:01:14.980 --> 02:01:16.060]  Parang program siya.\n",
            "[02:01:17.640 --> 02:01:18.460]  Kayo lahat\n",
            "[02:01:18.460 --> 02:01:19.600]  ang gagastos niyan?\n",
            "[02:01:19.760 --> 02:01:20.260]  Ganun mo yan?\n",
            "[02:01:20.700 --> 02:01:21.440]  Sa ako po.\n",
            "[02:01:21.580 --> 02:01:22.940]  May budget naman po\n",
            "[02:01:22.940 --> 02:01:23.480]  sa ano eh.\n",
            "[02:01:23.540 --> 02:01:24.280]  May budget.\n",
            "[02:01:24.500 --> 02:01:25.540]  Ano yung sa amin?\n",
            "[02:01:26.760 --> 02:01:27.040]  Ah,\n",
            "[02:01:27.200 --> 02:01:27.640]  venue.\n",
            "[02:01:27.940 --> 02:01:28.520]  Saka yun.\n",
            "[02:01:28.800 --> 02:01:29.360]  Venue.\n",
            "[02:01:29.740 --> 02:01:30.460]  Binapayaran din\n",
            "[02:01:30.460 --> 02:01:31.440]  nata ang venue\n",
            "[02:01:31.440 --> 02:01:32.060]  sa...\n",
            "[02:01:32.060 --> 02:01:32.160]  Hahaha.\n",
            "[02:01:32.160 --> 02:01:32.260]  Hahaha.\n",
            "[02:01:32.260 --> 02:01:33.260]  Hahaha.\n",
            "[02:01:35.260 --> 02:01:36.260]  Ano ba?\n",
            "[02:01:36.260 --> 02:01:37.260]  Ah, hindi.\n",
            "[02:01:37.260 --> 02:01:38.260]  Parang...\n",
            "[02:01:38.260 --> 02:01:39.260]  Ano kaya?\n",
            "[02:01:39.260 --> 02:01:40.260]  Pwede po kayong ano,\n",
            "[02:01:40.260 --> 02:01:41.260]  kung ano po yung kaya niyang i-share.\n",
            "[02:01:41.260 --> 02:01:42.260]  Hahaha.\n",
            "[02:01:42.260 --> 02:01:43.260]  Okay.\n",
            "[02:01:43.260 --> 02:01:44.260]  Sige, sige.\n",
            "[02:01:44.260 --> 02:01:45.260]  Ang maganda yan,\n",
            "[02:01:45.260 --> 02:01:47.260]  parang may AI festival tayo.\n",
            "[02:01:47.260 --> 02:01:48.260]  Apo.\n",
            "[02:01:48.260 --> 02:01:49.260]  Tapos sa ICS,\n",
            "[02:01:49.260 --> 02:01:51.260]  core and collaboration,\n",
            "[02:01:51.260 --> 02:01:52.260]  ICS,\n",
            "[02:01:52.260 --> 02:01:53.260]  IPB,\n",
            "[02:01:53.260 --> 02:01:54.260]  ganyan-ganyan.\n",
            "[02:01:54.260 --> 02:01:55.260]  Ayun.\n",
            "[02:01:55.260 --> 02:01:56.260]  I-plan po natin yan.\n",
            "[02:01:56.260 --> 02:01:57.260]  Sama natin yung engineering\n",
            "[02:01:57.260 --> 02:01:58.260]  para maka...\n",
            "[02:01:58.260 --> 02:01:59.260]  Apo.\n",
            "[02:01:59.260 --> 02:02:01.260]  Maka-share kami sa HP.\n",
            "[02:02:01.260 --> 02:02:02.260]  Hahaha.\n",
            "[02:02:02.260 --> 02:02:03.260]  Oo nga.\n",
            "[02:02:03.260 --> 02:02:04.260]  Tama.\n",
            "[02:02:04.260 --> 02:02:05.260]  Alam mo,\n",
            "[02:02:05.260 --> 02:02:06.260]  pati yung ERDT,\n",
            "[02:02:06.260 --> 02:02:07.260]  may nagdanong sa akin ba,\n",
            "[02:02:07.260 --> 02:02:08.260]  sabi,\n",
            "[02:02:08.260 --> 02:02:09.260]  may ERDT scholars ba kayo?\n",
            "[02:02:09.260 --> 02:02:10.260]  Eh, parang...\n",
            "[02:02:10.260 --> 02:02:11.260]  Parang wala.\n",
            "[02:02:11.260 --> 02:02:12.260]  Pero,\n",
            "[02:02:12.260 --> 02:02:13.260]  ang computer science,\n",
            "[02:02:13.260 --> 02:02:14.260]  ano siya,\n",
            "[02:02:14.260 --> 02:02:15.260]  qualified siya.\n",
            "[02:02:17.260 --> 02:02:18.260]  By the way,\n",
            "[02:02:18.260 --> 02:02:19.260]  si Lasal po,\n",
            "[02:02:19.260 --> 02:02:20.260]  meron din palang gano'n.\n",
            "[02:02:20.260 --> 02:02:21.260]  Same lang nung sa UPLB.\n",
            "[02:02:21.260 --> 02:02:22.260]  Yung kung ano yung na...\n",
            "[02:02:22.260 --> 02:02:23.260]  na...\n",
            "[02:02:23.260 --> 02:02:24.260]  na-denate.\n",
            "[02:02:24.260 --> 02:02:25.260]  Si Lasal din eh,\n",
            "[02:02:25.260 --> 02:02:26.260]  meron din sila.\n",
            "[02:02:26.260 --> 02:02:27.260]  Na ano?\n",
            "[02:02:27.260 --> 02:02:28.260]  Nung,\n",
            "[02:02:28.260 --> 02:02:29.260]  nung ano,\n",
            "[02:02:29.260 --> 02:02:30.260]  V100 ng HPC\n",
            "[02:02:30.260 --> 02:02:31.260]  na-denate.\n",
            "[02:02:31.260 --> 02:02:32.260]  Ah, meron na sila?\n",
            "[02:02:32.260 --> 02:02:33.260]  Meron silang data science,\n",
            "[02:02:33.260 --> 02:02:34.260]  ano eh,\n",
            "[02:02:34.260 --> 02:02:35.260]  center eh,\n",
            "[02:02:35.260 --> 02:02:36.260]  institute.\n",
            "[02:02:36.260 --> 02:02:37.260]  Apo.\n",
            "[02:02:41.260 --> 02:02:42.260]  Sige po,\n",
            "[02:02:42.260 --> 02:02:43.260]  i-plano po natin yan,\n",
            "[02:02:43.260 --> 02:02:44.260]  yung ano.\n",
            "[02:02:44.260 --> 02:02:45.260]  Okay.\n",
            "[02:02:45.260 --> 02:02:46.260]  Madilim na.\n",
            "[02:02:46.260 --> 02:02:47.260]  Madilim.\n",
            "[02:02:47.260 --> 02:02:48.260]  Hahaha.\n",
            "[02:02:48.260 --> 02:02:49.260]  Pero,\n",
            "[02:02:49.260 --> 02:02:50.260]  sige po.\n",
            "[02:02:50.260 --> 02:02:51.260]  Ang ganda.\n",
            "[02:02:51.260 --> 02:02:52.260]  Opo.\n",
            "[02:02:52.260 --> 02:02:53.260]  May question pa ba?\n",
            "[02:02:53.260 --> 02:02:54.260]  Kung wala po,\n",
            "[02:02:54.260 --> 02:02:55.260]  request ko lang po sana,\n",
            "[02:02:55.260 --> 02:02:56.260]  para meron tayong,\n",
            "[02:02:56.260 --> 02:02:57.260]  ano,\n",
            "[02:02:57.260 --> 02:02:58.260]  memento.\n",
            "[02:02:58.260 --> 02:02:59.260]  Pipicture lang po.\n",
            "[02:02:59.260 --> 02:03:00.260]  Ay oo.\n",
            "[02:03:00.260 --> 02:03:01.260]  Hahaha.\n",
            "[02:03:01.260 --> 02:03:02.260]  Oo.\n",
            "[02:03:02.260 --> 02:03:03.260]  Ayan lang po bang pa-open\n",
            "[02:03:03.260 --> 02:03:04.260]  ng camps?\n",
            "[02:03:04.260 --> 02:03:05.260]  Ayan.\n",
            "[02:03:05.260 --> 02:03:06.260]  Ayun, nakita ko na si Sir Andre.\n",
            "[02:03:06.260 --> 02:03:07.260]  Mam Nia,\n",
            "[02:03:07.260 --> 02:03:08.260]  Mam Rox.\n",
            "[02:03:08.260 --> 02:03:09.260]  Hahaha.\n",
            "[02:03:09.260 --> 02:03:10.260]  Kita yung gulo\n",
            "[02:03:10.260 --> 02:03:11.260]  ng office.\n",
            "[02:03:11.260 --> 02:03:12.260]  Kumaka-open.\n",
            "[02:03:12.260 --> 02:03:13.260]  Ayan.\n",
            "[02:03:13.260 --> 02:03:14.260]  Ayan po.\n",
            "[02:03:14.260 --> 02:03:15.260]  Sige po.\n",
            "[02:03:15.260 --> 02:03:16.260]  Wait lang po ah.\n",
            "[02:03:16.260 --> 02:03:17.260]  Bibilang lang po ako.\n",
            "[02:03:17.260 --> 02:03:18.260]  Ako din kukuha.\n",
            "[02:03:18.260 --> 02:03:19.260]  Okay.\n",
            "[02:03:19.260 --> 02:03:20.260]  Kurt, ikaw din.\n",
            "[02:03:20.260 --> 02:03:21.260]  Kumuha ka din.\n",
            "[02:03:21.260 --> 02:03:22.260]  Ay wait lang po ah.\n",
            "[02:03:22.260 --> 02:03:23.260]  Teka.\n",
            "[02:03:23.260 --> 02:03:24.260]  Bibilang ako\n",
            "[02:03:24.260 --> 02:03:25.260]  para ano,\n",
            "[02:03:25.260 --> 02:03:26.260]  i-lakihan ko lang\n",
            "[02:03:26.260 --> 02:03:27.260]  tong ano.\n",
            "[02:03:27.260 --> 02:03:28.260]  Ayan.\n",
            "[02:03:28.260 --> 02:03:29.260]  Documentation ha.\n",
            "[02:03:29.260 --> 02:03:30.260]  Sige po po.\n",
            "[02:03:30.260 --> 02:03:31.260]  Sige po.\n",
            "[02:03:31.260 --> 02:03:32.260]  Smile.\n",
            "[02:03:32.260 --> 02:03:33.260]  Say akabay.\n",
            "[02:03:35.260 --> 02:03:36.260]  Isa pa.\n",
            "[02:03:36.260 --> 02:03:37.260]  Isa pa po.\n",
            "[02:03:40.260 --> 02:03:41.260]  Asti,\n",
            "[02:03:41.260 --> 02:03:42.260]  X-UPLB.\n",
            "[02:03:44.260 --> 02:03:45.260]  Ayan.\n",
            "[02:03:46.260 --> 02:03:47.260]  Thank you po.\n",
            "[02:03:47.260 --> 02:03:48.260]  Nakuha ko na po yung picture.\n",
            "[02:03:48.260 --> 02:03:49.260]  Maraming salamat.\n",
            "[02:03:49.260 --> 02:03:50.260]  Ay, kasama yung mga anak ko,\n",
            "[02:03:50.260 --> 02:03:51.260]  Sir Vanny.\n",
            "[02:03:51.260 --> 02:03:52.260]  Hahaha.\n",
            "[02:03:52.260 --> 02:03:53.260]  Masa.\n",
            "[02:03:53.260 --> 02:03:54.260]  Parang nagro-road trip sila.\n",
            "[02:03:54.260 --> 02:03:55.260]  Hello.\n",
            "[02:03:56.260 --> 02:03:57.260]  Bye-bye po.\n",
            "[02:03:57.260 --> 02:03:58.260]  Thank you ma'am.\n",
            "[02:03:58.260 --> 02:03:59.260]  Thank you so much.\n",
            "[02:03:59.260 --> 02:04:00.260]  Thank you.\n",
            "[02:04:00.260 --> 02:04:01.260]  Nagka-collaboration.\n",
            "[02:04:01.260 --> 02:04:02.260]  Nagka-collaboration natin.\n",
            "[02:04:02.260 --> 02:04:03.260]  Thank you Sir Ayan.\n",
            "[02:04:03.260 --> 02:04:04.260]  Thank you, bye-bye.\n",
            "[02:04:04.260 --> 02:04:05.260]  Thank you everyone, bye-bye.\n",
            "[02:04:05.260 --> 02:04:06.260]  Bye-bye.\n",
            "[02:04:06.260 --> 02:04:07.260]  Ba-bye.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the input directory containing audio files\n",
        "input_dir = '/content/drive/MyDrive/'  #@param {type: \"string\"}\n",
        "\n",
        "# Iterate over audio files in the input directory\n",
        "for audio_file in os.listdir(input_dir):\n",
        "    if audio_file.endswith('.mp3'):  # Adjust the file extension as needed\n",
        "        audio_path = os.path.join(input_dir, audio_file)\n",
        "\n",
        "        # Transcribe the audio file\n",
        "        !whisper \"{audio_path}\" --model large-v3 --output_dir \"{input_dir}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# whisper-large-v3\n",
        "- https://huggingface.co/openai/whisper-large-v3"
      ],
      "metadata": {
        "id": "mTKIj0FQGmBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade transformers datasets[audio] accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqKDaX6iGxdK",
        "outputId": "a28093bd-1b95-48ca-bf57-97a5b3b1953b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.70.15)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.11.0)\n",
            "Requirement already satisfied: soxr>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.5.0.post1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (1.8.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->datasets[audio]) (4.3.8)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->datasets[audio]) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets[audio]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets[audio]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZJfWqMjG93z",
        "outputId": "1ba48636-ed34-4998-a6b0-a5910ef27047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Imports\n",
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# STEP 2: Set device\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "print(f\"\\nDevice set to use {device}\")\n",
        "\n",
        "# STEP 3: Load model & processor\n",
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "# STEP 4: Define parameters\n",
        "chunk_duration = 30.0  # seconds\n",
        "generate_kwargs = {\n",
        "    \"max_length\": 448,\n",
        "    \"return_timestamps\": \"word\",  # optional: \"word\" or \"segment\"\n",
        "    \"do_sample\": False,\n",
        "}\n",
        "\n",
        "# STEP 5: Define input directory\n",
        "input_dir = '/content/drive/MyDrive/'  #@param {type: \"string\"}\n",
        "\n",
        "# STEP 6: Find audio files\n",
        "audio_files = [\n",
        "    os.path.join(input_dir, f)\n",
        "    for f in os.listdir(input_dir)\n",
        "    if f.endswith('.mp3') or f.endswith('.wav')\n",
        "]\n",
        "\n",
        "# STEP 7: Transcribe files\n",
        "for audio_path in tqdm(audio_files, desc=\"Transcribing audio files\"):\n",
        "    print(f\"\\n🗂️ Transcribing: {audio_path}\")\n",
        "\n",
        "    # Load audio\n",
        "    audio_array, sr = librosa.load(audio_path, sr=16000)\n",
        "    total_duration = librosa.get_duration(y=audio_array, sr=sr)\n",
        "    num_chunks = int(np.ceil(total_duration / chunk_duration))\n",
        "\n",
        "    print(f\"📏 Total duration: {total_duration:.2f} sec → {num_chunks} chunks of {chunk_duration:.0f} sec\")\n",
        "\n",
        "    full_transcript = \"\"\n",
        "\n",
        "    for i in tqdm(range(num_chunks), desc=\"Chunks\", leave=False):\n",
        "        start_sample = int(i * chunk_duration * sr)\n",
        "        end_sample = int(min((i + 1) * chunk_duration * sr, len(audio_array)))\n",
        "        chunk = audio_array[start_sample:end_sample]\n",
        "\n",
        "        # Process this chunk\n",
        "        inputs = processor(chunk, sampling_rate=16000, return_tensors=\"pt\")\n",
        "        input_features = inputs.input_features.to(device, dtype=torch_dtype)\n",
        "\n",
        "        # Generate\n",
        "        generated_tokens = model.generate(input_features=input_features, **generate_kwargs)\n",
        "        decoded = processor.batch_decode(generated_tokens, skip_special_tokens=True)[0].strip()\n",
        "\n",
        "        # Print live chunk result\n",
        "        start_time = i * chunk_duration\n",
        "        end_time = min((i + 1) * chunk_duration, total_duration)\n",
        "        print(f\"[{start_time:06.2f} --> {end_time:06.2f}] {decoded}\")\n",
        "\n",
        "        # Append to full transcript\n",
        "        full_transcript += f\"[{start_time:.2f} --> {end_time:.2f}] {decoded}\\n\"\n",
        "\n",
        "    # Save transcript to .txt\n",
        "    transcript_path = audio_path + \".txt\"\n",
        "    with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(full_transcript)\n",
        "    print(f\"\\n✅ Saved transcript to: {transcript_path}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08a8868d60a8431d857eae23eb74391a",
            "316fcf94cc18441cba6f7bf1cf5875af",
            "cabb50fc61f6455982d653a675573a43",
            "fafabedf0c5349d5a79b498ada2f438a",
            "f50c9d733a874e1882e76f5040586901",
            "59057142c7484021862763c837a83df0",
            "8b9c2ffc7d374a88824e8ccbd7cf6c60",
            "c67ea78f05754723a36db9d5bfc6d847",
            "160ddf2c05c343919dfc193e74ed1be6",
            "ee3778a77d914c558ae2fe11e9dd9e50",
            "c5b1612bd0cd4a0f8af03a31d9991c15",
            "30345451f2eb4039b690c52bd65701e3",
            "bdc7e28550b443dab917634690a9cf93",
            "24deefad2ac4452b8e644bc876141310",
            "668e8c1c3b5f4eb69268bf97df5823be",
            "9ee5a51e28d949f3b077af5f9e9ed963",
            "7c9391398ab34a0a8ac1ee86ab50f2af",
            "e933ce06b5f343b0845fcef8c5dbd394",
            "e622d6c7395f4038b6c27072929402c4",
            "b2779945066e4348a48703d443b29894",
            "817b99d3bc3f44b1ab406775933088fd",
            "8a5f4846287046a6a2fa97d625d2ba0f",
            "e26086736e2149faa30264fdc47466e7",
            "f8507a542f484955817bf60c9d4e78a7",
            "d113289f24d74dc8891835d0681fcd64",
            "4291cf4cd8674aff933bea5e5e18711a",
            "d127825763d946a4bf35dc1d05befa9c",
            "93bcf0ebd8f54c3894cc74cc627e980f",
            "fb874ab6059a43fe9c71c54419a490e0",
            "8c507718062f431e80166cff199f020c",
            "0a49c00ec90d4c62bb2a906224dd94e9",
            "a91197a82e4f4305a1245fe984126ccc",
            "10b071612b784e26b02a2a66a08a748a",
            "eea893e32ec44ebcb3e60c8ec70fc655",
            "a7acc423177344c29255a76bbd159926",
            "79f540767d5742cb850bbbe12486592d",
            "b4763e33f00c4410934c8a25a9cad0be",
            "91d4e029699e4afca30735baa5aef536",
            "478c8f31831c4eca8c1ed12782dfe9fa",
            "2e3caa93a0294b16b394907481353e04",
            "ed02b7d8ceeb47e3a07e50dab0437c30",
            "92579b31e232496a8144e3cf54684b17",
            "dc326222c6fb4aa6999cfe3157b56bcc",
            "d6d12aa086324481b045808a2e8bfe7e",
            "09fa0c2ca867419fa27ad0f328a971db",
            "5008ac00c9624a6f83018c54446eb0fa",
            "e1af3efdb0524df69999b4b73e9c9191",
            "f0ceac8662e645e18f1af107f14ec391",
            "3b8631a071644d238093f16fac832687",
            "696d2e73123945beb01dd327a2630370",
            "3a02f280684846e2a680eefa37689324",
            "030f700ed92243de9dae7ea7a265985b",
            "a7c25b6c57bd4fa688f5124283564e5f",
            "79701dd790034c8c8b2a4b12d50c0c64",
            "d494ae756a0d4abab7e91db7deda15e2",
            "724c362bdd5e4470ba4f520222a32857",
            "3e37c44e9f1c45928c0945b8208f53c0",
            "58de999e8ced4d2bb0cd62493a51a0fc",
            "fa7c3a2a7a584403b42be774d32cf9e7",
            "8f7a229642474b7f9fa52ac56c23f18b",
            "c18135cd2c7e411c89bd7a275d722481",
            "73eee035866048719e3c7a19d72f8ce8",
            "e7a39542c8e14d8694b2ff13d6b91fa7",
            "2d39b1d70e234f1cb2d5ade7f06894dd",
            "c1c28c1edf824c408a5b39c8490d79ed",
            "f3791f0e8b184963ae85c4e3c7b11a07",
            "6f1b35db6f2e4876be68e0123b1dbb40",
            "72e0c1c626854ccf862e3768d51fe24c",
            "0f37d5a9ed39450686ee81514bea7e79",
            "51081cfec6fc4bc1a95643ab344a6ed1",
            "6d2c2985d7254c0b8c938c2b63cc41c1",
            "ef9b7524a5e940a4aeaeead56cee73be",
            "c6528d0150374a3589941b2d43897d28",
            "3d9f0477250f4859bbe47995c7b31e8d",
            "6230bbe983b34cab9ff23a5aac661447",
            "a53554ffb7c2432a9c48ed4cf69baa26",
            "4d77691baaa745789a513174755e64e5",
            "6aec4510260d418b970ed7a3a49c91d4",
            "1c3183931e734894a661c30f81b119fb",
            "8dfbd4830b5048afb77906e1d495a1d6",
            "3f40ff17c00a4f1bb6baae4d836609bc",
            "7a6cc240c25849c29d78a8e4d30505f2",
            "40d58c5ecc5d4e6a893f7e8c35a4ddbb",
            "8fac2a76034e423c9fc8f92c0036390c",
            "0b3d9577aa04444babc11fab923f6785",
            "26672faa0ff84f23b5c1ec5ba9431761",
            "db35198aacaf41a9afe8168bf7c42e54",
            "24316f423e50444782dfded6e198b93f",
            "a0ebfccaaf62441a9df7a3af42820115",
            "e7cc3b68821648a6bb8e2d5c68e9eab2",
            "5694d791d7434157a4c7221aedfe40e6",
            "019ee4b3a9c64f8fab5f4d7e0ac46297",
            "77d2a25db3cc4d43af9390165e6a3133",
            "ad1bdc86e0aa4c71a1288137b15613c6",
            "9981a366c1ac46a282ba7fd5431748fb",
            "f93b430ba3d542c490c5a9d1a307fd08",
            "9e5c7cfd70db41d29805aa07509e7177",
            "2fac794af5b54e988f9fad9e5e468ebe",
            "feeccf4e643d4f1983e5e41dc6c1cbf3",
            "287e24831a6f497ebaa2d41cc5c69045",
            "df05d5baf9ff43f88d7ec3ba3b1e830a",
            "2a774dfd78754b3c915291fa8d1be864",
            "d7b6c0628314415e830eca4e6d56007c",
            "2a5963bf1e474172bcec724f02294c4b",
            "46c344ced7654c5797eff636ae8aadd3",
            "ef5df9be1dcb421298db8cfcb68a7b73",
            "ea507e5561a74da0a91d51a001bf3533",
            "b0a8e0d036dc4140bcd11f7a9c4af34f",
            "91a1f8e218834ed5ab42d5bc74baf59f",
            "8dc9fc4480d149bdab2bbb125352b231",
            "fde545cea1564e4fad941f43e504c407",
            "261bc6782d324374a9669a76d0aeb1f8",
            "a154181fb5e741f0b20c303ee40396af",
            "a18e7d2b9fb64a9bad10958586a05145",
            "f2d575612e3248ec9c2d2a460d7d5e9e",
            "249c500199c84467bf537c92906a5b63",
            "64e63c760f884f56ad77c9aa0f5b47d0",
            "0a2c81bb533141e7ba54f97329c44148",
            "770e249c72844ef69b05de157cab65e0",
            "fbd6e67551a344aca2d1f7851039a67b",
            "cfb559e7fa2342ad841d5381945c7aef"
          ]
        },
        "id": "2xs6xd29mcI1",
        "outputId": "99c479b2-ec31-4c76-a324-ac3c8b8d7170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08a8868d60a8431d857eae23eb74391a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30345451f2eb4039b690c52bd65701e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e26086736e2149faa30264fdc47466e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eea893e32ec44ebcb3e60c8ec70fc655"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09fa0c2ca867419fa27ad0f328a971db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "724c362bdd5e4470ba4f520222a32857"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f1b35db6f2e4876be68e0123b1dbb40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aec4510260d418b970ed7a3a49c91d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0ebfccaaf62441a9df7a3af42820115"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "287e24831a6f497ebaa2d41cc5c69045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fde545cea1564e4fad941f43e504c407"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTranscribing audio files:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🗂️ Transcribing: /content/drive/MyDrive/AI Governance.wav\n",
            "📏 Total duration: 4455.84 sec → 149 chunks of 30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   0%|          | 0/149 [00:00<?, ?it/s]\u001b[ADue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\n",
            "Chunks:   1%|          | 1/149 [00:05<14:10,  5.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[000.00 --> 030.00] Have you ever stopped to consider just how much of our everyday lives, especially, you know, when we interact with public services, is now quietly shaped by algorithms? It's really kind of remarkable how artificial intelligence has become this invisible hand guiding things. Yeah. Everything from, well, how your mail gets sorted to potentially much bigger things, right? Yeah. Like health care resource allocation or even law enforcement priorities. Exactly. It's not just about the latest app on your phone.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   1%|▏         | 2/149 [00:09<10:54,  4.45s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[030.00 --> 060.00] This stuff is deeply embedded in the public sphere now. It's powering what we might call AI-powered economies. It's true. We're really seeing this exponential growth of AI's presence in government and public services. Right. And, well, with that growth comes this really urgent critical need to think carefully about how these incredibly powerful tools are actually developed and deployed. deployed. Which is why today we're taking a deep dive into the government perspective on emergency\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   2%|▏         | 3/149 [00:13<10:48,  4.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[060.00 --> 090.00] emerging technology R&D, AI-powered economies, how governments are shaping the future. We're really digging into how public bodies are grappling with this new reality. And our main source for this, our foundation, is a really crucial guide from the Alan Turing Institute. It's called Understanding Artificial Intelligence Ethics and Safety, a guide for the responsible design and implementation of AI systems in the public sector. Dr. David Leslie authored it. Yeah, and this guide, it isn't just abstract.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   3%|▎         | 4/149 [00:17<10:02,  4.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[090.00 --> 120.00] theory, it's really designed for policymakers, for the people leading public service delivery. It gives them a concrete roadmap. The goal is basically to ensure that AI systems in the public sector are developed and deployed ethically, safely, and responsibly, right from the very start, you know, not just tacked on later. Right, not as an afterthought. So our mission today is to unpack exactly how governments are trying to balance the immense promise of AI, all those incredible benefits we keep hearing about with.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   3%|▎         | 5/149 [00:21<10:02,  4.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[120.00 --> 150.00] these critical considerations, ethics, safety, societal impact. It's a huge balancing act. Think of this as your shortcut to understanding this complex landscape of responsible AI governance. We'll highlight the challenges, sure, but also the practical frameworks being developed to tackle them head on. So let's start unpacking. Sounds good. Let's begin by sort of laying the ethical groundwork. And the Alan Turing Institute, our source here, is really central to this. Their public policy program set up back in May.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   4%|▍         | 6/149 [00:28<11:53,  4.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[150.00 --> 180.00] 2018, it wasn't just about playing with data, was it? No, not at all. Its core aim is specifically to help governments innovate with these data-intensive technologies for public benefit. That purpose is key. Purpose-driven innovation. I like that. And what really defines their approach is this core belief. Governments can only truly benefit from AI if ethics and safety are treated as a first priority. It has to be foundational. Foundational. Got it. What's also quite interesting about this guide is that they call it a living\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   5%|▍         | 7/149 [00:32<11:09,  4.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[180.00 --> 210.00] document. A living document. Yeah. It's designed to evolve, to improve with continuous input and feedback from the people using it. And importantly, the stakeholders affected by it. So it's not like some static rule book. It's meant to be dynamic, responsive. That makes perfect sense. I mean, the tech itself is evolving so fast, the guidance needs to keep up. Exactly. So let's pin this down. What exactly is AI ethics and why is it so, so crucial, especially when we're talking about public sector applications. Right. Well, AI...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   5%|▌         | 8/149 [00:36<10:23,  4.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[210.00 --> 240.00] AI ethics is essentially a set of values, principles, and techniques. And these are derived from widely accepted standards of right and wrong. They're meant to guide moral conduct throughout the entire AI lifecycle development use everything. So like a moral compass for the technology. Pretty much. Its main purpose is to motivate morally acceptable practices and also to prescribe the duties, the obligations needed to make sure AI applications are ethical, fair, and safe. It's about, you know, instilling a kind of conscience into the.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   6%|▌         | 9/149 [00:40<10:16,  4.40s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[240.00 --> 270.00] technology by guiding its creators. We hear so much about AI's potential, don't we? The guide calls it a remarkable time of human promise. Big data, cloud computing, advanced machine learning, they're driving these dramatic improvements everywhere. Healthcare, education, transport. Absolutely. And the guide points out that these bounties are, in fact, likely just the start. Because AI and machine learning systems, they inherently get better with more data, more computers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   7%|▋         | 10/149 [00:44<10:06,  4.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[270.00 --> 300.00] power. Right. So they're only going to become more effective. The guide actually calls AI a gatekeeper technology for advancing vital public interests and sustainable human development. Wow. Gatekeeper technology. That's a really strong phrase. It implies a huge amount of power and responsibility. It does. It suggests an almost unavoidable role for AI in our future. But as with any tech that evolves this quickly, there's always a flip side, isn't there? The guide doesn't exactly paint a purely rosy picture. It acknowledges risks. Oh, definitely not. It's very clear on it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   7%|▋         | 11/149 [00:48<09:27,  4.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[300.00 --> 330.00] It states that like any new tech with a steep learning curve, unanticipated and harmful impacts will inevitably occur. AI is no exception here. So it's not if, but when. Exactly. It's not a possibility. The guide frames it as a certainty. And this inevitability is precisely why making ethics and safety a first priority at every single stage of an AI project is just so incredibly critical. You have to anticipate harm. So it's not just about stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   8%|▊         | 12/149 [00:53<09:50,  4.31s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[330.00 --> 360.00] people using AI maliciously, which is one thing, but about foreseeing those unintended consequences. That sounds much harder. It is much harder. And who's responsible for that foresight? Is it just down to the data scientists writing the code? No, absolutely not. The guide really emphasizes that responsible AI needs a truly collaborative effort. You need multidisciplinary teams. Right. We're talking data scientists, product managers, engineers, crucially domain experts who understand the context, delivery managers, they all need to work together.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   9%|▊         | 13/149 [00:56<09:25,  4.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[360.00 --> 390.00] The goal is to align the actual development of the AI with these ethical values. Yeah. It's got to be team sport, you know, shared responsibility. That makes sense. Collaboration is key. Now let's dig into what those unanticipated and harmful impacts might actually look like. The guide outlines six pretty significant forms of harm from misuse, abuse, poor design, or just negative unintended consequences. We should probably walk through these. Yeah, definitely. The first one they highlight is bias and discrimination.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:   9%|▉         | 14/149 [01:00<09:03,  4.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[390.00 --> 420.00] This is a big one. I bet. Because data-driven technologies, they learn from existing societal structures, right? So as a result, they can end up reproducing, reinforcing, and sometimes even amplifying existing patterns of marginalization, inequality, discrimination. If your training data reflects historical injustices, well, the algorithm is going to learn those injustices. So the biases that are already out there in the world just get sort of baked right into the algorithms, like a feedback loop of it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  10%|█         | 15/149 [01:05<09:34,  4.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[420.00 --> 450.00] inequality. Exactly that. And it's not just the data. Designers own preconceptions, their unconscious biases. They can also be inadvertently replicated through the choices they make about, say, what features to use or what metrics optimize for. And if the data samples you use aren't representative of the population you're trying to make inferences about, well, you end up with flawed inputs. And that leads to a very real possibility of biased discriminatory outcomes right from the get-go. It's a huge, huge challenge. Okay, bias and discrimination.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  11%|█         | 16/149 [01:09<09:13,  4.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[450.00 --> 480.00] What's the next potential harm? The second is denial of individual autonomy, recourse, and rights. This is interesting. When AI systems start automating cognitive functions that humans used to do. Like making decisions. Yeah, exactly. Making judgments or decisions. It can create what the guide calls an accountability gap. Because the process is so complex, distributed across different people and systems, it becomes incredibly difficult to pinpoint who is actually responsible if something goes wrong. If there's an injury,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  11%|█▏        | 17/149 [01:13<08:52,  4.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[480.00 --> 510.00] or a negative consequence. So if an algorithm makes a bad call that harms someone, it's hard to hold anyone accountable. That sounds like a massive problem for due process and individual rights. It really is. This accountability gap can fundamentally harm a person's autonomy, and it can potentially violate their rights because the system acts, but the human who behind that action gets obscured, lost in the complexity. And related to that, I guess, is transparency. We hear that word all the time in AI discussions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  12%|█▏        | 18/149 [01:17<09:13,  4.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[510.00 --> 540.00] do. And that brings us neatly to the third harm, non-transparent, unexplainable or unjustifiable outcomes. Many advanced machine learning models, people often call them black box models. Right. The black box. They operate on these really high dimensional correlations that are just beyond human ability to interpret easily. So the reasoning, the rationale behind the outcome, the algorithm spits out, remains opaque, hidden, especially to the individuals affected by it. So it gives you an answer, maybe predict something, but you have absolutely no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  13%|█▎        | 19/149 [01:25<11:06,  5.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[540.00 --> 570.00] idea why it reached that conclusion. Exactly. Now, maybe in some low stakes uses like, you know, recommending a movie, maybe that opacity is okay, but it becomes deeply problematic in applications where the data being processed could harbor discrimination, bias, or unfairness. You need to know why a decision was made, especially if it seriously impacts your life, your access to public services, or your fundamental rights. Absolutely. And of course, privacy. That's Always a huge concern with data-driven tech. Always. That's the...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  13%|█▎        | 20/149 [01:29<10:35,  4.92s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[570.00 --> 600.00] fourth arm, invasions of privacy. And the threats here can arise both from the design and development process itself. Like how? Well, think about using personal data without proper consent, or maybe risky handling practices that accidentally expose sensitive information. But threats also come from the deployment phase, how the AI is used. Systems might target, profile, or maybe even nudge individuals without their knowledge or consent. nudging without consent. That sounds particularly, well, manipulative, almost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  14%|█▍        | 21/149 [01:33<10:03,  4.71s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[600.00 --> 630.00] like psychological steering. It can feel that way. And it can infringe upon a person's ability to lead a private life, to manage how technology influences their development. It really undermines their basic right to pursue their own goals free from, you know, unchosen influence. That connects to a broader societal impact too, doesn't it? How we interact with each other. It does, yeah. The fifth harm they identify is isolation and disintegration of social connection. AI has this amazing capacity for curating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  15%|█▍        | 22/149 [01:37<09:23,  4.43s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[630.00 --> 660.00] experiences. Hyper personalization. Which sounds good for consumers maybe. It can be yeah. Improve consumer life. Yeah. But it also carries risks like excessive automation might reduce the need for actual human to human interaction in some areas. And hyper personalization while convenient can inadvertently polarize social relationships. If you're only ever shown things that align with your existing views it limits your exposure to diverse world views. It pushes us into echo chambers. So instead of bringing us together, it could access.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  15%|█▌        | 23/149 [01:41<08:47,  4.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[660.00 --> 690.00] push us further apart. Filter bubbles on a societal scale. Exactly. The guide really emphasizes how important it is to preserve trust, empathy, mutual understanding, the things that make societies cohesive, especially as AI becomes more widespread. These are fundamental for a healthy society, and AI should ideally support, not undermine them. Okay. And the last one, what about just the quality of what the AI actually produces? That's the sixth harm, unreliable, unsafe, or poor quality outcomes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  16%|█▌        | 24/149 [01:45<09:06,  4.37s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[690.00 --> 720.00] Simply put, irresponsible data management, negligent design, maybe questionable deployment practices, they can all lead to AI systems just not working well, producing unreliable, unsafe, or simply poor quality outcomes. And in the public sector, that's not just annoying. It could be really damaging. Absolutely. It can mean direct damage to the well-being of individuals or the public welfare more broadly. And beyond that immediate harm, what are the knock-on effects? Well, beyond that, it can profoundly undermine public trust in the responsible use of AI overall.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  17%|█▋        | 25/149 [01:50<08:57,  4.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[720.00 --> 750.00] If people see failures, they lose faith. And it can lead to harmful inefficiencies, too, wasting limited public resources on AI tech that's ineffective or even detrimental. So, yeah, these six harms really underscore just how critical it is to get AI ethics right, especially in government. That is a comprehensive list and, frankly, a bit sobering. It really highlights why governments can't just, you know, jump on the AI bandwagon blindly. They need a solid framework. Exactly. So let's talk about that framework. The guide introduces the idea.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  17%|█▋        | 26/149 [01:54<08:44,  4.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[750.00 --> 780.00] of an ethical platform for responsible AI delivery. What's that about? Right. So this ethical platform concept, it's envisioned as a kind of governance architecture. It's meant to unite two things, an inbuilt culture of responsible innovation and the actual practices that bring ethical, fair, and safe AI to life. It serves a dual purpose. Okay. A dual purpose. What are they? Well, first, it gives project teams a solid process-based footing. Think of it as an ethical foundation they can build on to design and implement AI systems ethically.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  18%|█▊        | 27/149 [01:58<08:50,  4.35s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[780.00 --> 810.00] equitably, safely. So the how-to. Right. And second, it aims to help facilitate a culture of responsible AI innovation. It's about fostering a shared commitment among all the teams involved, a commitment to developing AI for the public good. It's trying to cultivate that shared mindset, not just, you know, ticking compliance boxes. Building a foundation and fostering a culture, that sounds like a powerful combination. What are the main goals for project teams working within this kind of framework.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  19%|█▉        | 28/149 [02:02<08:37,  4.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[810.00 --> 840.00] out four primary goals. Teams need to make sure their AI project is first, ethically permissible. That means really thinking through its impact on stakeholders, on communities. Second, it needs to be fair and non-discriminatory. That means actively working to mitigate biases at every stage. Right, which we just discussed. Third, it has to be worthy of public trust. That comes down to ensuring its safety, accuracy, reliability, security, robustness, all those technical aspects. Trust is huge. Absolutely. And fourth, it needs to be justifiable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  19%|█▉        | 29/149 [02:06<08:16,  4.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[840.00 --> 870.00] means prioritizing transparency of the process itself and the interpretability of the outcomes. Can you explain it? Can you justify it? Ethically permissible, fair, trustworthy, justifiable. Got it. But, you know, not all AI projects are the same, are they? Like a spam detector versus a cancer diagnosis tool. The stakes are vastly different. Does the platform account for that? It does. Yeah. That's a really crucial preliminary consideration the guide brings up. Proportionality. Proportionality.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  20%|██        | 30/149 [02:11<08:33,  4.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[870.00 --> 900.00] clearly states, you know, a machine learning algorithm just detecting spam emails is going to present fewer ethical challenges than one trying to detect cancer and blood samples. Obvious. So projects that aren't safety critical, that don't directly impact people's lives in major ways and don't process highly sensitive data, they'll require less intensive, proactive ethical stewardship. You tailor the oversight to the level of risk. So more risk, more scrutiny, less risk, Maybe a later touch. Exactly. However, and this is really important.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  21%|██        | 31/149 [02:15<08:06,  4.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[900.00 --> 930.00] However, the guide stresses that all AI projects have social and ethical impacts, even if it's just by diverting public resources away from something else or affecting public perception of AI. Ah, OK. So even the low-stakes ones aren't entirely impact-free. Right. So ethical considerations and this kind of principles-based policy thinking should play a salient role in every prospective AI project, even if the depth of the ethical review varies depending on the context and potential impact. That's a critical nuance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  21%|██▏       | 32/149 [02:19<08:10,  4.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[930.00 --> 960.00] project gets a completely free pass ethically. So how does this ethical platform actually get built? What are its foundational components, its building blocks? The guide identifies three main building blocks for what it calls a responsible AI project delivery ecosystem. And they're designed to work together, forming this continuous cycle of reflect, act, and justify. Reflect, act, justify. Okay, what are the three blocks? They are the SUM values, the fast track principles, and the process-based governance PBG framework. FASCM, FASTAFI, PBG. Got it. So the SMV.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  22%|██▏       | 33/149 [02:24<08:28,  4.38s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[960.00 --> 990.00] values are for reflecting, thinking about the ethical purposes, the objectives. The fast-track principles are for acting, making sure every step taken actually produces ethical, fair, safe AI innovation. And the PBG framework is for justifying setting up transparent processes that ensure end-to-end transparency and accountability. Okay, let's start with those SUM values. They sound like the moral compass you mentioned earlier. Where do they come from? What are they based on? Yeah, they provide what the guy calls a moral vocabulary.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  23%|██▎       | 34/149 [02:28<08:09,  4.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[990.00 --> 1020.00] And it's drawn primarily from two pretty well-established traditions. First, bioethics, you know, the ethics around medicine and biology, which focuses heavily on protecting individuals, their well-being, equitable treatment. Right, like do no harm. Exactly. And second, human rights discourse, which is anchored in these universal principles like human dignity, civil rights, political rights, social rights, community participation. So it's a blend, really, of medical ethics and universal human rights principles. Interesting blend. So what are the four specific esiums?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  23%|██▎       | 35/149 [02:31<07:44,  4.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1020.00 --> 1050.00] values? Can you break them down? Sure. They are respect, connect, care, and protect. They really lay the moral foundation. First, respect the dignity of individual persons. This means things like ensuring people can make free and informed decisions about AI affecting them, safeguarding their autonomy, their right to be heard, and supporting their ability to contribute to the community and pursue their talents and passions. It's fundamentally about recognizing the intrinsic worth of every single individual when AI is involved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  24%|██▍       | 36/149 [02:36<08:04,  4.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1050.00 --> 1080.00] So AI should empower individuals, support their flourishing and agency, not diminish it. Makes sense. What's next? Second, connect with each other sincerely, openly and inclusively. This value is about safeguarding the integrity of, well, interpersonal dialogue, meaningful human connection, social cohesion. The social fabric. Exactly. It prioritizes diversity, participation, inclusion at all points in the AI lifecycle. It really encourages making sure all voices are heard. And it pushes for using AI pros socially to enable self-awareness.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  25%|██▍       | 37/149 [02:40<07:45,  4.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1080.00 --> 1110.00] Solidarity, reinforced trust, empathy, mutual understanding among people. So AI shouldn't just optimize things for individuals in isolation. It should actively foster healthy social bonds. That's a powerful point and maybe one that gets overlooked sometimes. I think it often does. Third is care for the well-being of each and all. This is about designing and deploying AI systems specifically to foster and cultivate the welfare of all stakeholders involved. It's a direct call to do no harm with these technologies. The\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  26%|██▌       | 38/149 [02:44<07:31,  4.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1110.00 --> 1140.00] bioethics influence again? Right. Minimize risks of misuse or abuse. Prioritize people's safety, their mental and physical integrity. It really demands foresight, thinking ahead about the consequences when considering new tech possibilities or deploying AI apps. Do no harm and think ahead. Got it. Finally, protect. Fourth, protect the priorities of social values, justice, and the public interest. This value dictates that we must treat all individuals equally, protect social equity. It means using digital tech to support.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  26%|██▌       | 39/149 [02:48<07:41,  4.20s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1140.00 --> 1170.00] fair and equal treatment under the law. Justice and fairness. Yes. It emphasizes prioritizing social welfare, the public interest. It encourages using AI to empower and advance the interest of as many individuals as possible. And crucially, it demands thinking big picture about the wider impacts of AI, not just now, but for future generations and even for the environment, the biosphere. Wow, that's a truly comprehensive ethical view. So these SUM values, They're meant to be like a constant reference point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  27%|██▋       | 40/149 [02:53<07:34,  4.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1170.00 --> 1200.00] throughout a project. That's exactly the idea. They should orient the deliberation about whether a potential AI project is even ethically permissible in the first place. And they should guide how teams consider the impact across the entire innovation lifecycle. The guide encourages project teams to actively discuss how to weigh these values, especially if the specifics of a use case create tension between them because sometimes they might conflict. Right. Tradeoffs are inevitable sometimes. Okay. So SCM values are the big picture moral compass. Now let's move to the next building block.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  28%|██▊       | 41/149 [02:57<07:25,  4.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1200.00 --> 1230.00] the fast track principles. You said these are more actionable, more tailored to the AI development process itself. Why was this extra layer needed? Why not just stick with the SUM values? That's a really good question. It gets right to the heart of why AI ethics has become its own field, really. See, when humans perform intelligent actions, make judgments, we hold them responsible, right, for the accuracy, the soundness of their judgments. Yeah, of course. But AI systems, they aren't human. They're machines.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  28%|██▊       | 42/149 [03:01<07:37,  4.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1230.00 --> 1260.00] They shift a lot of cognitive functions over to algorithmic processes. And these processes, as inert machinery, they aren't morally accountable agents. They can't be blamed in the human sense. Ah, okay. So there's a gap. Exactly. This creates what the guide calls an ethical breach or an accountability gap. The FAST-TRACK principles, which stand for fairness, accountability, sustainability, and transparency, are specifically designed to fill this gap. They aim to bridge the new smart agency of machines with their fundamental lack of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  29%|██▉       | 43/149 [03:05<07:30,  4.25s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1260.00 --> 1290.00] moral responsibility. So they translate the need for moral accountability from humans into the design and deployment specs for these machines. That makes sense. And you mentioned earlier that these FAST principles aren't all quite the same type of principle. That's right. Accountability and transparency are seen as sort of end-to-end governing principles. They're about ensuring humans remain answerable and that the processes used are justifiable. Okay, the how. Right. Fairness and sustainability, on the other hand, are described more as qualities of algorithmic system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  30%|██▉       | 44/149 [03:09<07:05,  4.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1290.00 --> 1320.00] Qualities for which the designers and implementers are held accountable through the mechanisms of transparency and accountability. They're all deeply interrelated, naturally, but their roles within the framework differ slightly. It's also important to note, as the guide does, that these principles often align closely with legal requirements, like the data protection principles in GDPR or the Data Protection Act 2018. That's a critical connection linking the ethical framework to existing legal obligations. Let's dive into the first of the fast.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  30%|███       | 45/149 [03:13<07:07,  4.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1320.00 --> 1350.00] principles. Fairness. This feels like the most immediate, maybe the most common concern when we think about AI and public services. Bias. Discrimination. It absolutely is. And the core challenge here, as the guide lays out, is that AI technologies are fundamentally human designed. So they're prone to human error, human prejudice, human bias at every single stage, from how data is extracted right through to how the system is implemented in the real world. And beyond that, the data itself, the stuff the AI learns from,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  31%|███       | 46/149 [03:17<07:05,  4.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1350.00 --> 1380.00] from often contains these culturally crystallized forms of bias and discrimination. History baked into the data. And the guide is very blunt. There's no silver bullet when it comes to fixing discrimination in AI. It's not just a simple technical problem you can patch. So what's the approach then? The guide proposes what it calls the principle of discriminatory non-harm as a minimum threshold. Basically, designers and users must prioritize bias mitigation. They have to actively work to ensure AI systems don't generate discriminatory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  32%|███▏      | 47/149 [03:22<07:00,  4.12s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1380.00 --> 1410.00] or inequitable impacts. Okay, a minimum standard of do no discriminatory harm. And this principle implies focusing on specific areas, right? You mentioned data, design, outcomes, implementation. Yes, exactly. Fairness isn't just one thing. It has to be considered across the entire AI project pipeline. These four aspects are integrated. First, data fairness. This is absolutely foundational. Garbage in, garbage out, essentially. Pretty much. If the AI's results are generated by biased, compromised, or skewed data sets,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  32%|███▏      | 48/149 [03:26<07:12,  4.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1410.00 --> 1440.00] then the people affected by those results won't be protected from harm. So data fairness involves several things. Ensuring representativeness in the data doesn't reflect the population fairly. Making sure it's fit for purpose and sufficient. Is there enough relevant data? Checking its source integrity and measurement accuracy. Are we accidentally using biased historical decisions as ground truth? Ensuring it's timely and recent old data can introduce bias. And making sure it's relevant and appropriate, drawing on domain knowledge. That's a lot to check just for the data. Yeah.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  33%|███▎      | 49/149 [03:31<07:17,  4.38s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1440.00 --> 1470.00] It is. The guide suggests using something called a data set fact sheet. It's a best practice, basically. A log documenting the data's provenance, its quality checks, potential limitations. Okay, so documenting everything about the data. That makes sense for auditability later, too. What about design fairness? That's about the human choices made during development. Exactly. This focuses on the precautions needed to prevent bias creeping in to the human choices made across the workflow. This includes things like problem formulation. How do you translate a broad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  34%|███▎      | 50/149 [03:35<07:02,  4.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1470.00 --> 1500.00] goal into specific measurable targets. You have to be careful that this translation doesn't inadvertently disadvantage certain groups. Right. How you define success matters. Hugely. It also involves data pre-processing. How do you label, annotate, or organize the training data? Human judgment is involved there, so it needs to be done with fairness in mind, using solid contextual info and metadata. And then there's feature determination and model building, selecting input variables, engineering new features, tuning the model's parameters. All these steps involve\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  34%|███▍      | 51/149 [03:39<06:49,  4.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1500.00 --> 1530.00] choices that could introduce bias. Awareness and often peer review are crucial here. The guide also warns about hidden proxies, things like redlining, where seemingly neutral data like zip codes actually correlate strongly with protected characteristics like race. So you have to scrutinize the correlations the model finds, not just assume they're okay, and demand interpretability, especially when dealing with social data. Precisely. If you can't explain how a correlation is morally justifiable and perceivable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  35%|███▍      | 52/149 [03:43<06:39,  4.12s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1530.00 --> 1560.00] fair, you shouldn't be using it at high-stakes social systems. Which leads us to outcome fairness. Right. How do you define and measure if the results are fair? This is maybe the trickiest part, technically, because there are many different ways to define and measure fairness and outcomes. Some approaches focus on group fairness, like ensuring similar outcomes or error rates across different demographic groups, like demographic parity or equal opportunity. Others focus on individual\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  36%|███▌      | 53/149 [03:47<06:34,  4.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1560.00 --> 1590.00] fairness ensuring similar individuals are treated similarly. So different mathematical definitions of fairness. Exactly. And the guide is clear. There's no single best definition. They often involve trade-offs. Improving fairness by one metric might worsen it by another. And implementing them can be hard, sometimes requiring access to sensitive data. It requires a multidisciplinary effort to choose the right approach for the context. So you have to be upfront about it. Yes. The guide recommends creating a fairness position statement, or FPS. This would be a publicly available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  36%|███▌      | 54/149 [03:51<06:24,  4.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1590.00 --> 1620.00] plain language explanation of which fairness criteria were chosen, why, and what the trade-offs are, transparency about the definition. Okay. Define your terms clearly. And finally, the fourth aspect, implementation fairness. This is about bias creeping in at the point of use. Right. Even if you designed a technically fair model, bias can still emerge when it's actually deployed and used by people in the real world. Automated decision support systems introduce some novel risks here. Like what? The guide highlights two main risks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  37%|███▋      | 55/149 [03:56<06:48,  4.35s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1620.00 --> 1650.00] main pitfalls. First, decision automation bias, which is sometimes called the technological halo effect. This is where human users tend to over-rely on or over-comply with the outputs of AI systems because they perceive them as objective or infallible. The computer said so, it must be right. Exactly that mentality. This can lead to what's called out-of-loop syndrome, where the human essentially stops critically engaging, their judgment degrades, and they might miss errors or perpetuate biases produced by the system. This can lead to safety hazards,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  38%|███▊      | 56/149 [04:00<06:40,  4.31s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1650.00 --> 1680.00] or discriminatory harm. So people just blindly trust the machine, potentially amplifying its mistakes? Precisely. The guide says the solution involves strong accountability regimes, proper training, and crucially framing the AI as assisting human judgment, not replacing it. Yeah. Humans need to stay in the loop, critically engaged. Okay. And the other pitfall? The other is kind of the opposite. Automation distressed bias. This is where users might disregard the AI's contributions, maybe due to general skepticism them or\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  38%|███▊      | 57/149 [04:04<06:15,  4.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1680.00 --> 1710.00] perhaps over-prioritizing their own expertise or intuition, even when the AI might be offering valuable insights. So either trusting it too much or not enough. Right. Both can lead to unfair or suboptimal outcomes. So safeguarding fair implementation means things like training the human implementers properly on the AI's limitations, designing the user interface to encourage active judgment, and proactively exploring potential cognitive biases in the users themselves. Fairness isn't a one-time check.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  39%|███▉      | 58/149 [04:09<06:39,  4.39s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1710.00 --> 1740.00] It's this continuous process integrated across the entire pipeline, enabling that end-to-end accountability. And that concept, end-to-end accountability, leads us perfectly into the next FAST principle, accountability. You mentioned that accountability gap earlier. What are the core challenges here, specifically for AI in the public sector context? Well, like we touched on, the first challenge is fundamental. AI systems themselves are not morally accountable agents. They can't answer for their actions. So, human answerability must be clearly attached to any answerable question.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  40%|███▉      | 59/149 [04:12<06:18,  4.20s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1740.00 --> 1770.00] decisions supported by AI. Someone has to be responsible. Okay, the buck has to stop with the human. All right. The second challenge is the sheer complexity of how AI gets produced and deployed. Think about all the different parties involved in a typical public sector AI project. Department leads making policy decisions, technical experts building the model, procurement specialists buying tools, policy advisors setting rules, frontline implementers actually using the system. Lots of cooks in the kitchen. Exactly. This multi-agent nature.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  40%|████      | 60/149 [04:16<06:03,  4.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1770.00 --> 1800.00] makes it incredibly difficult to assign responsibility if the system's use leads to negative consequences. Who exactly is accountable when so many hands touch the process? So it's not just that the AI itself isn't accountable, but also that figuring out which human should be accountable on such a complex web is really hard. How does the guide suggest breaking down accountability into more actionable concepts? It defines accountability mainly through two subcomponents, answerability and auditability. Answerability and auditability, okay. Answerability.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  41%|████      | 61/149 [04:21<06:09,  4.20s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1800.00 --> 1830.00] means establishing a continuous chain of human responsibility across that entire AI project workflow. No gaps where responsibility gets lost. It also demands that the relevant human authorities can offer understandable explanations and justifications for algorithmically supported decisions. And crucially, these explanations need to be in plain, coherent language based on sound and impartial reasons understandable to those affected. So someone has to be able to explain it clearly and take responsibility for it. What about auditability? Auditability and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  42%|████▏     | 62/149 [04:24<05:44,  3.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1830.00 --> 1860.00] The answer is the how. How are designers and implementers actually held accountable? It means being able to demonstrate responsible practices and justifiable outcomes. This requires keeping detailed records, comprehensive logs. Logs of everything. Pretty much. Records for monitoring the soundness of the innovation processes, tracking data provenance from collection right through to deployment, and enabling critical review of how the system is actually operating in practice. The algorithmic models themselves must be built for audited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  42%|████▏     | 63/149 [04:28<05:37,  3.92s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1860.00 --> 1890.00] accountability. They need to be reproducible and equipped for end-to-end recording and monitoring of their data processing. That dataset fact sheet we talked about earlier, that becomes a crucial piece of the audit trail. It sounds like the overall principle here is really accountability by design, building it in from the start, making it proactive rather than just reactive when something goes wrong. Yes, absolutely. The guide makes a distinction between anticipatory Accountability, or Ex-Ante, which prioritizes making good decisions before deployment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  43%|████▎     | 64/149 [04:32<05:45,  4.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1890.00 --> 1920.00] to bolster the design's soundness, preempt potential harms, and inform stakeholders early. So getting it right beforehand. Right. And remedial accountability, or ex post, which focuses on corrective actions or providing justifications after a process is completed or a negative outcome occurs. The strong emphasis in the guide is on embedding accountability early, making it anticipatory to prevent problems in the first place. Though, of course, remedial accountability being able to justify things after the fact is still\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  44%|████▎     | 65/149 [04:36<05:43,  4.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1920.00 --> 1950.00] a necessary fallback. Okay, proactive accountability. From there, we move to the third FAST principle, sustainability. Now, this sounds like it's about the long-term view, the bigger picture impact. It is, exactly. Designers and users of AI systems need to remain constantly aware that these technologies can have truly transformative and long-term effects, both on individuals and on society as a whole. So to ensure sustainable deployment, project teams must be continuously sensitive to the real-world impacts their system will have or is having.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  44%|████▍     | 66/149 [04:41<05:40,  4.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1950.00 --> 1980.00] over time. So it's not just about whether it works now, but what its effects are down the line. How do they actually assess these long-term societal impacts? Is there a specific tool or process? Yes. The guide recommends using a stakeholder impact assessment, or SIA. SIA. This is basically a structured way to evaluate the potential social impact and the sustainability of an AI project. Yeah. It focuses on the effects on individuals, on different groups, on organizations. It applies whether the AI is for a public-facing or a public-facing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  45%|████▍     | 67/149 [04:45<05:39,  4.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1980.00 --> 2010.00] service, or even just a back office function. And what's the purpose of doing an SIA? What does it achieve? The guide lists several purposes. Building public confidence and trust is a big one. Strengthening accountability, obviously. Helping to reveal unseen risks or unintended consequences before they happen. Underwriting more informed decision making by policymakers. And generally demonstrating forethought and due diligence, showing that the potential impacts have been seriously considered. So it's about anticipating and trying to address those broader...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  46%|████▌     | 68/149 [04:49<05:43,  4.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2010.00 --> 2040.00] ripple effects proactively, when exactly should these SIAs be done? Is it a one-off thing? No, definitely not a one-off. The guide recommends conducting SIAs or at least revisiting them at three critical points in the project lifecycle. Three points. Okay. First, early on in the alpha phase during the initial problem formulation stage. This is for an initial assessment of ethical permissibility, often using those SEM values we discussed. And if significant impacts are anticipated, this initial SIA should ideally be opened up to.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  46%|████▋     | 69/149 [04:54<05:41,  4.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2040.00 --> 2070.00] input from the public and internal stakeholders. Get feedback early. Makes sense. Second, from alpha to beta, which is basically pre-implementation. Once the model is trained and technically validated, the team revisits that initial SIA. They reconfirm its findings, update it based on the developed model, and crucially make it publicly available before the system is launched. They also need to set clear time frames for when it will be reassessed once the system is live. So transparency before launch and a plan for review. And the third point. The third point is the beta phase.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  47%|████▋     | 70/149 [04:58<05:35,  4.25s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2070.00 --> 2100.00] for reassessment. After the AI system is actually deployed and running in the real world, the team needs to intermittently revisit and re-evaluate the SIA. They compare the predicted impacts with the actual real-world impacts observed. This allows them to identify and mitigate any unintended negative consequences that have emerged, and it should incorporate further public consultation. It's designed to be a continuous feedback loop, constantly checking the system's real-world sustainability. A continuous loop of assessment and...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  48%|████▊     | 71/149 [05:02<05:23,  4.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2100.00 --> 2130.00] Adaptation. Okay. That covers societal sustainability. Now for the final aspect linked to sustainability in the FAST principles, which the guide sometimes discusses under safety or technical sustainability, ensuring the system itself is technically reliable and robust. This feels like it gets into the nuts and bolts of the AI system. It does. Beyond the broader social sustainability, this technical sustainability, let's call it safety for clarity here, as the guide often does, is absolutely paramount. A technically sustainable or safe AI system is one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  48%|████▊     | 72/149 [05:05<05:02,  3.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2130.00 --> 2160.00] that is accurate, reliable, secure, and robust. Accurate, reliable, secure, robust. Right. Achieving these goals is challenging because AI often operates in a complex, uncertain world. But hitting these targets is crucial for mitigating risks and building that essential public trust, especially since potential failures in public sector AI could produce really harmful outcomes. So what are the core safety objectives teams should be aiming for when building these systems?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  49%|████▉     | 73/149 [05:10<05:12,  4.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2160.00 --> 2190.00] The guide breaks them down into those four operational objectives we just mentioned. First, accuracy and performance metrics. This is about the proportion of correct outputs versus errors, but it's also about refining those measures, maybe looking at the total cost of errors or using metrics like precision and recall. And critically, it's about coping with unavoidable noise in the data, architectural uncertainties in the model, and changes in the input data over time. So accuracy isn't static. No. Second, reliability. This simply means that the data is being sent to the server.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  50%|████▉     | 74/149 [05:14<05:07,  4.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2190.00 --> 2220.00] the ai system behaves exactly as its designers intended it to it consistently adheres to its program specifications does it do what it's supposed to do consistently okay third third security this covers a range of things protecting the ai system from adversarial attack someone trying to maliciously interfere with it maintaining the integrity of the information it processes ensuring its continuous functionality that it doesn't just crash and maintaining confidentiality where needed. Protecting it from bad actors and ensuring it stays.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  50%|█████     | 75/149 [05:17<04:51,  3.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2220.00 --> 2250.00] up. Exactly. And fourth, robustness. This is the goal that an AI system functions reliably and accurately, even under harsh or unexpected conditions. This could include deliberate adversarial intervention, errors made by the human implementer using the system, or even just the system encountering skewed or unusual data it wasn't specifically trained on. Can it handle surprises gracefully? Accurate, reliable, secure, robust. These objectives sound incredibly challenging to guarantee, especially with new\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  51%|█████     | 76/149 [05:21<04:47,  3.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2250.00 --> 2280.00] threats and complexities emerging all the time. What are some of the critical risks to AI safety that the guide specifically identifies? It flags several key risks. First, concept drift. We touched on this briefly. Most machine learning systems are static models trained on historical data. But the real world changes, right? The underlying data distributions can shift over time. So the past isn't always a good predictor of the future. Exactly. For example, a model trained on past disease patterns might start failing if a new variant emerged.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  52%|█████▏    | 77/149 [05:26<04:53,  4.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2280.00 --> 2310.00] emerges with different characteristics. Teams need vigilance and action plans to detect and address this drift, perhaps by retraining the model periodically. Ok, concept drift, what else? Second, brittleness. This refers to inherent limitations, particularly in very complex models like deep neural networks. They can often struggle when they encounter unfamiliar events or scenarios that fall outside their training data distribution. Because they lack genuine context awareness or common sense, they can make unexpected, sometimes bizarre, unexpected,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  52%|█████▏    | 78/149 [05:29<04:41,  3.97s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2310.00 --> 2340.00] unexplainable mistakes in these situations. Right. They might perform brilliantly on the test data, but fail spectacularly and unpredictably when faced with something genuinely new in the real world. Precisely. And this is especially critical in safety-critical applications. Think autonomous transportation, medical diagnosis. Unseen situations can lead to catastrophic failures if the model is too brittle. Okay. Brittleness. What's next? Third, adversarial attack. These are deliberate attempts to fool the AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  53%|█████▎    | 79/149 [05:33<04:38,  3.98s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2340.00 --> 2370.00] It involves maliciously modifying the input data, often in ways that are imperceptible to humans, specifically to induce the AI to make a mistake, a misclassification, or an incorrect prediction. Can you give an example? The classic example is slightly altering the pixels on an image of, say, a panda, so that a human still sees a panda. But a sophisticated image recognition AI confidently classifies it as a given. What? Or, more worryingly, changing a few pixels on a stop sign image so a self-driving car\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  54%|█████▎    | 80/149 [05:38<04:47,  4.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2370.00 --> 2400.00] as AI misidentifies it as a speed limit sign. Wow. That has huge safety implications for critical systems. Absolutely. It requires specific defense strategies, often called model hardening, like adversarial training or modifying the model architecture to be less susceptible, and runtime detection methods. Okay. Adversarial attacks. What else? Fourth, data poisoning. This is a related type of adversarial attack, but it happens earlier in the process. Here, an adversary compromises the data sources during collection or pre-processing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  54%|█████▍    | 81/149 [05:42<04:39,  4.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2400.00 --> 2430.00] They deliberately manipulate the training data set itself to induce misclassification later on, or even systemic malfunction. Sometimes they create hidden back doors in the model. It really highlights the importance of responsible data management and securing your data pipeline. So sabotaging the training data itself, scary. Is there one more? Yes. Finally, the guide discusses misdirected reinforcement learning behavior, RL. Reinforcement learning is where systems learn by trial and error, trying to maximize a predefined reward function. Learning by doing. Right. However,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  55%|█████▌    | 82/149 [05:45<04:18,  3.86s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2430.00 --> 2460.00] If these systems lack broader context awareness or common sense, they might find clever but unintended and potentially harmful ways to optimize that reward function, ways that the designers didn't anticipate. For instance, an AI optimizing for traffic flow speed might learn to achieve that goal by, say, routing cars in a way that compromises pedestrian safety if pedestrian safety wasn't explicitly included and properly weighted in its reward function. So the RL system achieves its narrow goal.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  56%|█████▌    | 83/149 [05:50<04:24,  4.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2460.00 --> 2490.00] but causes unintended collateral damage along the way because it doesn't understand the bigger picture or human values. Precisely. It just optimizes the metric it was given. Mitigation strategies here include things like extensive simulations in safe environments before deployment, continuous monitoring in the real world, building in interpretability, and crucially, having human override or shutdown mechanisms. Human oversight is key. Always. The guide really emphasizes that end-to-end AI safety is paramount. These considerations, accuracy, reliability, security, robustness,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  56%|█████▋    | 84/149 [05:54<04:21,  4.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2490.00 --> 2520.00] they can't be an afterthought. They have to operate at every stage of the AI project life cycle, involving rigorous testing, validation, and ongoing self-assessments. Okay, we've covered a lot. The ethical groundwork with SUM values, the actionable fast principles, including fairness, accountability, sustainability, and safety. Now let's turn to the final fast principle, transparency. This feels absolutely vital for building public trust, especially when it's the government using AI. It is.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  57%|█████▋    | 85/149 [05:58<04:17,  4.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2520.00 --> 2550.00] Incredibly vital. And the guide does a good job of clarifying that transparency in the context of AI ethics actually has two distinct but closely related meanings. Two meanings. OK. On the one hand, transparency refers to interpretability. This is about knowing how and why a model performed the way it did. Understanding its internal logic, its rationale. It's often talked about as opening the black box of AI. It involves content clarification, making the system intelligible. So understanding the machine's inner workings, its logic, the why behind its output. Exactly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  58%|█████▊    | 86/149 [06:02<04:12,  4.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2550.00 --> 2580.00] hand, transparency also refers to justifiability. This is broader. It means being able to demonstrate the ethical permissibility, the non-discrimination or fairness, and the trustworthiness of both the design and implementation processes that led to the AI and the actual outcomes produced by the AI system. Okay, so it's not just about understanding how the machine works, but also being able to understand and justify the human choices and processes behind it and whether the outcome itself is ethically sound. Precisely.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  58%|█████▊    | 87/149 [06:06<04:21,  4.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2580.00 --> 2610.00] It's about showing that the use of the AI is practically and morally sound and that the human decisions and governance surrounding it are also sound and defensible. So the guide breaks this down further using this process product distinction you mentioned. It outlines three critical tasks for ensuring transparent AI. Yes, that process product distinction is really helpful here. The three tasks are first process transparency. Task one, justify process. This involves demonstrating that those ethical principles, permissibility, non-discrimination, fairness, and justice are not just a matter of choice.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  59%|█████▉    | 88/149 [06:10<04:03,  3.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2610.00 --> 2640.00] safety were actively considered and applied throughout the design and implementation processes. You prove this by following best practices and having robust auditability measures in place. So, proving that the journey taken to arrive at the AI outcome was ethically sound and well-documented. Correct. Second, outcome transparency, task two, clarify content and explain outcome. This task requires showing, in plain, understandable language, the guide calls socially meaningful, how and why a specific model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  60%|█████▉    | 89/149 [06:13<03:50,  3.84s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2640.00 --> 2670.00] model performed as it did in a particular context or for a particular decision. It's about translating the complex technical rationale into everyday terms that non-specialists can actually grasp, making sense of it in terms of human practices and relevant societal factors. And the phrase socially meaningful is key, isn't it? The explanation has to resonate with human practices and societal context, not just be a list of mathematical functions. Absolute critical. And third, outcome transparency. Task three, justify outcome. This builds is\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  60%|██████    | 90/149 [06:18<04:04,  4.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2670.00 --> 2700.00] directly on the clarified content from task two. It demands demonstrating that a specific decision or behavior of the system is, in itself, ethically permissible, non-discriminatory or fair, and worthy of public trust. This justification relies heavily on having followed those sound processes established back in task one. That's a really clear three-part structure. Justify the process, explain the outcome, justify the outcome. So how does the guide suggest achieving that first part, process transparency? How do we make the governance itself transparent?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  61%|██████    | 91/149 [06:22<03:53,  4.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2700.00 --> 2730.00] It boils down to a few key elements. Maintaining strong regimes of professional and institutional transparency is the baseline. This means team members adhering to rigorous standards of integrity, honesty, impartiality, things you'd expect in public service anyway. And the design and implementation process itself should be as open to public scrutiny as reasonably possible, balancing transparency with necessary confidentiality limits. So openness and integrity are the foundation. And then you mentioned the PBG framework earlier. Yes, the process-based governance PBG framework is key here.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  62%|██████▏   | 92/149 [06:25<03:40,  3.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2730.00 --> 2760.00] Its purpose is to operationalize those values, SUM, and principles, FAST, across the entire AI design and development pipeline, whatever specific workflow model is being used, like CRISPM for data mining. Okay. It provides what the guide calls a landscape view of the governance procedures. It clearly shows who the relevant team members and roles are, what the necessary workflow stages are for specific ethical interventions or checks, sets explicit timeframes for follow-up actions, and defines clear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  62%|██████▏   | 93/149 [06:30<03:48,  4.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2760.00 --> 2790.00] protocols for logging activity and ensuring that crucial end-to-end auditability. It's basically the detailed blueprint for how ethical considerations get woven into every step. And presumably all the information generated by following that PBG framework feeds into the auditability piece, enabling auditability with a process log. Exactly. The idea to centralize all this information digitally records from the PBG framework checkpoints, data about model development, testing results, SIA documents, fairness assessments. This creates a comprehensive process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  63%|██████▎   | 94/149 [06:33<03:30,  3.83s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2790.00 --> 2820.00] And the benefit of that log? Two main benefits. First, it allows the team to demonstrate responsible practices and justifiable outcomes to any concerned parties, regulators, oversight bodies, the public. Second, and this is really important, it allows them to curate different kinds of explanations for different stakeholders based on their level of technical expertise. It helps ensure what the guide calls cognitive equity, making sure understanding is accessible, not just locked away in technical.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  64%|██████▍   | 95/149 [06:37<03:27,  3.85s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2820.00 --> 2850.00] jargon. Cognitive equity, that's a great term. Okay, that covers making the process transparent. Now let's tackle the other side, outcome transparency. Explaining and justifying the specific AI decisions. You said earlier there's no simple technological fix here, which sounds, well, challenging. It is challenging, yeah. Because it's a multifaceted undertaking. It's not just about technology. It requires sound human judgment, collaboration, and communication skills. The core challenge is to effectively clarify and convey the rationale behind a model's output.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  64%|██████▍   | 96/149 [06:41<03:21,  3.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2850.00 --> 2880.00] in a way that can properly inform human judgment downstream, and be genuinely accessible and meaningful to the stakeholders affected by the decision. Because without sufficient interpretability, without understanding why the model did what it did, it's impossible to tell how and why things might be going wrong, which is crucial for ensuring safety, checking for fairness, detecting hidden bias, and ultimately for building trust. So interpretable AI means making the logic understandable. And the guide connects this need for interpretability.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  65%|██████▌   | 97/149 [06:45<03:30,  4.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2880.00 --> 2910.00] back to four dimensions of human reasoning. Can you explain that? Yeah. This is a really interesting part of the guide. It argues that when we ask for an explanation of an algorithmic model's decision, we're essentially asking it to make explicit how the factors determining that outcome serve as evidence, almost as if a reasoning human had produced it. And human reasoning, the guide suggests, typically involves four interconnected dimensions. So what are they? First, aspects of logic, formal explanations, rules of inference. Second,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  66%|██████▌   | 98/149 [06:49<03:18,  3.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2910.00 --> 2940.00] Second, semantics understanding how and why things work, the technical rationale, the function of different parts. Third, social understanding grasping the context of human practices, beliefs, intentions. This is about clarifying the socially meaningful content. And fourth, moral justification, assessing rightness and wrongness, fairness, ethical permissibility. And these four dimensions map directly onto what we demand from AI interpretability. Exactly. The technical aspects of AI ensuring safety, robustness,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  66%|██████▋   | 99/149 [06:53<03:16,  3.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2940.00 --> 2970.00] fairness, require understanding the underlying logic and the semantic inner workings of the model. But because these AI systems are designed to fulfill human objectives and operate within our social world, we also need to understand their decisions in terms of their social context and meaning. And since their decisions often have direct moral consequences, especially in the public sector, their outcomes require moral justification. These dimensions are seen as interdependent, building on each other to form a complete explanation. That's a really holistic way to think about what constitutes a good explanation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  67%|██████▋   | 100/149 [06:57<03:19,  4.06s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2970.00 --> 3000.00] Now, let's get into the more technical aspects of choosing, designing, and using an interpretable AI system. The guide makes an interesting point early on, saying that all AI models are, at a foundational level, mathematical glass boxes. What does that mean? Isn't the problem usually the black box? Right. What it means is that purely from a formal, logical perspective, any algorithmic model, even a massive deep neural network with millions of parameters, is technically\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  68%|██████▊   | 101/149 [07:01<03:11,  3.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3000.00 --> 3030.00] transparent. It's a closed system of computable operations. Rules and mathematical transformations are mechanically applied to inputs to determine outputs. In that very restricted mathematical sense, they are transparent. You can, in principle, trace every calculation. But crucially, that kind of mathematical transparency doesn't actually explain how or why a particular outcome occurred in a way that's meaningful or understandable to a human. It doesn't give you the intuitive grasp, the semantic understanding. And that's where the famous black box challenge really comes in.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  68%|██████▊   | 102/149 [07:05<03:03,  3.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3030.00 --> 3060.00] comes in. Yes, exactly. As machine learning systems handle more and more data and grow in complexity to capture intricate patterns, they use much larger feature spaces, meaning many more input variables and employ highly complex nonlinear mapping functions to connect inputs to outputs. This is characteristic of black box models like deep neural networks, support vector machines, or complex ensemble methods. So things get tangled up. Incredibly tangled. Yeah. The effects of changing one input variable become intertwined with many other variables.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  69%|██████▉   | 103/149 [07:09<03:07,  4.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3060.00 --> 3090.00] others in ways that are hard to isolate or understand intuitively. The internal logic becomes effectively opaque to human inspection. And this poses that key dilemma for designers and policymakers. How do you weigh the potential for superior performance or accuracy that these complex models might offer against the very real tangible risks of lacking interpretability, especially in critical public sector applications where fairness, safety, and accountability are paramount. It's a difficult trade-off and the guide offers specific guidelines to help.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  70%|██████▉   | 104/149 [07:13<03:02,  4.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3090.00 --> 3120.00] navigate this. What's the first guideline? Guideline one. Look first at context, potential impact, and domain-specific need. Before even thinking about specific models, you need to assess the situation. What's the type of application? Is it a low-stakes tool processing forms or a high-stakes safety critical system like a security checkpoint or medical diagnosis? The need for interpretability scales with the potential impact. Right. Context is king. Absolutely. And domain specificity is vital too. You need solid domain knowledge to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  70%|███████   | 105/149 [07:17<02:56,  4.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3120.00 --> 3150.00] understand the sector-specific explanation standards, the expectations of stakeholders in that field, and maybe even how older existing technologies in that domain hand an explanation. Okay, so step one, understand the context, the risks, the domain requirements. What's guideline two? Guideline two, draw on standard interpretable techniques when possible. The message here is, don't jump straight to the complex black box if you don't need to. Teams should actively try to find the right fit between the risks, the data they have, and the available machine learning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  71%|███████   | 106/149 [07:22<02:56,  4.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3150.00 --> 3180.00] techniques. For applications with high impact, high safety criticality, or those processing sensitive personal data, simpler, inherently non-opaque techniques should be prioritized if they can achieve adequate performance. Like what kind of techniques? Things like decision trees, linear or logistic regression, if the number of features is manageable, rule lists models where the decision-making process is relatively straightforward to understand. The guide even suggests that reaching for a black box prematurely might sometimes be ineffective.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  72%|███████▏  | 107/149 [07:25<02:46,  3.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3180.00 --> 3210.00] efficient, adding unnecessary complexity and risk. So the mantra is use the simplest, most explainable model that can effectively do the job. But what if it can't? What if the problem genuinely requires a black box model to get the needed performance, maybe in areas like complex image recognition or natural language processing? That brings us logically to guideline three. When considering the use of black box AI systems, this guideline itself has three key steps. First, thoroughly weigh impacts and risks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  72%|███████▏  | 108/149 [07:29<02:36,  3.82s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3210.00 --> 3240.00] The decision to use a black box model should only be made if its potential impacts and risks have been carefully considered and deemed acceptable, and if supplemental interpretability tools can provide a sufficient level of semantic explainability enough to ensure the system operates safely, fairly, and ethically. So, use a black box only if you really have to, and only if you have robust methods to explain its behavior afterward. Okay, use with caution and only with explainability tools. What are these supplemental interventions?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  73%|███████▎  | 109/149 [07:33<02:42,  4.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3240.00 --> 3270.00] interpretability tools. That's the second step, right? Yes, second step. Consider options for supplemental interpretability tools. This involves assessing the range of technical methods available for providing post hoc explanations and choosing ones that fit the specific use case needs and provide clear explanatory resources. The guide explores several different strategies here. Can you give us a flavor of those strategies? Sure. There's internal explanation, which tries to make the internal components of the black box model itself more intelligible, perhaps for better engineering insight. There's external or post hoc explanation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  74%|███████▍  | 110/149 [07:37<02:38,  4.06s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3270.00 --> 3300.00] This is probably the most common approach currently. It involves trying to understand the black box by observing its input-output behavior, essentially reverse engineering it. Techniques like perturbing the input slightly to see how the output changes or building simpler proxy models that mimic the black box's behavior locally. Tools like LIME and ESHAP fall into this category. They try to explain specific predictions by highlighting which input features were most important for that particular outcome. Lime and Esche. We hear those names.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  74%|███████▍  | 111/149 [07:41<02:24,  3.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3300.00 --> 3330.00] We do. They're prominent examples, though the guide notes they have limitations. The explanations are approximations and can sometimes be sensitive to how they're applied. Another strategy is supplemental explanatory infrastructure, building secondary explanatory facilities into the system itself. This might involve mechanisms that generate natural language explanations or justifications alongside the output, or visualization tools that help users understand the model's focus, like attention maps and image analysis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  75%|███████▌  | 112/149 [07:45<02:24,  3.91s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3330.00 --> 3360.00] And finally, there's counterfactual explanation. Counterfactuals? What are those? This is a really interesting approach. Counterfactual explanations aim to provide actionable recourse to the person affected by the decision. They answer the question, what factors would need to change and by how much for the outcome to be different and presumably more favorable, for example. Your loan application would have been approved if your income was X amount higher. Wow, that sounds incredibly useful and empowering for the individual, giving them\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  76%|███████▌  | 113/149 [07:50<02:29,  4.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3360.00 --> 3390.00] concrete steps they could potentially take. It can be, yes. It's powerful because it's contrastive and agency-promoting. Though again, the guide notes limitations generating them can be complex. They might not capture all interactions, and they work best when only a few factors need changing. And these different strategies also relate to the scope of the explanation, right? The guide talks about local versus global interpretability. Correct. That's an important distinction. Local interpretability focuses on explaining individual cases or Thank you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  77%|███████▋  | 114/149 [07:53<02:23,  4.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3390.00 --> 3420.00] predictions. LIME and S-SHOP are primarily local methods. They tell you why the specific prediction was made. Global interpretability, on the other hand, aims to explain the behavior of the model as a whole. How does it generally make decisions? What are the overall patterns it has learned? Understanding the big picture of the model. Right. Achieving true global understanding of a complex black box is often very difficult. But the guide suggests constructive views. Even approximating the opaque model with a simpler interpretable one can provide value.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  77%|███████▋  | 115/149 [07:57<02:16,  4.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3420.00 --> 3450.00] valuable insights into its general behavior, support knowledge discovery, and help advance data science by revealing patterns. Okay. So, weigh risks, consider explanation tools, local, global, counterfactual. What's the third step under Guideline 3? The third step is to formulate an interpretability action plan. Once you've decided on explanatory strategies, you need a concrete plan. Articulate which tools and techniques will be used, specify the delivery strategy, how explanations will be provided to different users,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  78%|███████▊  | 116/149 [08:02<02:23,  4.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3450.00 --> 3480.00] set time frames for evaluating the effectiveness of the explanations, and clearly map out who is responsible for what in delivering interpretability. A concrete plan. That makes sense. This all sounds like a continuous, thoughtful effort. And the guide's final guideline, guideline four, think about interpretability in terms of the capacities of human understanding, seems like a really crucial overarching principle tying this together. It absolutely is. It reminds us that interpretability isn't some binary switch into either interpretable or not. It's a continuum of comprehensibility.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  79%|███████▊  | 117/149 [08:06<02:08,  4.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3480.00 --> 3510.00] And where something falls on that continuum depends fundamentally on human cognitive limits, meaning even a mathematically simple model, like a linear regression, can become effectively uninterpretable if it involves, say, thousands of features. No human can hold all those weighted factors in their head and intuitively grasp the overall logic. The sheer volume of information exceeds our cognitive capacity. So complexity kills interpretability, even for simple models sometimes. Yes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  79%|███████▉  | 118/149 [08:10<02:03,  3.97s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3510.00 --> 3540.00] And the key takeaway from this guideline is the need to tailor explanations to the cognitive capacities and expertise levels of different audiences. Technical operators running the system need a different kind of explanation than frontline implementers using its outputs, who in turn need something different from the non-specialist members of the public affected by its decisions. Ensuring this cognitive equity, making sure understanding is genuinely accessible to all relevant parties, is vital for responsible AI. Cognitive equity. I really like that framing. It's not just about technology.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  80%|███████▉  | 119/149 [08:14<02:03,  4.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3540.00 --> 3570.00] technical transparency, but about making that transparency meaningful to everyone involved. It sounds like all these guidelines, all this thinking about interpretability, ultimately culminates in how you actually implement these systems in a human-centered way. Precisely. The final major section of the guide, securing responsible delivery through human-centered implementation protocols and practices, is entirely dedicated to this crucial last mile. The core principle here is straightforward, but powerful. You must devise delivery and implementation process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  81%|████████  | 120/149 [08:18<01:57,  4.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3570.00 --> 3600.00] that are deeply sensitive to human factors, to people's needs, their competences, their capacities, their contexts. To provide clear and effective explanations that actually work in practice, you have to build from the human ground up, understanding the specific use case and domain context inside out. Building from the human ground up, okay. And the guide outlines three steps for achieving this human-centered implementation. What's step one? Step one. Consider aspects of system type and domain context to define roles and determine user needs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  81%|████████  | 121/149 [08:21<01:48,  3.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3600.00 --> 3630.00] needs. This involves really thinking about who will be affected by the system. Which communities? Are there vulnerable groups involved? How might their background or experiences influence their ability to understand or challenge an AI-driven decision? The explanatory strategy needs to be fine-tuned to accommodate these varying needs, providing clear, non-technical details accessible to everyone. So, map out the users and their needs? Yes, and define their roles clearly. The guide gives a hypothetical example.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  82%|████████▏ | 122/149 [08:26<01:53,  4.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3630.00 --> 3660.00] of a predictive risk assessment system in, say, social care. It defines roles like the decision subject, the person the assessment is about, their advocate, maybe a lawyer or support worker, the implementer, the frontline social worker using the tool, the system operator, technical staff managing the system, and the delivery manager overseeing the service. Each role has different goals, objectives, and critically different levels of technical and domain knowledge. Their needs for explanation vary significantly. That's a really practical way to break down the complex user landscape. Define the role of the user landscape.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  83%|████████▎ | 123/149 [08:30<01:45,  4.06s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3660.00 --> 3690.00] understand their specific needs, what's step two? Step two, define delivery relations and map delivery processes. Once you have the roles, you need to think about the relationships between them. How does the decision subject or their advocate interact with the implementer? How does the implementer get technical support or clarification from the system operator? Mapping these relationships and the communication flows is crucial. Okay. And the principal objective of the delivery process itself, the guide argues, is twofold.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  83%|████████▎ | 124/149 [08:34<01:38,  3.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3690.00 --> 3720.00] First, to translate the statistically expressed results from the AI into humanly significant reasons. Second, to translate the algorithmic outputs into socially meaningful outcomes within the context of the person's life and the service being provided. So it's not enough to just hand over the raw data or probability score. You have to translate it into human terms, into social context. Exactly. It's a translation task. And this twofold objective reasons and meaningful outcomes helps organize the duties of responsible implementation into a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  84%|████████▍ | 125/149 [08:37<01:31,  3.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3720.00 --> 3750.00] technical component and a social component. Technical and social components. Tell us about the technical component first. The technical component is about conveying the statistical results appropriately as empirically derived evidence that can support but not replace sound human judgment. AI results, the guide says, serve as stand-ins for acts of speech and representation. And like any representation making a claim, they require rational justification. So treat the AI output like evidence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  85%|████████▍ | 126/149 [08:42<01:32,  4.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3750.00 --> 3780.00] that needs to be weighed. Right. Delivering this technical content responsibly means prioritizing the perspectives of the user and the decision subject, getting input from domain experts. It often requires a multi-tiered approach based on technical literacy. Implementers need to understand the model's assumptions and limitations. System operators need deeper technical proficiency. Decision subjects need clarity above all. And what kind of technical information should be delivered? The guide makes several recommendations. Use plain, non-technical...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  85%|████████▌ | 127/149 [08:45<01:24,  3.84s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3780.00 --> 3810.00] language for implementers and decision subjects. Present results as facts or evidence supporting a conclusion with clear premises and rationale. Make process logs and monitoring results available. And crucially, include that implementation disclaimer we discussed earlier. Yes, that disclaimer felt really important, worth reiterating its core message. Absolutely. The essence is, this AI output is intended to assist your judgment, not replace it. It's not the sole basis for your decision. It's based on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  86%|████████▌ | 128/149 [08:49<01:17,  3.69s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3810.00 --> 3840.00] statistical analysis of population data, meaning there's unavoidable uncertainty, and it doesn't capture the specific circumstances of the individual. Your inference must bridge that gap from statistical generalization to the individual's concrete situation. That's such a vital qualification, statistical generalization versus individual reality. It is. Other technical recommendations include providing explicit performance metrics, clear representations of confidence intervals or error bars, raw numerical probabilities behind any simplified score.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  87%|████████▋ | 129/149 [08:53<01:18,  3.95s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3840.00 --> 3870.00] like wristbands 110, and including counterfactual explanatory tools where feasible to offer that actionable recourse. Okay, that's the technical side. What about the social component of responsible implementation? You said it's about translating into socially meaningful terms. Yes, this is about clarifying the socially meaningful content embedded within and produced by the AI's output. It means explicitly translating the model's technical machinery, its variables, parameters, functions, back into the everyday language of humanly relevant.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  87%|████████▋ | 130/149 [08:57<01:13,  3.86s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3870.00 --> 3900.00] meanings, categories, and relationships that actually shaped its original design in the first place. So connecting the math back to the human world it came from. Precisely. It's this reconstruction of the underlying societal purposes, norms, and practices that allows implementers to apply the AI's insights appropriately to the specific social and individual contexts of the people affected. It requires training implementers to carry out this translation with, as the guide puts it. Interpretive charity, reasonableness, empathy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  88%|████████▊ | 131/149 [09:01<01:10,  3.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3900.00 --> 3930.00] and context specificity. That sounds less like technical training and more like training and interpretation and communication. Understanding the human story behind the data points. It really is. The guide visualizes this as the content life cycle, which has three phases. Phase one, translate human values in during the design process. This is where human choices about goals, data sampling, feature engineering happen. Right. And where historical biases might get embedded in the data. Okay. Values and biases go in. Phase two, data processing. This is the.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  89%|████████▊ | 132/149 [09:05<01:07,  3.97s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3930.00 --> 3960.00] computation stage where the trained model processes the quantified proxies of those human purposes and values. The machine does its thing. Right. Phase three. Translate human values out during the implementation process. This is where the implementer reconstructs the societal purposes and norms to clarify the socially meaningful content of the results for this specific situation. And the guide argues it's only through this crucial retranslation out that the model becomes usefully interpretable and enables genuine end-to-end accountability. Translate it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  89%|████████▉ | 133/149 [09:09<01:03,  3.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3960.00 --> 3990.00] process translate out and this leads to something called the translation rule yes the translation rule it basically states what is translated in to an algorithmic system is directly proportional to what in terms of the explanatory needs must be translated out so the more complex the human values and social context you try to capture in the model the more explanation and interpretation is required out at the implementation stage exactly the rule highlights two key distinctions first between clarifying socially meaningful you\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  90%|████████▉ | 134/149 [09:13<00:58,  3.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3990.00 --> 4020.00] content, which makes AI interpretable, and establishing normative rightness, which makes AI justifiable. Second, between intention and design, the human purpose is baked into the model's construction, and intention and application, how the human implementer uses the output and the consequences for the subject. And the guide uses two contrasting examples to really drive this home, doesn't it? It does, very effectively. It compares a hypothetical radiomics cancer detection system with a predictive risk assessment system in child social care. Okay.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  91%|█████████ | 135/149 [09:16<00:54,  3.88s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4020.00 --> 4050.00] How do they differ in terms of this translation rule? Well, in the radiomic system, the social content translated in is relatively minimal. It's primarily about clinical goals, image features related to pathology. But the normative aspect, patient well-being, safety, avoiding misdiagnosis, is highly significant. So the main explanatory burden translation out for the physician and patient is less about unpacking complex social meanings and more about justifying the system's safety, reliability, accuracy, and ensuring equitable access to this health benefit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  91%|█████████▏| 136/149 [09:20<00:51,  3.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4050.00 --> 4080.00] Makes sense. Simpler social input, high safety justification needed. But the child social care example must be completely different. Entirely different. The social content translated in is incredibly intricate and extensive. The target variable itself, child safety, is complex. The features might include things like age, public health records, family history, parental mental health, neighborhood crime rates, all deeply socially embedded concepts. Loaded with context. Exactly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  92%|█████████▏| 137/149 [09:24<00:46,  3.86s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4080.00 --> 4110.00] The affirmative aspect is also extremely complex, balancing the paramount need for child welfare against principles of parental fairness, system efficiency, the sanctity of familial relations. So the translation burden on the frontline social worker using this tool is immense. What do they need to do? They have to scrutinize the particular decision subject situation intensely. They need to clarify the socially meaningful content of all those input features, like demographic info or past welfare interactions, within the living context of that specific family. And\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  93%|█████████▎| 138/149 [09:28<00:41,  3.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4110.00 --> 4140.00] And they must critically assess the potential legacies of historical discrimination or structural bias that might be embedded in that data or the model's logic. The guide calls this process of weighing the algorithmic output against the specific human context and broader ethical principles normative triangulation. It's crucial for achieving justifiable AI in such sensitive domains. Normative triangulation. Wow. So the social worker becomes this essential bridge, this interpreter between the algorithm's statistical pattern matching and the incredibly nuanced.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  93%|█████████▎| 139/149 [09:33<00:41,  4.12s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4140.00 --> 4170.00] high-stakes human reality. It really underscores how the AI is just a tool, and the ultimate responsibility, the deep interpretation, rests squarely with trained, ethically aware people. Absolutely. It cannot replace that situated human judgment, which leads us to the final step in human-centered implementation. Step three, build an ethical implementation platform. This sounds like the capstone, bringing it all together. Yes, that's exactly what it is. It has several components. First, train ethical implementation. Implementers need to be prepared\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  94%|█████████▍| 140/149 [09:36<00:35,  3.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4170.00 --> 4200.00] not just technically, but ethically. They need to be stewards of interpretable and justifiable AI. What does that training involve? It involves equipping them to rationally evaluate the AI outputs, communicate algorithmically-assisted decisions effectively in plain language, appropriately apply the system's conclusions to specific social circumstances, weigh the AI insights against broader purposes and values, and ultimately justify the ethical permissibility and trustworthiness of both the age and the time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  95%|█████████▍| 141/149 [09:40<00:32,  4.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4200.00 --> 4230.00] AI systems outcomes, and the processes behind them. So it's a demanding role requiring ethical and communicative skills, not just technical know-how. So training for judgment and communication, what else is part of the platform? Second, make your implementation platform a relevant part and capstone of the sustainability track of your project. This means the platform shouldn't just be about pushing information out. It needs to be a two-way street. It should serve as a sounding board for feedback from implementers and affected communities about the system's real-life effects, its usability,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  95%|█████████▌| 142/149 [09:44<00:28,  4.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4230.00 --> 4260.00] its unforeseen consequences. It needs to be dialogically and collaboratively connected to the communities it serves to support that ongoing SIA process we talked about. A feedback loop for continuous improvement. Exactly. And third, provide a model sheet to implementers and establish protocols for implementation reporting. This means giving implementers concise summary sheets, model sheets containing key information, technical specs, performance metrics, the fairness criteria used, that crucial implementation disclaimer,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  96%|█████████▌| 143/149 [09:49<00:24,  4.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4260.00 --> 4290.00] and easy links to the full process logs and SIA information. You also need clear protocols for reporting issues, successes, or concerns, with the level of reporting proportional to the risks involved. Giving them the key info at their fingertips and a way to report back makes sense. And finally... Finally, and perhaps most importantly, foster outcome understanding through dialogue. This really ties everything together. The guide stresses that achieving interpretable and justifiable AI is inherently a dialogical and collaborative effort. Understanding is not just about understanding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  97%|█████████▋| 144/149 [09:52<00:19,  3.95s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4290.00 --> 4320.00] isn't just passively received, it's actively reached through communication. A conversation. Yes. Implementers and decision subjects, or their advocates, are participants in an ongoing explanatory dialogue. Understanding is achieved through open, respectful, sincere, and well-informed communication where all voices are considered. This dialogue not only advances responsible implementation in specific cases, but also encourages reflection and feedback that can lead to improvements in the AI's design, delivery, and overall performance over time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  97%|█████████▋| 145/149 [09:56<00:15,  4.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4320.00 --> 4350.00] It brings the whole process full circle. Wow. What an incredible, detailed, deep dive. We've really journeyed through the complexities of AI ethics and safety, specifically from that government perspective, trying to shape these AI-powered economies responsibly, from foundational SDRM values right down to practical implementation protocols and the importance of dialogue. It is a complex landscape, definitely. But what's clear from the Alan Turing Institute guide is that there is a path forward. It provides a comprehensive and I think quite actionable roadmap.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  98%|█████████▊| 146/149 [10:01<00:12,  4.25s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4350.00 --> 4380.00] roadmap for navigating these challenges responsibly, always keeping that focus on public benefit. It really makes you think, doesn't it? Going right back to the origins of this technology. You know, back in 1936, Alan Turing himself, with just pencil and paper, sketched out the abstract idea of the Turing machine, fundamentally defining what it means to compute. Yeah, an incredibly humble beginning for something that ushered in the entire digital age. And led eventually to these omnipresent algorithmic systems we've been discussing today. And as the guide points out quite powerfully,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  99%|█████████▊| 147/149 [10:05<00:08,  4.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4380.00 --> 4410.00] near the end, AI isn't just another general purpose technology like, say, electricity. It's evolving into something more. A gatekeeper technology. Gatekeeper. There's that phrase again. Yeah. Meaning it uniquely holds the key, potentially, both to exponential advancements in human well-being and simultaneously to significant, maybe even existential, risks for society's future. It controls access to so many potential futures. So it really leaves us as a species with.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks:  99%|█████████▉| 148/149 [10:09<00:04,  4.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4410.00 --> 4440.00] a fundamental choice. The guide, as you said, has offered one way to move forward, one framework. It suggests that responsible innovation comes from deliberately prioritizing ethical purposes and values. It's about consciously trying to steer the course of our algorithmic creations in accordance with a shared vision of what a better human future should look like, not just letting the tech lead us wherever it may go. Ultimately, the guide reminds us, and this is a powerful closing thought, that it is humankind\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunks: 100%|██████████| 149/149 [10:12<00:00,  3.68s/it]\u001b[A\n",
            "Transcribing audio files: 100%|██████████| 1/1 [10:31<00:00, 631.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4440.00 --> 4455.84] that must ultimately choose which direction the key will turn. The choice is ours. The technology doesn't choose for us. That really is a provocative thought to leave you, our listeners, with. How will you, in your own way, contribute to shaping this future? Which direction will you help turn that key?\n",
            "\n",
            "✅ Saved transcript to: /content/drive/MyDrive/AI Governance.wav.txt\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "GNmYH7tsGWkU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08a8868d60a8431d857eae23eb74391a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316fcf94cc18441cba6f7bf1cf5875af",
              "IPY_MODEL_cabb50fc61f6455982d653a675573a43",
              "IPY_MODEL_fafabedf0c5349d5a79b498ada2f438a"
            ],
            "layout": "IPY_MODEL_f50c9d733a874e1882e76f5040586901"
          }
        },
        "316fcf94cc18441cba6f7bf1cf5875af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59057142c7484021862763c837a83df0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b9c2ffc7d374a88824e8ccbd7cf6c60",
            "value": "config.json: 100%"
          }
        },
        "cabb50fc61f6455982d653a675573a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67ea78f05754723a36db9d5bfc6d847",
            "max": 1272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_160ddf2c05c343919dfc193e74ed1be6",
            "value": 1272
          }
        },
        "fafabedf0c5349d5a79b498ada2f438a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee3778a77d914c558ae2fe11e9dd9e50",
            "placeholder": "​",
            "style": "IPY_MODEL_c5b1612bd0cd4a0f8af03a31d9991c15",
            "value": " 1.27k/1.27k [00:00&lt;00:00, 123kB/s]"
          }
        },
        "f50c9d733a874e1882e76f5040586901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59057142c7484021862763c837a83df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b9c2ffc7d374a88824e8ccbd7cf6c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c67ea78f05754723a36db9d5bfc6d847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160ddf2c05c343919dfc193e74ed1be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee3778a77d914c558ae2fe11e9dd9e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b1612bd0cd4a0f8af03a31d9991c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30345451f2eb4039b690c52bd65701e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdc7e28550b443dab917634690a9cf93",
              "IPY_MODEL_24deefad2ac4452b8e644bc876141310",
              "IPY_MODEL_668e8c1c3b5f4eb69268bf97df5823be"
            ],
            "layout": "IPY_MODEL_9ee5a51e28d949f3b077af5f9e9ed963"
          }
        },
        "bdc7e28550b443dab917634690a9cf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9391398ab34a0a8ac1ee86ab50f2af",
            "placeholder": "​",
            "style": "IPY_MODEL_e933ce06b5f343b0845fcef8c5dbd394",
            "value": "model.safetensors: 100%"
          }
        },
        "24deefad2ac4452b8e644bc876141310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e622d6c7395f4038b6c27072929402c4",
            "max": 3087130976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2779945066e4348a48703d443b29894",
            "value": 3087130976
          }
        },
        "668e8c1c3b5f4eb69268bf97df5823be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_817b99d3bc3f44b1ab406775933088fd",
            "placeholder": "​",
            "style": "IPY_MODEL_8a5f4846287046a6a2fa97d625d2ba0f",
            "value": " 3.09G/3.09G [00:46&lt;00:00, 80.5MB/s]"
          }
        },
        "9ee5a51e28d949f3b077af5f9e9ed963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9391398ab34a0a8ac1ee86ab50f2af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e933ce06b5f343b0845fcef8c5dbd394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e622d6c7395f4038b6c27072929402c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2779945066e4348a48703d443b29894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "817b99d3bc3f44b1ab406775933088fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5f4846287046a6a2fa97d625d2ba0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e26086736e2149faa30264fdc47466e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8507a542f484955817bf60c9d4e78a7",
              "IPY_MODEL_d113289f24d74dc8891835d0681fcd64",
              "IPY_MODEL_4291cf4cd8674aff933bea5e5e18711a"
            ],
            "layout": "IPY_MODEL_d127825763d946a4bf35dc1d05befa9c"
          }
        },
        "f8507a542f484955817bf60c9d4e78a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93bcf0ebd8f54c3894cc74cc627e980f",
            "placeholder": "​",
            "style": "IPY_MODEL_fb874ab6059a43fe9c71c54419a490e0",
            "value": "generation_config.json: 100%"
          }
        },
        "d113289f24d74dc8891835d0681fcd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c507718062f431e80166cff199f020c",
            "max": 3903,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a49c00ec90d4c62bb2a906224dd94e9",
            "value": 3903
          }
        },
        "4291cf4cd8674aff933bea5e5e18711a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91197a82e4f4305a1245fe984126ccc",
            "placeholder": "​",
            "style": "IPY_MODEL_10b071612b784e26b02a2a66a08a748a",
            "value": " 3.90k/3.90k [00:00&lt;00:00, 258kB/s]"
          }
        },
        "d127825763d946a4bf35dc1d05befa9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bcf0ebd8f54c3894cc74cc627e980f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb874ab6059a43fe9c71c54419a490e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c507718062f431e80166cff199f020c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a49c00ec90d4c62bb2a906224dd94e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a91197a82e4f4305a1245fe984126ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b071612b784e26b02a2a66a08a748a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eea893e32ec44ebcb3e60c8ec70fc655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7acc423177344c29255a76bbd159926",
              "IPY_MODEL_79f540767d5742cb850bbbe12486592d",
              "IPY_MODEL_b4763e33f00c4410934c8a25a9cad0be"
            ],
            "layout": "IPY_MODEL_91d4e029699e4afca30735baa5aef536"
          }
        },
        "a7acc423177344c29255a76bbd159926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478c8f31831c4eca8c1ed12782dfe9fa",
            "placeholder": "​",
            "style": "IPY_MODEL_2e3caa93a0294b16b394907481353e04",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "79f540767d5742cb850bbbe12486592d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed02b7d8ceeb47e3a07e50dab0437c30",
            "max": 340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92579b31e232496a8144e3cf54684b17",
            "value": 340
          }
        },
        "b4763e33f00c4410934c8a25a9cad0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc326222c6fb4aa6999cfe3157b56bcc",
            "placeholder": "​",
            "style": "IPY_MODEL_d6d12aa086324481b045808a2e8bfe7e",
            "value": " 340/340 [00:00&lt;00:00, 32.2kB/s]"
          }
        },
        "91d4e029699e4afca30735baa5aef536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478c8f31831c4eca8c1ed12782dfe9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e3caa93a0294b16b394907481353e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed02b7d8ceeb47e3a07e50dab0437c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92579b31e232496a8144e3cf54684b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc326222c6fb4aa6999cfe3157b56bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d12aa086324481b045808a2e8bfe7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09fa0c2ca867419fa27ad0f328a971db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5008ac00c9624a6f83018c54446eb0fa",
              "IPY_MODEL_e1af3efdb0524df69999b4b73e9c9191",
              "IPY_MODEL_f0ceac8662e645e18f1af107f14ec391"
            ],
            "layout": "IPY_MODEL_3b8631a071644d238093f16fac832687"
          }
        },
        "5008ac00c9624a6f83018c54446eb0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696d2e73123945beb01dd327a2630370",
            "placeholder": "​",
            "style": "IPY_MODEL_3a02f280684846e2a680eefa37689324",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e1af3efdb0524df69999b4b73e9c9191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030f700ed92243de9dae7ea7a265985b",
            "max": 282843,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7c25b6c57bd4fa688f5124283564e5f",
            "value": 282843
          }
        },
        "f0ceac8662e645e18f1af107f14ec391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79701dd790034c8c8b2a4b12d50c0c64",
            "placeholder": "​",
            "style": "IPY_MODEL_d494ae756a0d4abab7e91db7deda15e2",
            "value": " 283k/283k [00:00&lt;00:00, 7.72MB/s]"
          }
        },
        "3b8631a071644d238093f16fac832687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696d2e73123945beb01dd327a2630370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a02f280684846e2a680eefa37689324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030f700ed92243de9dae7ea7a265985b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c25b6c57bd4fa688f5124283564e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79701dd790034c8c8b2a4b12d50c0c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d494ae756a0d4abab7e91db7deda15e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "724c362bdd5e4470ba4f520222a32857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e37c44e9f1c45928c0945b8208f53c0",
              "IPY_MODEL_58de999e8ced4d2bb0cd62493a51a0fc",
              "IPY_MODEL_fa7c3a2a7a584403b42be774d32cf9e7"
            ],
            "layout": "IPY_MODEL_8f7a229642474b7f9fa52ac56c23f18b"
          }
        },
        "3e37c44e9f1c45928c0945b8208f53c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18135cd2c7e411c89bd7a275d722481",
            "placeholder": "​",
            "style": "IPY_MODEL_73eee035866048719e3c7a19d72f8ce8",
            "value": "vocab.json: 100%"
          }
        },
        "58de999e8ced4d2bb0cd62493a51a0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a39542c8e14d8694b2ff13d6b91fa7",
            "max": 1036558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d39b1d70e234f1cb2d5ade7f06894dd",
            "value": 1036558
          }
        },
        "fa7c3a2a7a584403b42be774d32cf9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1c28c1edf824c408a5b39c8490d79ed",
            "placeholder": "​",
            "style": "IPY_MODEL_f3791f0e8b184963ae85c4e3c7b11a07",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.34MB/s]"
          }
        },
        "8f7a229642474b7f9fa52ac56c23f18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18135cd2c7e411c89bd7a275d722481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73eee035866048719e3c7a19d72f8ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7a39542c8e14d8694b2ff13d6b91fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d39b1d70e234f1cb2d5ade7f06894dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1c28c1edf824c408a5b39c8490d79ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3791f0e8b184963ae85c4e3c7b11a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f1b35db6f2e4876be68e0123b1dbb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72e0c1c626854ccf862e3768d51fe24c",
              "IPY_MODEL_0f37d5a9ed39450686ee81514bea7e79",
              "IPY_MODEL_51081cfec6fc4bc1a95643ab344a6ed1"
            ],
            "layout": "IPY_MODEL_6d2c2985d7254c0b8c938c2b63cc41c1"
          }
        },
        "72e0c1c626854ccf862e3768d51fe24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9b7524a5e940a4aeaeead56cee73be",
            "placeholder": "​",
            "style": "IPY_MODEL_c6528d0150374a3589941b2d43897d28",
            "value": "tokenizer.json: 100%"
          }
        },
        "0f37d5a9ed39450686ee81514bea7e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9f0477250f4859bbe47995c7b31e8d",
            "max": 2480617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6230bbe983b34cab9ff23a5aac661447",
            "value": 2480617
          }
        },
        "51081cfec6fc4bc1a95643ab344a6ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53554ffb7c2432a9c48ed4cf69baa26",
            "placeholder": "​",
            "style": "IPY_MODEL_4d77691baaa745789a513174755e64e5",
            "value": " 2.48M/2.48M [00:00&lt;00:00, 7.62MB/s]"
          }
        },
        "6d2c2985d7254c0b8c938c2b63cc41c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9b7524a5e940a4aeaeead56cee73be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6528d0150374a3589941b2d43897d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d9f0477250f4859bbe47995c7b31e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6230bbe983b34cab9ff23a5aac661447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a53554ffb7c2432a9c48ed4cf69baa26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d77691baaa745789a513174755e64e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aec4510260d418b970ed7a3a49c91d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c3183931e734894a661c30f81b119fb",
              "IPY_MODEL_8dfbd4830b5048afb77906e1d495a1d6",
              "IPY_MODEL_3f40ff17c00a4f1bb6baae4d836609bc"
            ],
            "layout": "IPY_MODEL_7a6cc240c25849c29d78a8e4d30505f2"
          }
        },
        "1c3183931e734894a661c30f81b119fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d58c5ecc5d4e6a893f7e8c35a4ddbb",
            "placeholder": "​",
            "style": "IPY_MODEL_8fac2a76034e423c9fc8f92c0036390c",
            "value": "merges.txt: 100%"
          }
        },
        "8dfbd4830b5048afb77906e1d495a1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3d9577aa04444babc11fab923f6785",
            "max": 493869,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26672faa0ff84f23b5c1ec5ba9431761",
            "value": 493869
          }
        },
        "3f40ff17c00a4f1bb6baae4d836609bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db35198aacaf41a9afe8168bf7c42e54",
            "placeholder": "​",
            "style": "IPY_MODEL_24316f423e50444782dfded6e198b93f",
            "value": " 494k/494k [00:00&lt;00:00, 31.3MB/s]"
          }
        },
        "7a6cc240c25849c29d78a8e4d30505f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d58c5ecc5d4e6a893f7e8c35a4ddbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fac2a76034e423c9fc8f92c0036390c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b3d9577aa04444babc11fab923f6785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26672faa0ff84f23b5c1ec5ba9431761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db35198aacaf41a9afe8168bf7c42e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24316f423e50444782dfded6e198b93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0ebfccaaf62441a9df7a3af42820115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7cc3b68821648a6bb8e2d5c68e9eab2",
              "IPY_MODEL_5694d791d7434157a4c7221aedfe40e6",
              "IPY_MODEL_019ee4b3a9c64f8fab5f4d7e0ac46297"
            ],
            "layout": "IPY_MODEL_77d2a25db3cc4d43af9390165e6a3133"
          }
        },
        "e7cc3b68821648a6bb8e2d5c68e9eab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1bdc86e0aa4c71a1288137b15613c6",
            "placeholder": "​",
            "style": "IPY_MODEL_9981a366c1ac46a282ba7fd5431748fb",
            "value": "normalizer.json: 100%"
          }
        },
        "5694d791d7434157a4c7221aedfe40e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f93b430ba3d542c490c5a9d1a307fd08",
            "max": 52666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e5c7cfd70db41d29805aa07509e7177",
            "value": 52666
          }
        },
        "019ee4b3a9c64f8fab5f4d7e0ac46297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fac794af5b54e988f9fad9e5e468ebe",
            "placeholder": "​",
            "style": "IPY_MODEL_feeccf4e643d4f1983e5e41dc6c1cbf3",
            "value": " 52.7k/52.7k [00:00&lt;00:00, 4.74MB/s]"
          }
        },
        "77d2a25db3cc4d43af9390165e6a3133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1bdc86e0aa4c71a1288137b15613c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9981a366c1ac46a282ba7fd5431748fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f93b430ba3d542c490c5a9d1a307fd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5c7cfd70db41d29805aa07509e7177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fac794af5b54e988f9fad9e5e468ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feeccf4e643d4f1983e5e41dc6c1cbf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "287e24831a6f497ebaa2d41cc5c69045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df05d5baf9ff43f88d7ec3ba3b1e830a",
              "IPY_MODEL_2a774dfd78754b3c915291fa8d1be864",
              "IPY_MODEL_d7b6c0628314415e830eca4e6d56007c"
            ],
            "layout": "IPY_MODEL_2a5963bf1e474172bcec724f02294c4b"
          }
        },
        "df05d5baf9ff43f88d7ec3ba3b1e830a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c344ced7654c5797eff636ae8aadd3",
            "placeholder": "​",
            "style": "IPY_MODEL_ef5df9be1dcb421298db8cfcb68a7b73",
            "value": "added_tokens.json: 100%"
          }
        },
        "2a774dfd78754b3c915291fa8d1be864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea507e5561a74da0a91d51a001bf3533",
            "max": 34648,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0a8e0d036dc4140bcd11f7a9c4af34f",
            "value": 34648
          }
        },
        "d7b6c0628314415e830eca4e6d56007c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a1f8e218834ed5ab42d5bc74baf59f",
            "placeholder": "​",
            "style": "IPY_MODEL_8dc9fc4480d149bdab2bbb125352b231",
            "value": " 34.6k/34.6k [00:00&lt;00:00, 3.60MB/s]"
          }
        },
        "2a5963bf1e474172bcec724f02294c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c344ced7654c5797eff636ae8aadd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5df9be1dcb421298db8cfcb68a7b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea507e5561a74da0a91d51a001bf3533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a8e0d036dc4140bcd11f7a9c4af34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91a1f8e218834ed5ab42d5bc74baf59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc9fc4480d149bdab2bbb125352b231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fde545cea1564e4fad941f43e504c407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_261bc6782d324374a9669a76d0aeb1f8",
              "IPY_MODEL_a154181fb5e741f0b20c303ee40396af",
              "IPY_MODEL_a18e7d2b9fb64a9bad10958586a05145"
            ],
            "layout": "IPY_MODEL_f2d575612e3248ec9c2d2a460d7d5e9e"
          }
        },
        "261bc6782d324374a9669a76d0aeb1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249c500199c84467bf537c92906a5b63",
            "placeholder": "​",
            "style": "IPY_MODEL_64e63c760f884f56ad77c9aa0f5b47d0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a154181fb5e741f0b20c303ee40396af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2c81bb533141e7ba54f97329c44148",
            "max": 2072,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_770e249c72844ef69b05de157cab65e0",
            "value": 2072
          }
        },
        "a18e7d2b9fb64a9bad10958586a05145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd6e67551a344aca2d1f7851039a67b",
            "placeholder": "​",
            "style": "IPY_MODEL_cfb559e7fa2342ad841d5381945c7aef",
            "value": " 2.07k/2.07k [00:00&lt;00:00, 249kB/s]"
          }
        },
        "f2d575612e3248ec9c2d2a460d7d5e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249c500199c84467bf537c92906a5b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64e63c760f884f56ad77c9aa0f5b47d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2c81bb533141e7ba54f97329c44148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770e249c72844ef69b05de157cab65e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbd6e67551a344aca2d1f7851039a67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb559e7fa2342ad841d5381945c7aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}